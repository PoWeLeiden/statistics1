# Inference for proportions {#sec-analysis-proportions}

## Inference for a single proportion

### Confidence interval for a single proportion

#### Calculating 'by hand' using R

One approach is to calculate the normal approximation of the binomial distribution (Wald interval), as described in the OpenIntro book. This is basically the same as doing the 'manual' calculation, but in R.

As an example, we use a survey of voters in which 23% indicate to support the Conservatives. We estimate a 95% confidence interval for this estimate:

```{r}
# Define input (change these you appropriate values)
p_hat = 0.23
n = 1000
confidence = 0.95


# Perform calculations (no need to change anything here)
se = sqrt(p_hat * (1 - p_hat)/ n)     # Calculate SE
z_star = qnorm((1 + confidence) / 2)  # Calculate z*-value 
lower = p_hat - z_star * se           # Lower bound CI
upper = p_hat + z_star * se           # Upper bound CI
c(lower, upper)
```

#### Using summary data

When you have only summary data, i.e. information about the sample size and sample proportion, we recommend using `prop.test` for calculating a confidence interval for a single proportion.[\^3] The function `prop.test` is part of the package `stats`, which is one of the few packages that R automatically loads when it starts.

```{r}
# Define input
p_hat = 0.23
n = 1000

# Run the actual test
prop.test(x = p_hat * n, 
          n = n, 
          conf.level = 0.95)
```

Note: The results from the calculation by hand and from the function `prop.test` are slightly different. This is due to the fact that `prop.test` uses a slightly more complicated formula for calculating the confidence interval (Wilson score interval), also incorporating a 'continutiy correction' (which accounts for the fact that we are using a continuous normal distribution to approximate a discrete phenomenon, i.e. the number of successes).

`prop.test`

:   This is the function that conducts a test for a proportion and its confidence interval.

`x = p_hat * n`

:   The first value specified should be the number of successes. In our example his is the number of people supporting the Conservatives. We can calculate this as the sample proportion ($\hat{p}$) times the sample size.

`n = n`

:   The second value specified should be the number of trials (read: the number of observations in our dataset). In our case: the number of respondents in the dataset.

`conf.level = 0.95`

:   This determines the confidence level. The default is 0.95 which corresponds to a 95% confidence interval.

#### Variables in a data frame

If you have a data frame with a variable that represents successes (or not) for each case, we can use the following procedure. In our example we have a variable that records the vote intention of a respondent, which is either `Conservative` or `Other party`:

```{r}
# For this example, we create a dataset of 1000 respondents with 230 expressing support for the Conservatives
example_data = data.frame(party_choice = factor(c(rep("Conservatives", 230), 
                                                  rep("Other party", 770))))
table(example_data$party_choice)
```

If we have data like this, we can directly calculate the confidence interval by running prop.test for the table:

```{r, eval = FALSE}
prop.test(table(example_data$party_choice),
          conf.level = 0.95)
```

`table(example_data$party_choice)`

:   The first argument is a table of our variable of interest, which we can create by this code. If you use your own data, replace `example_data` with the name of your data frame and `party_choice` with the name of the variable of interest.[^3]

    **Note**: The table should include only two categories. R will calculate the confidence interval for the first category in the table (in our case: Conservatives).[^4]

`conf.level = 0.95`

:   This determines the confidence level. The default is 0.95 which corresponds to a 95% confidence interval.

[^3]: If you really like pipes, you can also use: `example_data |> pull(party_choice) |> table()` .

[^4]: If you would like to calculate the confidence interval for the second category, you can use, for example, `relevel` to re-order the categories of the first variable:

    ```{r, echo = TRUE}
    prop.test(table(relevel(example_data$party_choice, ref = "Other party")),
              conf.level = 0.95)
    ```

```{r, echo = FALSE}
prop.test(table(example_data$party_choice),
          conf.level = 0.95)
```


### Hypothesis tests for a single proportion

#### Summary data

When you only have information about the sample size and the proportion, we recommend using `prop.test` for conducting a hypothesis test.[^5]

[^5]: This uses a slightly more complicated formula for calculating the confidence interval (Wilson score interval), also incorporating a 'continutiy correction' (which accounts for the fact that we are using a continuous normal distribution to approximate a discrete phenomenon, i.e. the number of successes)

```{r}
# Define input
p_hat = 0.23
n = 1000

# Run the actual test
prop.test(x = p_hat * n, 
          n = n, 
          p = 0.25,
          alternative = "two.sided")
```

`prop.test`

:   This is the function that conducts a test for a proportion.

`x = p_hat * n`

:   The first value specified should be the number of successes. We can calculate this as the sample proportion ($\hat{p}$) times the sample size.

`n = n`

:   The second value specified should be the number of trials (read: the number of observations in our dataset). In our case: the number of respondents in the dataset.

`p = 0.25`

:   This specifies the hypothesized null value. In this example this is 0.25 or 25%, so we are testing the null hypothesis $\mu_0 = 0.25$

`alternative = "two.sided"`

:   Determine whether we want to use a two sided-test, or a one-sided test. Options are "two.sided" (default), "less" (when $H_1: \mu < p$) or "greater" (when $H_1: \mu > p$).

#### Variables in a data frame

If you have a data frame with a variable that represents successes (or not) for each case, we can input this data directly into `prop.test`. In our example we have a variable that records the vote intention of a respondent, which is either `Conservative` or `Other party` (for the preparation of the data see [Single proportion confidence intervals for variables in a data frame]).

```{r, eval = FALSE}
prop.test(table(example_data$party_choice),
          p = 0.25,
          alternative = "two.sided")
```

`table(example_data$party_choice)`

:   The first argument is a table of our variable of interest, which we can create by this code. If you use your own data, replace `example_data` with the name of your data frame and `party_choice` with the name of the variable of interest.

    **Note**: The table should include only two categories. R will perform the test that the proportion for the first category is equal to the hypothesized value (`p`, see below).

`p = 0.25`

:   This specifies the hypothesized null value. In this example this is 0.25 or 25%, so we are testing the null hypothesis $\mu_0 = 0.25$

`alternative = "two.sided"`

:   Determine whether we want to use a two sided-test, or a one-sided test. Options are "two.sided" (default), "less" (when $H_1: \mu < p$) or "greater" (when $H_1: \mu > p$).

```{r, echo = FALSE}
prop.test(table(example_data$party_choice),
          p = 0.25,
          alternative = "two.sided")
```

## Reporting the results from a hypothesis test for a single proportion

```{r, echo = TRUE, include=TRUE}
#Obtain z-value based on manual calculation

# Define input
p_hat = 0.12
n = 1500
p = 0.10

z <- (p_hat-p)/(sqrt((p*(1-p)/n)))
z
2*pnorm(q=z, lower.tail=FALSE)

# Run the actual test
prop.test(x = p_hat * n, 
          n = n, 
          p = 0.10,
          alternative = "two.sided",
          correct = FALSE)
```

::: callout-note
#### Output explanation

* the probability of finding the observed ($z$ or $\chi^2$, given the null hypothesis (*p*-value) is given as follows:
  + in R, see p-value = 0.009823. Note: If the value is very close to zero, R may use the scientific notation for small numbers (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022). In these cases, write p < 0.001 in your report.
:::

#### Reporting

If you calculate the results by hand and obtain a z-score, then the correct report includes:

* A conclusion about the null hypothesis; followed by
* Information about the sample percentage and the population percentage.
* $z$ = the value of z. 
* p = p-value. When working with statistical software, you should report the exact p-value that is displayed. 
  + in R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p < 0.001 in your report.

If you calculate the results using prop.test and obtain a $\chi^2$-score, then the correct report includes:

* A conclusion about the null hypothesis; followed by
* Information about the sample percentage and the population percentage.
* $\chi^2$ = the value of chi-square, followed by the degrees of freedom in brackets. 
* p = p-value. When working with statistical software, you should report the exact p-value that is displayed. 
  + in R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p < 0.001 in your report.

::: callout-tip
#### Report

✓ The percentage of supporters found in our sample (N = 1500) who support the Socialist Party (12%) is statistically significantly different from the percentage of the entire population (10%), z=2.58, p=0.1394.

✓ The percentage of supporters found in our sample (N = 1500) who support the Socialist Party (12%) is statistically significantly different from the percentage of the entire population (10%), $\chi^2$ (1)=6.6667, p=0.0098.

:::


## Comparing two proportions

Last week, we calculated a confidence interval for a single proportion. This week we cover two (independent) proportions. The calculations below apply to the case where the two proportions are drawn from different samples or subsamples, for example the support for a party in two separate opinion polls or the left-right position of respondents who live in the capital city and those who do not live there (these groups are independent because you can only belong to one).

### Confidence interval for the difference between two proportions

We use the CPR data set from the `openintro` package (see p. 218). The data set contains data on patients who were randomly divided into a treatment group where they received a blood thinner or the control group where they did not receive a blood thinner. The outcome variable of interest was whether the patients survived for at least 24 hours.

```{r}
library(tidyverse)
library(openintro)
library(flextable)
data(cpr)

# Refactor variables to ensure the order is the same as in the textbook table
cpr <- cpr |>
  mutate(group = factor(group, levels = c("control", "treatment"), ordered = TRUE),
         outcome = factor(outcome, levels = c("survived", "died"), ordered = TRUE))

table_example <- proc_freq(x = cpr, 
                           row = "group", 
                           col = "outcome", 
                           include.row_percent = FALSE, 
                           include.column_percent = FALSE, 
                           include.table_percent = FALSE) 
table_example
```

Note that we usually put the independent variable in the columns. However, the book does not follow this convention.

#### Calculating 'by hand' using R

To calculate a 90 % confidence interval of the difference for the survival rates ($p_{1}$ and $p_{2}$) by hand, we can write:

```{r}
# Define input (change these according to your values)
p_hat_1 = 14 / 40  # Treatment group
p_hat_2 = 11 / 50  # Control group
n_1 = 40
n_2 = 50
confidence = 0.9

# Perform calculations (no need to change anything here)
p_hat = p_hat_1 - p_hat_2
se = sqrt((p_hat_1*(1-p_hat_1)/n_1) + (p_hat_2*(1-p_hat_2)/n_2))
z_star = qnorm((1 + confidence) / 2)  # Calculate z*-value 
lower = p_hat - z_star * se   # Lower bound CI
upper = p_hat + z_star * se   # Upper bound CI
c(lower, upper)
```

Note: we follow the order of the book and take p1 as the percentage for the treatment group and p2 as the percentage for the control group.

#### Summary data

When you have only summary data, i.e. information about the sample size and sample proportion, we recommend using `prop.test` for calculating a confidence interval for the difference between proportions in two samples. The function `prop.test` is part of the package `stats`, which is one of the few packages that R automatically loads when it starts.

```{r eval=FALSE}
prop.test(x = c(14, 11),
          n = c(40, 50),
          conf.level = 0.90,
          correct=FALSE)
```

`prop.test`

:   This is the function that conducts a test for proportions.

`x = c(14, 11)`

:   Here we specify the number of 'successes' for each group (in this case the number of survivors in each group).

`n = c(40, 50)`

:   The second value specified should be the number of trials for each of the two samples (read: the number of observations in our dataset). In our case: the number of participants in both groups.

`conf.level = 0.90`

:   This determines the confidence level. The default is 0.95 which corresponds to a 95% confidence interval. We set the interval to `0.90`.

`correct = FALSE`

:   This sets the continuity correction to `FALSE`. This should provide the same results as the manual calculations above.

```{r echo=FALSE}
# I repeat the code, so we have the explanations for the options first
# This seems better when the output is relatively long.
prop.test(x = c(14, 11),
          n = c(40, 50),
          conf.level = 0.90,
          correct=FALSE)
```

### Hypothesis test for the difference between two proportions

We use the mammogram data set from the `openintro` package. The data set contains data from an experiment where 89,835 women were randomized to either get a mammogram or a non-mammogram breast screening. The response measured was whether they had died from breast cancer within 25 years.

```{r}
library(openintro)
library(flextable) 
data(mammogram)

# Refactor variables to control the order of categories in the cross table
mammogram <- mammogram |>
  mutate(breast_cancer_death = factor(breast_cancer_death, levels = c("yes", "no"), ordered=TRUE)) |>
  mutate(treatment = factor(treatment, levels = c("mammogram", "control"), ordered = TRUE))

table_example <- proc_freq(x = mammogram, 
                           row = "treatment", 
                           col = "breast_cancer_death", 
                           include.row_percent = FALSE, 
                           include.column_percent = FALSE, 
                           include.table_percent = FALSE) 
table_example
```

 

This table is the same as Table 6.2 on p. 219.

#### Calculation by hand using R

To test the hypothesis whether there was a difference in breast cancer deaths in the two groups by hand, we can write:

```{r}
# Define input (change these according to your values)
p_hat_1 = 500 / (500 + 44425)
p_hat_2 = 505 / (505 + 44405)
n_1 = 500 + 44425 #this is the total number of subjects in the first group
n_2 = 505 + 44405 #this is the total number of subjects in the second group
null_value = 0

# Perform calculations (no need to change anything here)
p_hat_pooled = (p_hat_1 * n_1 + p_hat_2 * n_2) / (n_1 + n_2)
point_est = p_hat_1 - p_hat_2
se = sqrt((p_hat_pooled*(1-p_hat_pooled)/n_1)+(p_hat_pooled*(1-p_hat_pooled)/n_2))
z = (point_est - null_value)/se
pnorm(z)
```

The lower tail area is 0.4349 (small difference compared to the book due to rounding). The p-value, represented by both tails together, is 0.434892\*2 = 0.869784. Because this value $p > 0.05$, we do not reject the null hypothesis.

We can visualize this as follows:

```{r}
library(visualize)
visualize.norm(stat = c(-z, z), section = "tails")
```

#### Summary data

Alternatively, we can use the R function `prop.test()` to test for the difference between the two groups. We used this function in week 4 already for the calculation of a single proportion. The function `prop.test` is part of the package `stats`, which is one of the few packages that R automatically loads when it starts. For our purpose, we use it as follow:

```{r}
result <- prop.test(x = c(500, 505), 
                    n = c(44925, 44910),
                    alternative = "two.sided",
                    correct = FALSE)
result
```

`prop.test(`

:   This is the function that conducts a test for a proportion.

`x = c(500, 505),`

:   Here we indicate the number of cases that are in our two groups. In this example, 500 patients who received a mammogram and died and 505 patients who did not receive a mammogram and died. Because these are two values, we combine them using 'c()'.

`n = c(44925, 44910),`

:   The second value specified should be the total number of trials. In our case: the total number of patients in the two groups. Because these are two values, we combine them using 'c()'.

`alternative = "two.sided"`

:   Determine whether we want to use a two sided-test, or a one-sided test. Options are "two.sided" (default), "less" (when $H_1: \mu < p$) or "greater" (when $H_1: \mu > p$).

`correct = FALSE)`

:   With this, we indicate that we do not want to calculate the confidence interval using a 'continuity correction'. By default, this value is set to 'TRUE'.

#### Data in a data frame

If you have a data frame with a variable that, for each case, represents one of two possible outcomes (in statistical terms “success” and “failure”), we can use `prop.test`.

```{r}
prop.test(table(mammogram$treatment, mammogram$breast_cancer_death), 
          alternative = "two.sided",
          correct = FALSE)
```

`prop.test(table(mammogram$treatment, mammogram$breast_cancer_death),`

:   This is the function that conducts a test for a proportion. We select the independent variable (`mammogram$treatment`) and dependent variable (`mammogram$breast_cancer_death`). Note that the order of the variables matters for the confidence interval: so list the independent first and then the dependent variable.

`alternative = "two.sided"`

:   Determine whether we want to use a two sided-test, or a one-sided test. Options are "two.sided" (default), "less" (when $H_1: \mu < p$) or "greater" (when $H_1: \mu > p$).

`correct = FALSE`

:   With this, we indicate that we do not want to calculate the confidence interval using a 'continuity correction'. By default, this value is set to 'TRUE'.

The results are identical to the example above that used the summary data.

## Reporting the results from a hypothesis test for the difference in two proportions

```{r, echo = TRUE, include=TRUE}
# Define input (change these according to your values)
p_hat_1 = 70 / 330
p_hat_2 = 90 / 470
n_1 = 330 #this is the total number of subjects in the first group
n_2 = 470 #this is the total number of subjects in the second group
null_value = 0

# Perform calculations (no need to change anything here)
p_hat_pooled = (p_hat_1 * n_1 + p_hat_2 * n_2) / (n_1 + n_2)
point_est = p_hat_1 - p_hat_2
se = sqrt((p_hat_pooled*(1-p_hat_pooled)/n_1)+(p_hat_pooled*(1-p_hat_pooled)/n_2))
z = (point_est - null_value)/se
z
2*pnorm(q=z, lower.tail=FALSE)

# Results using prop.test
prop.test(x = c(70, 90), 
                    n = c(330, 470),
                    alternative = "two.sided",
                    correct = FALSE)
```

::: callout-note
#### Output explanation

* the probability of finding the observed ($z$ or $\chi^2$, given the null hypothesis (*p*-value) is given as follows:
  + in R, see p-value = 0.009823. Note: If the value is very close to zero, R may use the scientific notation for small numbers (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022). In these cases, write p < 0.001 in your report.
:::

#### Reporting

If you calculate the results by hand and obtain a z-score, then the correct report includes:

* A conclusion about the null hypothesis; followed by
* Information about the sample percentage and the population percentage.
* $z$ = the value of z. 
* p = p-value. When working with statistical software, you should report the exact p-value that is displayed. 
  + in R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p < 0.001 in your report.

If you calculate the results using prop.test and obtain a $\chi^2$-score, then the correct report includes:

* A conclusion about the null hypothesis; followed by
* Information about the sample percentage and the population percentage.
* $\chi^2$ = the value of chi-square, followed by the degrees of freedom in brackets. 
* p = p-value. When working with statistical software, you should report the exact p-value that is displayed. 
  + in R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p < 0.001 in your report.
  
::: callout-tip
#### Report

✓ There is no statistically significant difference between the percentage of citizens who were somewhat dissatisfied with democracy before the election (21.21%, n = 330) and after the election (19.14%, n = 470), z = 0.72, p = 0.47.

✓ There is no statistically significant difference between the percentage of citizens who were somewhat dissatisfied with democracy before the election (21.21%, n = 330) and after the election (19.14%, n = 470), $\chi^2$ (1) = 0.51, p = 0.47.

:::