# T-tests for means {#sec-analysis-t-test}

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)

library(tidyverse)
library(rio)
library(DescTools)
library(infer)

canada <- import(here::here("data/2019 Canadian Election Study.rds"))
```

We use data from the 2019 Canadian Election Study as an example in this chapter:

```{r, eval=FALSE}
canada <- import("2019 Canadian Election Study.rds")
```

## Standard error of the mean

The standard error of the mean can be estimated as $\frac{s}{\sqrt{n}}$. In R we can use the function `MeanSE` from package `DescTools`:

```{r}
library(DescTools)
example_vector <- rnorm(20)  # Example data of 20 normally distributed random numbers.

MeanSE(x = example_vector, 
       na.rm = TRUE)
```

`MeanSE(…)`

:   This function calculates the standard error of the mean for a vector of numbers.

`x = example_vector`

:   We want to calculate the SE of the Mean for the values in `example_vector`. For your own data, you would change this to the appropriate vector name.

`na.rm = TRUE`

:   This option ensures that any missing values are ignored.

You can also use `MeanSE` for a variable in a data frame:

```{r}
# Using $ to select a variable from a data frame
MeanSE(canada$cps19_age, na.rm = TRUE)  

# Using function summarise
canada |>
  summarise(SE_age = MeanSE(cps19_age, na.rm = TRUE))
```

The `describe` function in package `psych` provides the Standard Error for the Mean for all variables in a data frame. It is particularly useful when we would like to quickly calculate the standard error for multiple variables. In this example we select three interval-ratio variables from the 2019 Canadian Election Study (which we imported above):

```{r}
library(psych)

# Select three variables from 'canada' and assign to dataset 'canada_selection'
canada_selection <- canada |> 
  select(cps19_age, cps19_lr_parties_1, cps19_lr_parties_2)

# Use describe to calculate summary statistics for 'canada_selection'
describe(canada_selection)

```

The column `se` displays the standard error of the mean (by default rounded to two decimals).

## T-tests

### One sample t-test

To calculate a one sample t-test we use the function `t.test`:

In the below example we measure whether the age of respondents is different from a hypothesized mean of 48.5:[^1]

[^1]: In this overview we use the co-called 'formula interface' to t.test. You can also use the so-called traditional interface. For the one-sample t-test example, the equivalent code is:

    ```{r}
    t.test(x = canada$cps19_age,
           alternative = "two.sided",
           mu = 48.5,
           conf.level = 0.95)
    ```

```{r}
t.test(formula = cps19_age ~ 1,
       data = canada,
       alternative = "two.sided",
       mu = 48.5,
       conf.level = 0.95)
```

`formula = cps19_age ~ 1`

:   As we have only one variable in a one sample t-test, we specify the formula in the form `<variable name> ~ 1`.

`data = canada`

:   We specify the data frame that we want to use.

`alternative = "two.sided"`

:   Determines whether we want to use a two sided-test, or a one-sided test. Options are "two.sided" (default), "less" (when $H_1: \mu < p$) or "greater" (when $H_1: \mu > p$).

`mu = 48.5`

:   The `mu` parameter should be set to the value of the mean *under the null hypothesis*.

`conf.level = 0.95`

:   This specifies the confidence level of the confidence interval reported. The default is 0.95 (a 95% confidence interval).

### Reporting a one-sample t-test

We illustrate the one-sample t-test using data on the fruit consumption of students. We test whether the fruit consumption is significantly different from a population value of 100.

*Example output R (do not include the output directly in an academic paper):*

```{r, echo=FALSE, include =FALSE}
fruit <- import("docs/s1_hhoorcollege_3 fruitconsumption.csv")
```


```{r, echo = TRUE, include = TRUE}
MeanSE(fruit$fruitconsumption)

t.test(x = fruit$fruitconsumption,
           alternative = "two.sided",
           mu = 100,
           conf.level = 0.95)
```

<!-- *Example output SPSS (do not include the output directly in an academic paper):* -->

<!-- ![](docs/spss_one_sample_ttest.png) -->

::: callout-note
#### Output explanation

* In R, the output shows:
  + the mean of the observations in the sample (see 'mean of x').
  + the calculated t-value (see 't = ').
  +  the degrees of freedom (see 'df = ').
  + the p-value (i.e. the probability of finding the obtained t-value, given the null hypothesis).
  + the expected value under the null hypothesis (here 100, see "true mean is not equal to 100").
  + the standard error of the observations in the sample is obtained separately via `MeanSE()`.


<!-- In SPSS, the information is presented in two tables.  -->

<!-- * In the table 'One-Sample Statistics', we find -->
<!--   +the mean of the observations in the sample (see cell 'Mean'). -->
<!--   +the standard error (see cell 'Std. Error Mean'). -->
<!-- * In the SPSS table 'One-Sample Test', we find -->
<!--   +the calculated t-value (see cell 't'). -->
<!--   +the degrees of freedom (see cell 'df'). -->
<!--   +the p-value (i.e. the probability of finding the obtained t-value, given the null hypothesis. -->
<!--   +the expected value under the null hypothesis (here 100, see "Test Value = 100"). -->

:::

#### Reporting

The correct report includes:

* A conclusion about the null hypothesis; followed by
* the mean (in the text or as M = ...) and the standard error (SE = ...) of the sample.
* t(degrees of freedom)
* p = p-value. When working with statistical software, you should report the exact p-value that is displayed. 
  + in  R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p < 0.001 in your report.
  <!-- + in  SPSS, very small p-values may be displayed as p=0.000. However, never write p=0.000 in your report. This is simply the way SPSS displays very small p-values < 0.0005. In these cases, write p < 0.001 in your report. -->

* If you calculate the t-value by hand you would write p < / = / > your chosen $\alpha$-level.

::: callout-tip
#### Report

✓ The mean fruit consumption of students was 90 (SE = 1.71). This is significantly different from the mean fruit consumption of the whole population (t(33) = -5.83, p < 0.001). 
:::

Below you find an example of a non-significant result. In this case we test whether the fruit consumption is significantly different from a population value of 92.

*Example output R (do not include the output directly in an academic paper):*

```{r, echo = TRUE, include = TRUE}
MeanSE(fruit$fruitconsumption, na.rm = TRUE)

t.test(x = fruit$fruitconsumption,
           alternative = "two.sided",
           mu = 92,
           conf.level = 0.95)
```

<!-- *Example output SPSS (do not include the output directly in an academic paper):* -->

<!-- ![](docs/spss_one_sample_ttest_2.png) -->

::: callout-tip
#### Report

✓ The mean fruit consumption of students was 90 (SE = 1.71). This is not significantly different from the mean fruit consumption of the whole population (t(33) = -1.167, p = 0.252). 
:::

### Paired samples t-test

In a paired samples t-test we compare the mean value of two interval-ratio variables.

In the below example we test the null hypothesis that the mean difference of the left-right placement of the Liberal party (variable `cps_lr_parties_1`) and the Conservative party (variable `cps19_lr_parties_2`) is equal to 0 in the population.

We can specify the test as follows:[^2]

[^2]: In this overview we use the co-called 'formula interface' to t.test. You can also use the so-called traditional interface. For the paired samples t-test example, the equivalent code is:

    ```{r}
    t.test(x = canada$cps19_lr_parties_1, 
           y = canada$cps19_lr_parties_2,
           data = canada,
           alternative = "two.sided",
           mu = 0,
           paired = TRUE,
           conf.level = 0.95)
    ```

    In this case, do not forget to include `paired = TRUE`.

```{r}
t.test(formula = Pair(cps19_lr_parties_1, cps19_lr_parties_2) ~ 1,
       data = canada,
       alternative = "two.sided",
       mu = 0,
       conf.level = 0.95)
```

`formula = Pair(cps19_lr_parties_1, cps19_lr_parties_2) ~ 1`

:   We have two paired interval-ratio variables and therefore use a formula in the form `Pair(<variable name 1>, <variable name 2>) ~ 1`

`data = canada`

:   We specify the data frame that we want to use.

`alternative = "two.sided"`

:   Determines whether we want to use a two sided-test, or a one-sided test. Options are "two.sided" (default), "less" (when $H_1: \mu < p$) or "greater" (when $H_1: \mu > p$).

`mu = 0`

:   The `mu` parameter should be set to the value of the mean *under the null hypothesis*. In the case of a paired sample t-test we usually hypothesize that the difference between the two means is 0 in the population, thus `mu = 0`.

`conf.level = 0.95`

:   This specifies the confidence level of the confidence interval of the difference. The default is 0.95 (a 95% confidence interval).

### Reporting a paired samples t-test

In a paired samples t-test we compare the mean value of two interval-ratio variables. In the below example we test the null hypothesis that the mean difference of the left-right placement of the Liberal party (variable `cps_lr_parties_1`) and the Conservative party (variable `cps19_lr_parties_2`) is equal to 0 in the population.

```{r, include = FALSE}
canada <- import("docs/2019 Canadian Election Study.rds")

sel.canada <- canada %>% 
  select(cps19_lr_parties_1, cps19_lr_parties_2)

export(sel.canada, "docs/2019 Canadian Election Study Sel.csv")
```

```{r, echo = TRUE, include = TRUE}
library(dplyr)
# Calculate the standard error of the mean for both variables, excluding missing observations
MeanSE(canada$cps19_lr_parties_1, na.rm = TRUE)
MeanSE(canada$cps19_lr_parties_2, na.rm = TRUE)

t.test(x = canada$cps19_lr_parties_1, 
           y = canada$cps19_lr_parties_2,
           data = canada,
           alternative = "two.sided",
           mu = 0,
           paired = TRUE,
           conf.level = 0.95)
```
<!-- *Example output SPSS (do not include the output directly in an academic paper):* -->

<!-- ![](docs/spss_paired_sample_ttest.png) -->

::: callout-note
#### Output explanation

* In R, the output shows:
  +the mean difference of the observations in the sample (see 'mean difference').
  +the calculated t-value (see 't = ').
  +the degrees of freedom (see 'df = ').
  +the p-value (i.e. the probability of finding the obtained t-value, given the null hypothesis), see p-value < 2.2e-16. This is a very small number which is why R displays it like this.
  +the expected value under the null hypothesis (here true mean difference is not equal to 0).
  +the standard errors of both variables in the sample are obtained separately via `MeanSE()`.

<!-- In SPSS, the information is presented in two tables. The middle table (Paired Samples Correlations) can be ignored for now. -->

<!-- * In the table 'Paired Samples Statistics', we find -->
<!--   +the means of the variables in the sample (see cells 'Mean'). -->
<!--   +the standard errors (see cells 'Std. Error Mean'). -->
<!-- * In the SPSS table 'Paired Samples Test', we find -->
<!--   +the mean of the paired differences (see cell 'Mean'). -->
<!--   +the standard deviation of the paired differences (see cell 'Std. Deviation'). -->
<!--   +the calculated t-value (see cell 't'). -->
<!--   +the degrees of freedom (see cell 'df'). -->
<!--   +the p-value (i.e. the probability of finding the obtained t-value, given the null hypothesis. -->

:::


#### Reporting

The correct report includes:

* A conclusion about the null hypothesis;
* the mean (in the text or as M = ...) and the standard error (SE = ...) of each variable.
* The difference in the means (here -2.637337),
* the degrees of freedom
* p = p-value. When working with statistical software, you should report the exact p-value that is displayed. 
  + in R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p < 0.001 in your report.
  <!-- + in SPSS, very small p-values may be displayed as p=0.000. However, never write p=0.000 in your report. This is simply the way SPSS displays very small p-values < 0.0005. In these cases, write p < 0.001 in your report. -->

If you calculate the results by hand you write p < “the chosen α-value”, for example, p < 0.05.

::: callout-tip
#### Report

✓ The left-right placement of the Liberal party (M = 4.25; SE = 0.017) was lower than the left-right placement of the Conservative party (M = 6.88; SE = 0.017). This difference, -2.64, was statistically significant, t(26718) = -95.406, p < 0.001.
:::

### Independent-samples t-test

The independent samples t-test is used to compare whether the means of two groups are statistically significantly different. We thus have a numeric variable, for which we can calculate a mean, and a grouping variable, which is a categorical variable that determines the group membership. In our example we test whether there is a statistically significant difference in the mean placement of the Liberal party by those who are born in Canada and those who are not.

First we inspect the grouping variable:

```{r}
table(canada$cps19_bornin_canada)
```

It turns out this variable has three categories. We would like to ignore the Don't know category, so we treat this as missing:

```{r}
canada <- canada |>
  mutate(cps19_bornin_canada = na_if(cps19_bornin_canada, "Don't know/ Prefer not to say")) 
```

Now we can run the t-test:

```{r, eval=FALSE}
t.test(formula = cps19_lr_parties_1 ~ cps19_bornin_canada,
       data = canada,
       alternative = "two.sided", 
       mu = 0,
       conf.level = .95)
```

`formula = cps19_lr_parties_1 ~ cps19_bornin_canada`

:   We have one interval-ratio variable and one categorical variable (factor) that captures to which group an observation belongs, thus we use a formula of the form `<interval-ratio variable> ~ <categorical variable>`.

`data = canada`

:   We specify the data frame that we want to use.

`alternative = "two.sided"`

:   Determines whether we want to use a two sided-test, or a one-sided test. Options are "two.sided" (default), "less" (when $H_1: \mu < p$) or "greater" (when $H_1: \mu > p$).

`mu = 0`

:   The `mu` parameter should be set to the value of the mean *under the null hypothesis*. In the case of an independent samples t-test we usually hypothesize that the difference between the two group means is 0 in the population, thus `mu = 0`.

`conf.level = 0.95`

:   This specifies the confidence level of the confidence interval of the difference. The default is 0.95 (a 95% confidence interval).

```{r, echo=FALSE}
t.test(formula = cps19_lr_parties_1 ~ cps19_bornin_canada,
       data = canada,
       mu = 0,
       alternative = "two.sided", 
       conf.level = .95)
```

R displays the result for the Welch Two Sample t-test, which is a version of the independent samples t-test that applies when equal variances are not assumed.

### Reporting an independent samples t-test

The independent samples t-test is used to compare whether the means of two groups are statistically significantly different. We use data on the number of gym attendances last month of male and female respondents.

*Example output R (do not include the output directly in an academic paper):*

```{r, echo=FALSE, include =FALSE}
#set.seed(2022)
#gender <- c(rep('Male', 1010), rep('Female', 970))  
#gym_attendance <- c(rpois(n = 1010, lambda = 4), rpois(n = 970, lambda = 3))
#gym <- as.data.frame(cbind(gender, gym_attendance))
#gym$gym_attendance <- as.numeric(gym$gym_attendance)
#gym$gender <- as.factor(gym$gender)
#export(gym, "docs/gym.csv")

gym <- import("docs/gym.csv")
```


```{r, echo=TRUE, include = TRUE}
library(dplyr)

# Calculate the standard error of the mean per group, dropping missing values. 
#These values (mean and standard error) are needed for the report.

gym %>%                               # Summary by group using dplyr
  group_by(gender) |>  
  summarize(mean = mean(gym_attendance), na.rm = TRUE,
            se = MeanSE(gym_attendance), na.rm = TRUE)

t.test(formula = gym_attendance ~ gender,
       data = gym,
       alternative = "two.sided", 
       mu = 0,
       conf.level = .95)
```

<!-- *Example output SPSS (do not include the output directly in an academic paper):* -->

<!-- ![](docs/spss_ind_sample_ttest.png) -->

::: callout-note
#### Output explanation

* In R, the output shows:
  +the means of the variables (see 'sample estimates').
  +the calculated t-value (see 't = ').
  +the degrees of freedom (see 'df = ').
  +the p-value (i.e. the probability of finding the obtained t-value, given the null hypothesis).
  +the expected value under the null hypothesis (here true mean difference is not equal to 0).
  +the mean of both groups is obtained separately via `mean()`.  
  +the standard errors of both groups in the sample are obtained separately via `MeanSE()`.

<!-- In SPSS, the information is presented in two tables.  -->
<!-- * In the table 'Group Statistics', we find -->
<!--   +the means of the variables (see cells 'Mean'). -->
<!--   +the standard errors (see cells 'Std. Error Mean'). -->
<!-- * In the SPSS table 'Independent Samples Test', we find two rows. The recommendation is to ignore Levene’s test in the lower table and always look at the lowest row (‘Equal variances not assumed’) for reporting. This is Welch’s t-test. -->
<!--   +the difference between the group means (see cell 'Mean Difference'). -->
<!--   +the standard deviation of the difference between the group means (see cell 'Std. Deviation Difference'). -->
<!--   +the calculated t-value (see cell 't'). -->
<!--   +the degrees of freedom (see cell 'df'). -->
<!--   +the p-value (i.e. the probability of finding the obtained t-value, given the null hypothesis, see cell 'Sig. (2-tailed)') -->

:::


#### Reporting

The correct report includes:

* A conclusion about the null hypothesis;
* the mean (in the text or as M = ...) and the standard error (SE = ...) of each variable,
* The difference in means (here 0.972),
* the degrees of freedom,
* p = p-value. When working with statistical software, you should report the exact p-value that is displayed. 
  + in R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p < 0.001 in your report.
  <!-- + in SPSS, very small p-values may be displayed as p=0.000. However, never write p=0.000 in your report. This is simply the way SPSS displays very small p-values < 0.0005. In these cases, write p < 0.001 in your report. -->

::: callout-tip
#### Report

✓ The number of gym attendances of men last month (M = 3.97; SE = 0.063) was higher than the number of gym attendances of women last month (M = 3.00; SE = 0.054). This difference, 0.972, was statistically significant, t(1944.363) = 11.674, p < 0.001.
:::

## Effect sizes for t-tests

We can calculate Cohen's $d$ or Hedges' $g^*_s$ as an effect size measure for a t-test. We are using function `cohens_d` and `hedges_g` from package `effectsize`.

### Cohen's $d$ for one sample

We are using function `cohens_d` from package `effectsize`. The parameters are pretty much the same as for the function `t.test`:

```{r}
library(effectsize)
cohens_d(cps19_age ~ 1, 
         data = canada, 
         mu = 48.5)
```

`cps19_age ~ 1`

:   This is the formula used for a single sample mean. In this case specify the formula in the form `<variable name> ~ 1`.

`data = canada`

:   We specify the data frame that we are using. Replace with your own data frame name.

`mu = 48.5`

:   We specify the value of the population mean under the null hypothesis. It is very important to specify this. If omitted, mu is set to 0 and this will often not be appropriate, especially for a one sample test.

### Cohen's d for paired samples

We are using function `cohens_d` from package `effectsize`. The parameters are pretty much the same as for the function `t.test`:

```{r}
library(effectsize)
cohens_d(Pair(cps19_lr_parties_1, cps19_lr_parties_2) ~ 1, 
         data = canada, 
         mu = 0)
```

`Pair(cps19_lr_parties_1, cps19_lr_parties_2) ~ 1`

:   We have two paired interval-ratio variables and therefore use a formula in the form `Pair(<variable name 1>, <variable name 2>) ~ 1`.

`data = canada`

:   We specify the data frame that we want to use.

`mu = 0`

:   The `mu` parameter should be set to the value of the mean *under the null hypothesis*. In the case of a paired sample t-test we usually hypothesize that the difference between the two variables is 0 in the population, thus `mu = 0`.

### Hedges' $g^*_s$ for independent samples

For two independent samples, we recommend calculating Hedges $g^*_s$ as effect size measure ([Delacre et al. 2021](https://doi.org/10.31234/osf.io/tu6mp)). Its interpretation is similar to Cohen's $d$, but bias-corrected and adapted to a situation when equal variances cannot be assumed. The values are very similar to Cohen's $d$ for larger samples.

Note that for our example we use the modified version of variable `cps19_bornin_canada` (see [Independent-samples t-test]):

```{r}
library(effectsize)
hedges_g(cps19_lr_parties_1 ~ cps19_bornin_canada, 
         data = canada, 
         mu = 0,
         pooled_sd = FALSE)
```

`cps19_lr_parties_1 ~ cps19_bornin_canada`

:   We have one interval-ratio variable and one categorical variable (factor) that captures to which group an observation belongs, thus we use a formula of the form `<interval-ratio variable> ~ <categorical variable>`.

`data = canada`

:   We specify the data frame that we want to use.

`mu = 0`

:   The `mu` parameter should be set to the value of the mean *under the null hypothesis*. In the case of an independent samples t-test we usually hypothesize that the difference between the two group means is 0 in the population, thus `mu = 0`.

`pooled_sd = FALSE`

:   This specifies that we do not use the pooled standard deviation, which is recommended when using Welch' t-test (not assuming variances are equal), which `t.test` does by default for the independent samples t-test.

### Reporting measures of association for t-tests

#### Cohen's d

Cohen's d, or standardized mean difference, is one of the most common ways to measure effect size for t-tests. There are different ways to calculate it, depending on the type of t-test but the reporting is the same. Here, I show Cohen's d based on the one-sample t-test above.

*Example output R (do not include the output directly in an academic paper):*

```{r, echo=FALSE, include =FALSE}

```


```{r, echo=TRUE, include =TRUE, warning = FALSE}
MeanSE(fruit$fruitconsumption, na.rm = TRUE)

t.test(x = fruit$fruitconsumption,
           alternative = "two.sided",
           mu = 100,
           conf.level = 0.95)

library(effectsize)
cohens_d(fruitconsumption ~ 1, 
         data = fruit, 
         mu = 100)
```

<!-- *Example output SPSS (do not include the output directly in an academic paper):* -->

<!-- ![](docs/spss_effect_ttest.png) -->

<!-- ::: callout-note -->
<!-- #### Output explanation -->

<!-- In SPSS, the value for Cohen's d is shown in the cell 'Point Estimate'. -->
<!-- ::: -->

::: callout-warning
#### Interpretation
The Cohen's d value range is from -∞ to +∞ and values can therefore be negative. If d is negative, it simply means that the group mean of the sample (or in the case of the paired/independent sample t-test the first group) is lower than the group of mean of population (or in the case of the paired/independent sample t-test the second group).

A Cohen's d of 1 means that the difference between the sample mean and hypothesized population mean is 1 standard deviation. A Cohen's d of 0.5 means that the difference between the sample mean and hypothesized mean is 0.5 standard deviations (half a standard deviation).

The following rule of thumbs are often applied for interpreting Cohen's d:

-   A value of at least **0.2** represents a **small** effect size.

-   A value of at least **0.5** represents a **medium** effect size.

-   A value of at least **0.8** represents a **large** effect size.

As always with rules of thumbs, be careful and consider the type of data that you are working with.
:::

#### Reporting

If you have calculated Cohen’s d for a t-test, you can add it to the report:

::: callout-tip
#### Report

✓ The mean fruit consumption of students was 90 (SE = 1.71). This is not significantly different from the mean fruit consumption of the whole population (t(33) = -1.167, p = 0.252). This represents a large difference, d = -1.00.
:::


#### Hedges' $g^*_s$ for independent samples

Cohen's d and Hedges $g^*_s$ are largely comparable, but Hedges modification is considered more robust for small samples.

*Example output R (do not include the output directly in an academic paper):*

```{r, echo=FALSE, include =FALSE}

```


```{r, echo=TRUE, include =TRUE, warning = FALSE}
MeanSE(fruit$fruitconsumption, na.rm = TRUE)

t.test(x = fruit$fruitconsumption,
           alternative = "two.sided",
           mu = 100,
           conf.level = 0.95)

library(effectsize)
hedges_g(fruitconsumption ~ 1, 
         data = fruit, 
         mu = 100)
```

<!-- *Example output SPSS (do not include the output directly in an academic paper):* -->

<!-- ![](docs/spss_effect_ttest.png) -->

<!-- ::: callout-note -->
<!-- #### Output explanation -->
<!-- In SPSS, the value for Hedges' $g_s^*$ is shown in the cell 'Point Estimate'. -->
<!-- ::: -->

::: callout-warning
#### Interpretation

The interpretation of Hedges' $g_s^*$ is similar to Cohen's D. A Hedges' $g_s^*$ of 1 means that the difference between the two sample means is 1 standard deviation. A Hedges' $g_s^*$ of 0.5 means that the difference between the two sample means is 0.5 standard deviations (half a standard deviation).

The following rule of thumbs are often applied for interpreting Cohen's d and Hedges' $g_s^*$:

-   A value of at least **0.2** represents a **small** effect size.

-   A value of at least **0.5** represents a **medium** effect size.

-   A value of at least **0.8** represents a **large** effect size.

As always with rules of thumbs, be careful and consider the type of data that you are working with.
:::

#### Reporting

The Hedges' $g_s^*$ effect size is often included after the independent samples t-test, for example:

::: callout-tip
#### Report

✓ The mean fruit consumption of students was 90 (SE = 1.71). This is not significantly different from the mean fruit consumption of the whole population (t(33) = -1.167, p = 0.252). This represents a large difference, $g_s^*$ = -0.98.
:::