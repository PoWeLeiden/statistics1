[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical analysis and presentation using R",
    "section": "",
    "text": "Preface\nThis book presents the R materials related to the course Statistics I.\nWe have divided the book into two parts:\nThis part also provides general guidelines on how to present and correctly report the output from statistical analyses. For different tests or measures of association, you will find the output from the statistical software as well as additional information:",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#overview-per-week",
    "href": "index.html#overview-per-week",
    "title": "Statistical analysis and presentation using R",
    "section": "Overview per week",
    "text": "Overview per week\nFor each week in the course, you need to read relevant chapters in both sections. In 2023-2024 this is:\n\n\n\n\n\n\n\n\nWeek\nWorking with data in R\nStatistical analysis in R\n\n\n\n\n1\n1  Working with R and RStudio: the basics, paragraph 1 to 7\n7  Measures of central tendency and dispersion\n\n\n2\n1  Working with R and RStudio: the basics, paragraph 8\n8  Graphing using ggplot2, 9  Tables and 10  Probability in R\n\n\n3\n2  Filtering, selecting & renaming\n11  Normal distribution and 12  Inference for proportions, paragraph 1 and 2\n\n\n4\n3  Creating, summarising & recoding variables and 4  Missing data\n12  Inference for proportions\n\n\n5\n5  Advanced recoding of variables\n13  Chi-squared and measures of association\n\n\n6\n-\n14  T-tests for means\n\n\n7\n6  Combining & joining data sets\n15  Power analysis and 16  ANOVA",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "part_working_data.html",
    "href": "part_working_data.html",
    "title": "Working with data in R",
    "section": "",
    "text": "This section of the materials focuses on working with data in R. You will learn how to:\n\nBasics of using R and RStudio\nRead/import data into R\nCreate data in R\nModify data in R",
    "crumbs": [
      "Working with data in R"
    ]
  },
  {
    "objectID": "data_01_basics.html",
    "href": "data_01_basics.html",
    "title": "1  Working with R and RStudio: the basics",
    "section": "",
    "text": "1.1 Interacting with the console: Using R as a calculator\nR can be used as a powerful calculator. You can simply enter equations directly at the prompt in the command console (the window with the &gt; symbol). Simply type your arithmetic expression and press ENTER on Windows keyboards and RETURN on Mac keyboards. R will evaluate the expressions and respond with the result.\nFor simple arithmetic expressions, the operators R uses are:\n+    Addition\n-    Subtraction\n*    Multiplication\n/    Division\n^    Exponentiation",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Working with R and RStudio: the basics</span>"
    ]
  },
  {
    "objectID": "data_01_basics.html#interacting-with-the-console-using-r-as-a-calculator",
    "href": "data_01_basics.html#interacting-with-the-console-using-r-as-a-calculator",
    "title": "1  Working with R and RStudio: the basics",
    "section": "",
    "text": "1.1.1 Using parentheses\nIf you want to add 6 and 3, then multiply the result by 2, you need to add parentheses. This imposes an order for the calculation of the result (i.e. first add 6 and 3 and then divide by 2). In the case of this example, you could enter\n\n(6 + 3) * 2\n\n[1] 18\n\n\nThis will return the result 18.\n\n\n1.1.2 More complex equations\nYou can write more complex expressions that use parentheses and operators.\nThe order of operations can be remembered by the acronym PEMDAS, which stands for: parentheses, exponents, multiplication and division from left to right, and addition and subtraction from left to right. Take the following equation:\n\\[\n\\frac{18 * 4^2 - (4+2)}{3}\n\\]\nYou enter this in the RStudio command console as follows:\n\n(18*4^2-(5+4))/3\n\n[1] 93\n\n\nNotice how you can control the order of evaluation by using parentheses.\n\nInternally, R first calculates 18*4^2 (= 288). It follows the rules outlined above (PEMDAS), so there is no need to put a parenthesis around 4^2. Exponents are calculated before multiplication so we do not need to specify this via a parenthesis.\nFrom this we subtract 5+4 (288-9 = 279).\nFinally, we divide by 3.\n\nThis returns:\n\n[1] 93",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Working with R and RStudio: the basics</span>"
    ]
  },
  {
    "objectID": "data_01_basics.html#base-r-and-additional-packages",
    "href": "data_01_basics.html#base-r-and-additional-packages",
    "title": "1  Working with R and RStudio: the basics",
    "section": "1.2 ‘base’ R and additional packages",
    "text": "1.2 ‘base’ R and additional packages\nWhen you download R from the Comprehensive R Archive Network (CRAN), you get the ‘base’ R system. This software contains basic functionality and implements the R language. However, one of the reasons why R is so useful is the large collection of additional packages that extend the basic functionality of R. R packages are developed and published by the larger R community. There are thousands of packages available covering a wide range of topics.\nThe primary location for obtaining R packages is CRAN. There are some additional locations but you do not have to worry about this for now.\n\n1.2.1 Installing and loading an R Package\nTo install a package, you use the install.packages() function and then write the name of the package. You must include quotation marks around the name of the package, i.e. install.packages(\"&lt;the package's name&gt;\"). For example, if you want to install the package ‘rio’ (an R package which makes data import and export in R very quick), you write:\n\ninstall.packages(\"rio\")\n\nR will automatically install everything it needs. Once you have installed a package, it remains on your laptop. Therefore, installing an R package only needs to be done once (until you install R again).\n\nPlease note: Packages that are needed for this course are pre-installed on all PCs at Leiden University. Therefore, this step can be skipped when you work on PCs at the university and you can simply load them (see next step). If you use your own laptop, you must first install the package.\n\nInstalling a package does not make it immediately available to you in R. Before you can use the package and the functions that come with it, you must load it into R. To load packages into R, the library() function is used. When loading a package, you do not use quotation marks. To load the ‘rio’ package into R, you would write:\n\nlibrary(rio)\n\nIf you try and load a package that is not installed, you get an error (‘Error in library(rio) : there is no package called 'rio'’).",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Working with R and RStudio: the basics</span>"
    ]
  },
  {
    "objectID": "data_01_basics.html#r-scripts",
    "href": "data_01_basics.html#r-scripts",
    "title": "1  Working with R and RStudio: the basics",
    "section": "1.3 R scripts",
    "text": "1.3 R scripts\nThe console window (in RStudio, the bottom left panel) is the place where you can type commands directly into the console, but they will be forgotten when you close the session.\nOften, we do not simply want to work in the console but we want to keep our commands and save them. A common way to do this is to work in an R script. This is a text file that contains all commands that you would enter on the command line of R. This keeps everything nicely organized.\nIt is easy to create a new script in RStudio. We can use the menu (“File” → “New File” → “R Script”) or with the keyboard shortcut “Command+Shift+N” on a Mac or “Ctrl+Shift+N” on Windows and Linux. Afterwards, the editor appears as a new pane in the top left of the RStudio window.\nYou can write all commands that are needed for your project. For example, we could write these three lines:\n\nprint(\"This is my first R script\")\n1+1\n17-8*2\n\n\n1.3.1 Annotating R scripts\nYou can add comments by annotating the R Script. Annotating it will make it much easier for yourself or people you collaborate with. You can use the symbol # to start an annotation. When you run a command, R will ignore everything after this symbol. Going back to my earlier example, assume you want to add a comment after the formula then you can write:\n\n(18*4^2-(5+4))/3 #This is a nice formula.\n\n\n\n1.3.2 Executing code in R scripts\nTo run a command in an R script, you have several options:\n\nPut the cursor on the line of the command and then click the ‘Run’ button at the top of the file window.\nPut the cursor on the line of the command and press CTRL + ENTER on Windows PCs or COMMAND + ENTER on Mac.\nYou can also select the whole line and press ‘Run’ or CTRL + ENTER). Note that if you do this you have to select the whole line. Otherwise, R will only execute the part of the command that you have highlighted.\n\n\n\n\nRMarkdown Visual Mode 1\n\n\nAfter you pressed ‘Run’ or CTRL + ENTER, R will execute the command.\nIf you have added an annotation (see above), R but will exclude the text behind #.\nYou can run of course run multiple lines. For example, if your R Script contains these three commands:\n\nprint(\"This is my first R script\")\n1+1\n17-8*2\n\nYou can select everything that you want to execute (i.e. the whole text or the first two lines, etc.) with your mouse cursor and then click the ‘Run’ button at the top of the file window or press CTRL + ENTER on Windows PCs or COMMAND + ENTER on Mac.\n\n\n1.3.3 Saving / Opening an existing R script\nYou can save your script by clicking on File &gt; “Save as…” or by clicking the Save icon at the top of the Script Editor panel. When you do that, a Save File option menu will open. Give the R script an informative name, so you can find it when you want to open it later. You can open an existing R script via File &gt; “Open file…”",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Working with R and RStudio: the basics</span>"
    ]
  },
  {
    "objectID": "data_01_basics.html#r-markdown-file",
    "href": "data_01_basics.html#r-markdown-file",
    "title": "1  Working with R and RStudio: the basics",
    "section": "1.4 R Markdown file",
    "text": "1.4 R Markdown file\nAnother common format is the R Markdown file. An R Markdown document is written in an easy-to-write plain text format and contains chunks of embedded R code. The great thing about R Markdown is that you can include code chunks (and in-line code) to report output and statistical analysis.\nOnce you export it, you can turn your text into high quality documents, reports, presentations and dashboards. This document, for example, is an R Markdown file.\n\nRStudio will automatically install the required rmarkdown package and load it when necessary.\n\n\n1.4.1 Editing R Markdown files\nFor now, you do not have to know how to create R Markdown files. However, we will use them throughout the course for exercises and assignments so you need to know how to work in them.\nR Markdown files have the .Rmd extension. Once you click on them, R Studio should open them. If it does not, you can open them via “File” → “Open File”. When you first open them, they will look like an R Script (with some colored code). It is easier to work in them using the ‘Visual’ mode. On Windows PCs you can switch to this mode via ‘CTRL + SHIFT + F4’. On Apple Macs you can switch to this mode via ‘COMMAND ⌘ + SHIFT + F4’. You can also click on the button ‘Visual’.\n\n\n\nRMarkdown Visual Mode 1\n\n\nTo execute code, you can select the code and press ‘CTRL + ENTER’ or, alternatively, click on the little green arrow.\n\n\n\nRMarkdown Visual Mode 2\n\n\nYou can also change the code and add new code in the field.\n\n\n\nRMarkdown Visual Mode 3\n\n\nOnce you execute the code, R will display the results.\n\n\n1.4.2 ‘Knitting’ an R Markdown file\nYou can transform your markdown file into an HTML, PDF, or Word document that you can upload on Brightspace. To do this, click the Knit icon that appears above your file in the scripts editor. After this, a document will be generated that includes both content as well as the output of any embedded R code chunks within the document.\n\n\n\nKnit button\n\n\nYou can save your .Rmd file with “File” → “Save File As…”.",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Working with R and RStudio: the basics</span>"
    ]
  },
  {
    "objectID": "data_01_basics.html#setting-up-an-r-project",
    "href": "data_01_basics.html#setting-up-an-r-project",
    "title": "1  Working with R and RStudio: the basics",
    "section": "1.5 Setting up an R Project",
    "text": "1.5 Setting up an R Project\nWhen you work with R, you will likely have several files related to what you are working on: a file with the data set, a file with your R script (or R Markdown file) and perhaps some output that you save. To keep track of all the files related to a project, we recommend setting up an R Project.\n\nClick “File” → “New Project”\nClick “New directory” and then “New Project”\nEnter your project name under ‘Directory name’ and specify in which folder the project will be located by clicking ‘Browse’ and selecting a folder. Then click ‘Create Project’\n\n\n\n\nSetting up a Project in RStudio\n\n\nR will now create the project and open the folder in the Files view at the bottom of the project.\nSet up a Project for this course, and save all assignment, exercises and data files for this course in the project folder/directory.\nUsing File → Open Project you can open an existing project and continue working on it.",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Working with R and RStudio: the basics</span>"
    ]
  },
  {
    "objectID": "data_01_basics.html#manually-entering-data-into-r",
    "href": "data_01_basics.html#manually-entering-data-into-r",
    "title": "1  Working with R and RStudio: the basics",
    "section": "1.6 Manually entering data into R",
    "text": "1.6 Manually entering data into R\nIn R, the main and most used way to enter data is the left-arrow operator (&lt;-). This assignment operator is used to assign a value.\nThe combination object &lt;- content means “assign the value of the result from the operation on the right hand side (‘content’) to the object on the left hand side (‘object’)”.\nR can also deal with other assignment operators but my suggestion is to stick with the &lt;- operator. This is the most conventional assignment operator used and is what you will find in all the base R source code.\n\n1.6.1 Storing data in an object\nR can deal with many different input forms (text, numbers, dates, etc,). You can determine the types of data that will be stored in the object. Let us assume, I want to assign the numeric value 12 to an object called ‘my_first_variable’.\nWe create an object called ‘my_first_variable’ (note that you cannot have a space in the name) and assign one value (12) to it. To do this in R we use the symbols &lt;-. You write it like this:\n\nmy_first_variable &lt;- 12\n\nIf you then call ‘my_first_variable’ by selecting the text with our mouse cursor and pressing CTRL + ENTER then R will display the content of the object.\n\nmy_first_variable \n\n[1] 12\n\n\nIf we check the data type via class(), we can see that this is a ‘numeric’ object. This is used if the values are numbers or if the values contain decimals.\n\nclass(my_first_variable)\n\n[1] \"numeric\"\n\n\nAt this point, it is maybe good to note that R is a case sensitive programming language. Meaning all variables, functions, and objects must be called by their exact spelling. If you try and call the object ‘my_first_variable’ by writing ‘My_first_variable’ (note the capital ‘M’), R will not be able to find it.\nOf course, we can also enter decimal numerals. You must use a ‘dot’ as decimal separator for this:\n\nmy_second_variable &lt;- 6.521\nmy_second_variable \n\n[1] 6.521\n\n\nWhen we inspect this object we can see that it is again a ‘numeric’ object.\n\nclass(my_second_variable)\n\n[1] \"numeric\"\n\n\nWe can also store text. In R, text is termed as a ‘string’. A string is a piece of text that is represented as a sequence of characters (letters, numbers, and symbols). It can be made of one character or contains a collection of characters. Any value written within a pair of single quote or double quotes in R is treated as a string. It is more common to use doubles quotes (““) than single quotes (’‘) around the text. This will create a ’character’ variable.\n\na_text_variable &lt;- \"Hello, world\"\n\n\na_text_variable\n\n[1] \"Hello, world\"\n\n\nAs explained above, you can use double quotation marks or single quotation marks. While this will lead to the same outcome, I would recommend that you stick with double quotation marks.\n\na_text_variable &lt;- 'Hello, world'\na_text_variable\n\n[1] \"Hello, world\"\n\n\n\n\n1.6.2 Creating a vector\nSo far, our object only contains one value. If we want to store different values then we must create a vector. Vectors are essential objects in R. They are the building block for data frames which we will cover later. Let us create a numeric vector which contains all numbers from 1 to 5 and the value 8.5. To do this we use c() to indicate that a list of values is followed. The ‘c’ inc() stands for combine.\n\nmy_first_vector &lt;- c(1, 2, 3, 4, 5, 8.5)\nmy_first_vector\n\n[1] 1.0 2.0 3.0 4.0 5.0 8.5\n\n\nIf we check the data type via class(), we can see that this is a ‘numeric’ object. This is used if the values are numbers or if the values contain decimals.\n\nclass(my_first_vector)\n\n[1] \"numeric\"\n\n\nWe can also create a vector with text instead of numbers.\n\ncolor_vector &lt;- c(\"blue\", \"red\", \"green\", \"white\", \"black\", \"yellow\")\ncolor_vector\n\n[1] \"blue\"   \"red\"    \"green\"  \"white\"  \"black\"  \"yellow\"\n\n\nAs was stated above, R uses the data type ‘character’ when storing text. If we check the data type via class(), we can see that this is a ‘character’ object.\n\nclass(color_vector)\n\n[1] \"character\"\n\n\nCan we mix numbers and text? No. Vectors are limited to 1 type of data (i.e. you can store numbers or strings but not both). What happens if we mix numbers and strings?\n\nmixed_vector &lt;- c(1, \"red\", 3, \"white\", \"black\", 6)\n\nR creates the vector as instructed but automatically makes this a ‘character’ vector (see the double quotation marks when we call the vector and the ouput from class(mixed_vector)):\n\nmixed_vector\n\n[1] \"1\"     \"red\"   \"3\"     \"white\" \"black\" \"6\"    \n\nclass(mixed_vector)\n\n[1] \"character\"\n\n\n\n\n1.6.3 Creating variables in R\nNow that we know how to store data, we can use it to build categorical and continuous variables.\n\n1.6.3.1 Categorical data: Factors\nFor categorical data (nominal and ordinal data), we use a factor. Factors are used to categorize the data and store it as levels. They can store both characters and numbers (integers, decimals).\n\n1.6.3.1.1 Nominal data\nSuppose we have a nominal variable with directions. First we create a vector as input.\n\ndata &lt;- c(\"East\", \"West\", \"East\", \"North\", \"North\", \"East\", \"West\", \"West\", \"West\", \"East\", \"North\")\n\nSo far, this simply a sequence of strings. If we call the object ‘data’ then we get:\n\ndata\n\n [1] \"East\"  \"West\"  \"East\"  \"North\" \"North\" \"East\"  \"West\"  \"West\"  \"West\" \n[10] \"East\"  \"North\"\n\n\nTo inform R that this is a categorical variable we must specify that it is a factor. We can do this by adding factor() around the expression:\n\ndirections &lt;- factor(c(\"East\", \"West\", \"East\", \"North\", \"North\", \"East\", \"West\", \"West\", \"West\", \"East\", \"North\"))\n\nInternally, R stores these factors as integers (=whole numbers), and uses the strings as labels. If we call the object ‘directions’ now we get:\n\ndirections\n\n [1] East  West  East  North North East  West  West  West  East  North\nLevels: East North West\n\n\nAs you can see, R treats this now as as categorical (nominal) variable.\nWe can also get more information on the unique values of our factor by using levels():\n\nlevels(directions)\n\n[1] \"East\"  \"North\" \"West\" \n\n\nUsing strings for factors is preferred because we can use the labels for information. It is of course possible to use integers, i.e. 1 for ‘North’ 2 for ‘East’, 3 for ‘South’ and 4 for ‘West’. However, this can make it difficult to know what the numbers mean without checking which labels they represent. Therefore, I would advice you to use strings when you create your own factors.\n\n\n1.6.3.1.2 Ordinal factor levels in R\nThe previous example used a nominal variable (i.e. no clear ordering of the categories). Ordinal variables, on the other hand, have clear ordering of the categories. This could be values such as low, medium, and high. To do this, we create factors with inherent ordering of the categories by adding levels = c(), ordered = TRUE. For example, we can create a factor with temperature using “low”, “medium”, “high”.\n\ntemperature &lt;- factor(c(\"low\", \"high\", \"medium\", \"high\", \"low\", \"medium\", \"high\"), levels = c(\"low\", \"medium\", \"high\"), ordered = TRUE)\n\n\ntemperature\n\n[1] low    high   medium high   low    medium high  \nLevels: low &lt; medium &lt; high\n\n\n\n\n\n1.6.3.2 Interval / ratio variables\nInterval/ratio data can be coded as variables with numbers (whole numbers or decimals). To create a continuous variable, we can simply create a vector with integers or decimals:\n\nexam_points &lt;- c(2, 7, 3, 4, 2, 0)",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Working with R and RStudio: the basics</span>"
    ]
  },
  {
    "objectID": "data_01_basics.html#data-frames",
    "href": "data_01_basics.html#data-frames",
    "title": "1  Working with R and RStudio: the basics",
    "section": "1.7 Data frames",
    "text": "1.7 Data frames\nArguably one of the powerful and widely used data structures in R are data frames. Data frames have two dimensions and consist of multiple variables, one in each column. Each row represents one case about which we have information. This is a very simple example of a data frame:\n\n\n  stud_id stud_name grade\n1       1    Arnold   6.5\n2       2       Dan   5.5\n3       3       Ina   7.0\n4       4    George   9.0\n5       5    Sophie   8.5\n\n\nThis example data frame has information about five students (one per row). It contains three variables: Student ID (stud_id), their name (stud_name) and their grade (grade). So we have three columns.\nIt is possible to create a data frame by manually entering data, normally we will load a data frame from a file.\n\nYou may encounter the term tibble later on, which is essentially the same thing as a data frame.\n\n\n1.7.0.1 Viewing the data in RStudio\nOnce you have entered or loaded data, R studio displays this in the ‘Environment pane’ on the right. You can click the data frame name (student.data in our example) to inspect the data in a separate window.\n\n\n\nThe Environment pane\n\n\n\n\n1.7.0.2 Creating data frames from vectors\nYou can use the data.frame() function to combine individual vectors into a single data frame. This will combine your vectors into a single data frames: each vector will be in a separate column. Each row represents one case about which we have information. Below I create three vectors: one about the day of the week, one about the temperature of that day and a factor variable about the type of weather. Then I combine them into a data frame called ‘weather’. Note that we use factor() for the factor variable.\n\nday = c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\",\"Friday\")\ntemp = c(7, 5, 7, 8, 8)\ntype &lt;- factor(c(\"cloudy\", \"showers\", \"rainy\", \"cloudy\", \"rainy\"))\nweather &lt;- data.frame(day, temp, type)\n\nstr(weather)\n\n'data.frame':   5 obs. of  3 variables:\n $ day : chr  \"Monday\" \"Tuesday\" \"Wednesday\" \"Thursday\" ...\n $ temp: num  7 5 7 8 8\n $ type: Factor w/ 3 levels \"cloudy\",\"rainy\",..: 1 3 2 1 2\n\nweather\n\n        day temp    type\n1    Monday    7  cloudy\n2   Tuesday    5 showers\n3 Wednesday    7   rainy\n4  Thursday    8  cloudy\n5    Friday    8   rainy\n\n\n\nweather &lt;- data.frame(day, temp, type)\n\nThis creates a new data frame called ‘weather’ which combines the three vectors ‘day’, ‘temp’ and ‘type’. Replace the names of the data frame and the vectors by the name of your data.\n\nstr(weather)\n\nThis part of the code display the internal structure of the data frame.\n\n\n\n\n1.7.1 Inspecting the data\n\n1.7.1.1 The $ operator\nThe ‘dollar sign’ operator ($) is incredibly important when we work with data frames. First, it can be used to access variables in data frames. For example, we can look at the variable ‘grade’ by writing:\n\nstudent.data$grade\n\n[1] 6.5 5.5 7.0 9.0 8.5\n\n\nYou can also create new variables. For this, we use the operator ‘&lt;-’. Let us create a new variable in our ‘weather’ data frame which is a numeric variable about the humidity on that day.\n\nweather$humidity &lt;- c(71, 84, 89, 76, 85) \nweather\n\n        day temp    type humidity\n1    Monday    7  cloudy       71\n2   Tuesday    5 showers       84\n3 Wednesday    7   rainy       89\n4  Thursday    8  cloudy       76\n5    Friday    8   rainy       85\n\n\nMake sure that the number of observations of the new vectors is the same as the number of observations in the data frame. For example, below I try to add another variable about the wind speed. However, because this variable only has 4 observations, R will give an error:\n\nweather$wind &lt;- c(27, 14, 21, 18) #this vector has only 4 observations\n\nError in `$&lt;-.data.frame`(`*tmp*`, wind, value = c(27, 14, 21, 18)): replacement has 4 rows, data has 5\n\n\n\n\n1.7.1.2 head() and tail()\nIf you have a data frame with many observations, it can be helpful to print only the first few rows. Our example data set is small, but we can still use it to illustrate the use of the two functions:\n\nhead(student.data)\n\n  stud_id stud_name grade\n1       1    Arnold   6.5\n2       2       Dan   5.5\n3       3       Ina   7.0\n4       4    George   9.0\n5       5    Sophie   8.5\n\nhead(student.data, n = 3)\n\n  stud_id stud_name grade\n1       1    Arnold   6.5\n2       2       Dan   5.5\n3       3       Ina   7.0\n\ntail(student.data, n = 3)\n\n  stud_id stud_name grade\n3       3       Ina   7.0\n4       4    George   9.0\n5       5    Sophie   8.5\n\n\n\nhead(student.data)\n\nThis displays the first five rows of a data frame. Replace student.data by the name of the appropriate data frame.\n\nhead(student.data, n = 3)\n\nIf we specify n = … We can specify how many rows of data we would like to display, in this example 3 rows.\n\ntail(student.data, n = 3)\n\nTail displays the last n rows of data. If you leave out n = … it will display the last 5 rows of data.\n\n\n\n\n\n1.7.2 Loading data into R\nYou can import data into R for analysis and data manipulation (changing variable names, selecting cases, recoding the values of variables, etc.).\nUsing the import function from package rio, we can import various file formats into R, including Microsoft Excel files, CSV files, SPSS, Stata or R files:\nSuppose we want to open a comma-separated values (CSV) file. A .csv file is the most used file format for data storing. Our example file is called ‘deniro.csv’ (available here) which contains Rotten Tomato ratings of movies with Robert De Niro. There are 87 records. Each record has Year, Rating, Title.\n\nMake sure to save the file to your project folder, because that is where R will look for the file when you open it.\n\nYou can import this data set in R using the following code:\n\nlibrary(rio) \ndeniro_data &lt;- import(\"deniro.csv\") \n\n\nlibrary(rio)\n\nThis loads the package ‘rio’ into R. You only need to do this once at the start of your R session.\n\nimport(\"deniro.csv\")\n\nimport() is a function in the rio package that allows you to import files in almost any format. The function import() infers the file format from the file’s extension and calls the appropriate data import function for you, returning a simple data.frame\nIn this example we load a file called deniro.csv and save it to a data frame called deniro_data. You can specify any name you would like for a data frame.\n\n\n\nImportantly, if you include only a file name (here: deniro.csv), R will assume this file is located in your current working directory. If you are working in an R Project, this working directory is the same as your project folder.\n\nWe can now display the contents of this data frame:\n\nprint(deniro_data)\n\n   Year Score                                   Title\n1  1968    86                               Greetings\n2  1970    17                             Bloody Mama\n3  1970    73                                Hi, Mom!\n4  1971    40                             Born to Win\n5  1973    98                            Mean Streets\n6  1973    88                    Bang the Drum Slowly\n7  1974    97                  The Godfather, Part II\n8  1976    41                         The Last Tycoon\n9  1976    99                             Taxi Driver\n10 1977    47                                    1900\n11 1977    67                      New York, New York\n12 1978    93                         The Deer Hunter\n13 1980    97                             Raging Bull\n14 1981    75                        True Confessions\n15 1983    90                      The King of Comedy\n16 1984    89             Once Upon a Time in America\n17 1984    60                         Falling in Love\n18 1985    98                                  Brazil\n19 1986    65                             The Mission\n20 1987   100 Dear America: Letters Home From Vietnam\n21 1987    80                        The Untouchables\n22 1987    78                             Angel Heart\n23 1988    96                            Midnight Run\n24 1989    64                                Jacknife\n25 1989    47                         We're No Angels\n26 1990    88                              Awakenings\n27 1990    29                          Stanley & Iris\n28 1990    96                              Goodfellas\n29 1991    76                               Cape Fear\n30 1991    69                                Mistress\n31 1991    65                     Guilty by Suspicion\n32 1991    71                               Backdraft\n33 1992    87                            Thunderheart\n34 1992    67                      Night and the City\n35 1993    75                         This Boy's Life\n36 1993    78                       Mad Dog and Glory\n37 1993    96                            A Bronx Tale\n38 1994    39             Mary Shelley's Frankenstein\n39 1995    80                                  Casino\n40 1995    86                                    Heat\n41 1996    74                                Sleepers\n42 1996    38                                 The Fan\n43 1996    80                           Marvin's Room\n44 1997    85                             Wag the Dog\n45 1997    87                            Jackie Brown\n46 1997    72                                Cop Land\n47 1998    68                                   Ronin\n48 1998    38                      Great Expectations\n49 1999    69                            Analyze This\n50 1999    43                                Flawless\n51 2000    43    The Adventures of Rocky & Bullwinkle\n52 2000    84                        Meet the Parents\n53 2000    41                            Men of Honor\n54 2001    73                               The Score\n55 2001    33                              15 Minutes\n56 2002    48                         City by the Sea\n57 2002    27                            Analyze That\n58 2003     4                                 Godsend\n59 2004    35                              Shark Tale\n60 2004    38                        Meet the Fockers\n61 2005     4              The Bridge of San Luis Rey\n62 2005    46                                    Rent\n63 2005    13                           Hide and Seek\n64 2006    54                       The Good Shepherd\n65 2007    21               Arthur and the Invisibles\n66 2007    76                     Captain Shakespeare\n67 2008    19                          Righteous Kill\n68 2008    51                     What Just Happened?\n69 2009    46                        Everybody's Fine\n70 2010    72                                 Machete\n71 2010    10                          Little Fockers\n72 2010    50                                   Stone\n73 2011    25                            Killer Elite\n74 2011     7                          New Year's Eve\n75 2011    70                               Limitless\n76 2012    92                 Silver Linings Playbook\n77 2012    51                             Being Flynn\n78 2012    29                              Red Lights\n79 2013    46                              Last Vegas\n80 2013     7                         The Big Wedding\n81 2013    29                            Grudge Match\n82 2013    11                          Killing Season\n83 2014     9                             The Bag Man\n84 2015    60                                     Joy\n85 2015    26                                   Heist\n86 2015    61                              The Intern\n87 2016    11                           Dirty Grandpa\n\n\n\n\n1.7.3 Exporting a data frame\nTo save a data frame, we use the export() function. I will use it save our data frame with student scores from earlier:\n\nexport(student.data, \"student_scores.csv\")\n\n\nexport(student.data, \"student_scores.csv\")\n\nexport() is a function in the rio package that allows you to save files in different formats. In the bracket you specify the name of the data frame, followed by the name you wish to give it and the file extension (in this case a csv file).\n\n\n‘rio’ also supports the export into the native format of R which uses the .rds extension. To do this, we simply write:\n\nexport(student.data, \"student_scores.rds\")\n\nAfter this, we can simply import it again in the same way we did earlier:\n\nstudent_scores &lt;- import(\"student_scores.rds\")\n\n\nstudent_scores\n\n  stud_id stud_name grade\n1       1    Arnold   6.5\n2       2       Dan   5.5\n3       3       Ina   7.0\n4       4    George   9.0\n5       5    Sophie   8.5",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Working with R and RStudio: the basics</span>"
    ]
  },
  {
    "objectID": "data_01_basics.html#the-pipe-operator",
    "href": "data_01_basics.html#the-pipe-operator",
    "title": "1  Working with R and RStudio: the basics",
    "section": "1.8 The pipe operator",
    "text": "1.8 The pipe operator\nIn statistical analysis we often perform multiple operations on a data set or single variable. The pipe operator |&gt; is used to write cleaner code.\nThe pipe operator basically takes whatever is at its left hand side and inputs it as the first parameter at its right hand side. For example, if we have a vector x:\n\nx = c(1,2,3,4,5)\n\nYou know that we can calculate the mean of x as follows:\n\nmean(x)\n\n[1] 3\n\n\nWe can also use the pipe operator to perform this operation:\n\nx |&gt; mean()\n\n[1] 3\n\n\nYou can read this code as ‘take x and put it as the first argument of the function mean’.\nThis example is of course trivial (and normally you would simply use mean(x)), but the nice thing about the pipe operator is that we can perform multiple operations in sequence, for example:\n\nx |&gt; \n  sqrt() |&gt; \n  mean()\n\n[1] 1.676466\n\n\nIn this example we take x, calculate the square root for each element of x and then take the mean of this. It is the same as writing mean(sqrt(x)) . The pipe is a cleaner way to write code, particularly if you have many subsequent steps in the pipe. Note that for clarity we usually write the different parts of the pipe on different lines.\n\n1.8.1 Annotating the pipe\nIf you want to include annotations in the pipe, put them after the pipe, like this:\n\nx |&gt;\n  sqrt() |&gt;  # This calculates the square root\n  mean()     # This calculates the mean\n\n[1] 1.676466\n\n\nIf you put them before the pipe, R thinks the pipe is part of the comment and will display an error1:\n\nx |&gt; \n  sqrt()  #  This is NOT the way to do it |&gt;  \n  mean()\n\nIf you run this code, the output is:\n\n## Error in mean.default(): argument \"x\" is missing, with no default\n\n\n\n1.8.2 Pipes and dataframes\nWe can also use the pipe operator for data frames. Next week we will learn about several useful functions in the dplyr package that will allow us to create new variables, filter data or select variables. This week we will not actively use the pipe a lot, but we will encounter some code that makes use of it. Now you know it simply means that we take the thing on the left and pass it along to the function on the right.\n\nYou may encounter %&gt;% in code written by others. This is also a pipe operator, which for our purposes works in the same way as |&gt;.",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Working with R and RStudio: the basics</span>"
    ]
  },
  {
    "objectID": "data_01_basics.html#footnotes",
    "href": "data_01_basics.html#footnotes",
    "title": "1  Working with R and RStudio: the basics",
    "section": "",
    "text": "R does not process the pipe operator after sqrt() because it is after the hashtag (#) and thus part of the comment. As a result, R runs the code x |&gt; sqrt() and displays the result. Then it continues to the line mean() and throws an error, because there are no arguments to the function.↩︎",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Working with R and RStudio: the basics</span>"
    ]
  },
  {
    "objectID": "data_02_filtering_selecting.html",
    "href": "data_02_filtering_selecting.html",
    "title": "2  Filtering, selecting & renaming",
    "section": "",
    "text": "2.1 Tibbles\nWe already encountered data frames in the first week. Data frames are one of the ‘original’ ways in R to interact with data. However, because of the way they are displayed, it can sometimes be difficult to manipulate data in them and to print their content.\nA tibble, or tbl_df, is a modern ‘version’ of the data frame. Tibbles have a refined print method that shows only the first 10 rows, and all the columns that fit on screen. Tibbles are therefore easier to use if you have large data sets containing complex objects. While the data set used here is not particularly complex, it makes sense to get used to tibbles.\nTo be able to work with tibbles, you must install tidyverse install.packages(\"tidyverse\") (already done on University computers). We can load the tidyverse packages by typing:\nlibrary(tidyverse)\nTo transform our data set into a tibble, we can write.\ndeniro_data &lt;- as_tibble(deniro_data)\ndeniro_data \n\n# A tibble: 87 × 3\n    Year Score Title                 \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;                 \n 1  1968    86 Greetings             \n 2  1970    17 Bloody Mama           \n 3  1970    73 Hi, Mom!              \n 4  1971    40 Born to Win           \n 5  1973    98 Mean Streets          \n 6  1973    88 Bang the Drum Slowly  \n 7  1974    97 The Godfather, Part II\n 8  1976    41 The Last Tycoon       \n 9  1976    99 Taxi Driver           \n10  1977    47 1900                  \n# ℹ 77 more rows",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Filtering, selecting & renaming</span>"
    ]
  },
  {
    "objectID": "data_02_filtering_selecting.html#tibbles",
    "href": "data_02_filtering_selecting.html#tibbles",
    "title": "2  Filtering, selecting & renaming",
    "section": "",
    "text": "deniro_data &lt;- as_tibble(deniro_data)\n\nWith this code we turn the existing object deniro_data into a tibble, a data frame with class tbl_df. If your data frame has a different name, you need to change the name. When we now open the data frame we can see that the way the data frame is displayed has changed. Note that nothing has been changed in terms of content. All the original variables and values are still the same. It is only a visual change at this point.",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Filtering, selecting & renaming</span>"
    ]
  },
  {
    "objectID": "data_02_filtering_selecting.html#selecting",
    "href": "data_02_filtering_selecting.html#selecting",
    "title": "2  Filtering, selecting & renaming",
    "section": "2.2 Selecting",
    "text": "2.2 Selecting\nOnce we have opened our data set we can start selecting variables. For example, if we want to select the columns (variables) regarding publication year (Year) and the title of the movie (Title) by their names, we can write:\n\ndeniro_data |&gt; \n  select(Year, Title)\n\n# A tibble: 87 × 2\n    Year Title                 \n   &lt;int&gt; &lt;chr&gt;                 \n 1  1968 Greetings             \n 2  1970 Bloody Mama           \n 3  1970 Hi, Mom!              \n 4  1971 Born to Win           \n 5  1973 Mean Streets          \n 6  1973 Bang the Drum Slowly  \n 7  1974 The Godfather, Part II\n 8  1976 The Last Tycoon       \n 9  1976 Taxi Driver           \n10  1977 1900                  \n# ℹ 77 more rows\n\n\n\ndeniro_data |&gt;\n\nThis part of the code extract one or multiple columns from deniro_data. Note that we use the native pipe operator (|&gt;), see week 2.\n\nselect(Year, Title)\n\nHere we select two columns of the tibble, named Year and Title. Note that as a matter of style, we suggest to put any new commands in a pipe on the next line (see overview of week 2)\n\n\nThere are several special functions that can be used inside select(). It is possible to apply a function to the columns and, for example, select only numeric columns:\n\ndeniro_data |&gt; \n  select(where(is.numeric))\n\n# A tibble: 87 × 2\n    Year Score\n   &lt;int&gt; &lt;int&gt;\n 1  1968    86\n 2  1970    17\n 3  1970    73\n 4  1971    40\n 5  1973    98\n 6  1973    88\n 7  1974    97\n 8  1976    41\n 9  1976    99\n10  1977    47\n# ℹ 77 more rows\n\n\n\ndeniro_data |&gt;\n\nThis part of the code extract one or multiple columns from deniro_data. Note that we use the native pipe operator (|&gt;), see week 2.\n\nselect(where(is.numeric))\n\nHere we select only those columns in deniro_data that are numeric.\n\n\nselect() can be also used to remove columns from the data frame. For this we would use the ‘-’ sign:\n\ndeniro_data |&gt; \n  select(-Year, -Title)\n\n# A tibble: 87 × 1\n   Score\n   &lt;int&gt;\n 1    86\n 2    17\n 3    73\n 4    40\n 5    98\n 6    88\n 7    97\n 8    41\n 9    99\n10    47\n# ℹ 77 more rows\n\n\nNote that at this point, none of the changes are ‘permanent’ because the resulting data frame (tibble) is not ‘created’ but only printed. You simply ask R to execute the command in the existing data set and print out the result (not save it). If you want to select (or remove) a variable on a permanent basis then you would need to create a new object. So, for example, if you want to only keep the columns (variables) of Year and Movie Title by their names, then you would need to write:\n\nnew_deniro_data &lt;- deniro_data |&gt; \n  select(Year, Title)\n\n\nnew_deniro_data &lt;-\n\nThis part of the code creates a new object called ‘new_deniro_data’.\n\ndeniro_data |&gt; select(Year, Title)\n\nThis part of the code extract one or multiple columns as a data table.\n\n\nNote that you do not always have to create a new data set. If you would like to change the existing data set, assign the result to an object with the same name:\n\ndeniro_data &lt;- deniro_data |&gt; \n  select(Year, Title)\n\nWatch out: This will overwrite the existing deniro_data with the changes. If you want to get back to the original data set you need to open it again.",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Filtering, selecting & renaming</span>"
    ]
  },
  {
    "objectID": "data_02_filtering_selecting.html#filtering-variables",
    "href": "data_02_filtering_selecting.html#filtering-variables",
    "title": "2  Filtering, selecting & renaming",
    "section": "2.3 Filtering variables",
    "text": "2.3 Filtering variables\nThe filter() function is used to subset the rows. There are a number of important functions and operators that are useful when constructing the expressions used to filter the data:\n\n== means ‘equal to’\n&lt; means ‘smaller than’\n&gt; means ‘larger than’\n&lt;= means ‘equal to or smaller than’\n&gt;= means ‘equal to or larger than’\n& means ‘AND’\n| means ‘OR’\n! means ‘is not’\n%in% is used to select one of multiple values\n\n\nTo illustrate the use of some of them, I will use the ‘starwars’ data set. This is a data set that is automatically loaded with the tidyverse package. We can load the package by typing:\n\nlibrary(tidyverse)\nstarwars\n\n# A tibble: 87 × 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n 1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…\n 2 C-3PO       167    75 &lt;NA&gt;       gold       yellow         112   none  mascu…\n 3 R2-D2        96    32 &lt;NA&gt;       white, bl… red             33   none  mascu…\n 4 Darth V…    202   136 none       white      yellow          41.9 male  mascu…\n 5 Leia Or…    150    49 brown      light      brown           19   fema… femin…\n 6 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…\n 7 Beru Wh…    165    75 brown      light      blue            47   fema… femin…\n 8 R5-D4        97    32 &lt;NA&gt;       white, red red             NA   none  mascu…\n 9 Biggs D…    183    84 black      light      brown           24   male  mascu…\n10 Obi-Wan…    182    77 auburn, w… fair       blue-gray       57   male  mascu…\n# ℹ 77 more rows\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\nLet us assume we want to filter by one or more criteria. For a character variable, we would write:\n\nstarwars |&gt; \n  filter(eye_color == \"blue\")\n\n# A tibble: 19 × 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n 1 Luke Sk…    172  77   blond      fair       blue            19   male  mascu…\n 2 Owen La…    178 120   brown, gr… light      blue            52   male  mascu…\n 3 Beru Wh…    165  75   brown      light      blue            47   fema… femin…\n 4 Anakin …    188  84   blond      fair       blue            41.9 male  mascu…\n 5 Wilhuff…    180  NA   auburn, g… fair       blue            64   male  mascu…\n 6 Chewbac…    228 112   brown      unknown    blue           200   male  mascu…\n 7 Jek Ton…    180 110   brown      fair       blue            NA   &lt;NA&gt;  &lt;NA&gt;  \n 8 Lobot       175  79   none       light      blue            37   male  mascu…\n 9 Mon Mot…    150  NA   auburn     fair       blue            48   fema… femin…\n10 Qui-Gon…    193  89   brown      fair       blue            92   male  mascu…\n11 Finis V…    170  NA   blond      fair       blue            91   male  mascu…\n12 Ric Olié    183  NA   brown      fair       blue            NA   male  mascu…\n13 Adi Gal…    184  50   none       dark       blue            NA   fema… femin…\n14 Mas Ame…    196  NA   none       blue       blue            NA   male  mascu…\n15 Cliegg …    183  NA   brown      fair       blue            82   male  mascu…\n16 Luminar…    170  56.2 black      yellow     blue            58   fema… femin…\n17 Barriss…    166  50   black      yellow     blue            40   fema… femin…\n18 Jocasta…    167  NA   white      fair       blue            NA   fema… femin…\n19 Tarfful     234 136   brown      brown      blue            NA   male  mascu…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\n\nfilter(eye_color == \"blue\")\n\nThe filter() function is used to subset a data frame, retaining all rows that satisfy your conditions. Here we ask for a specific eye color.\n\n\n\nOne mistake that people often make in filtering character variables is that they forget the quotation marks.\n\nIf there are multiple eye colors that you would want to select, you can use %in%:\n\nstarwars |&gt; \n  filter(eye_color %in% c(\"blue\", \"red\"))\n\n# A tibble: 24 × 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n 1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…\n 2 R2-D2        96    32 &lt;NA&gt;       white, bl… red             33   none  mascu…\n 3 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…\n 4 Beru Wh…    165    75 brown      light      blue            47   fema… femin…\n 5 R5-D4        97    32 &lt;NA&gt;       white, red red             NA   none  mascu…\n 6 Anakin …    188    84 blond      fair       blue            41.9 male  mascu…\n 7 Wilhuff…    180    NA auburn, g… fair       blue            64   male  mascu…\n 8 Chewbac…    228   112 brown      unknown    blue           200   male  mascu…\n 9 Jek Ton…    180   110 brown      fair       blue            NA   &lt;NA&gt;  &lt;NA&gt;  \n10 IG-88       200   140 none       metal      red             15   none  mascu…\n# ℹ 14 more rows\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\n\nfilter(eye_color %in% c(\"blue\", \"red\"))\n\nThe filter() function is used to subset a data frame, retaining all rows that satisfy your conditions. Here we ask for the eye_color to be one of the colors in the vector c(\"blue\", \"red\") , i.e. that eye_color is equal to blue or to red.\n\n\nFor a numeric variable (such as height), we do not use the quotation marks. Let us also filter for all characters that are at least 172 cm tall and have blue eyes.\n\nstarwars |&gt; \n  filter(eye_color == \"blue\" & height &gt;= 172)\n\n# A tibble: 13 × 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n 1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…\n 2 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…\n 3 Anakin …    188    84 blond      fair       blue            41.9 male  mascu…\n 4 Wilhuff…    180    NA auburn, g… fair       blue            64   male  mascu…\n 5 Chewbac…    228   112 brown      unknown    blue           200   male  mascu…\n 6 Jek Ton…    180   110 brown      fair       blue            NA   &lt;NA&gt;  &lt;NA&gt;  \n 7 Lobot       175    79 none       light      blue            37   male  mascu…\n 8 Qui-Gon…    193    89 brown      fair       blue            92   male  mascu…\n 9 Ric Olié    183    NA brown      fair       blue            NA   male  mascu…\n10 Adi Gal…    184    50 none       dark       blue            NA   fema… femin…\n11 Mas Ame…    196    NA none       blue       blue            NA   male  mascu…\n12 Cliegg …    183    NA brown      fair       blue            82   male  mascu…\n13 Tarfful     234   136 brown      brown      blue            NA   male  mascu…\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\n\nfilter(eye_color == \"blue\" & height &gt;= 172)\n\nThe filter() function is used to subset a data frame, retaining all rows that satisfy your conditions. Here we ask for a specific eye color and at least a specific height.\n\n\nIf you would like to filter characters that are at least 172 cm tall or have blue eyes, you can use:\n\nstarwars |&gt; \n  filter(eye_color == \"blue\" | height &gt;= 172)\n\n# A tibble: 60 × 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n 1 Luke Sk…    172    77 blond      fair       blue            19   male  mascu…\n 2 Darth V…    202   136 none       white      yellow          41.9 male  mascu…\n 3 Owen La…    178   120 brown, gr… light      blue            52   male  mascu…\n 4 Beru Wh…    165    75 brown      light      blue            47   fema… femin…\n 5 Biggs D…    183    84 black      light      brown           24   male  mascu…\n 6 Obi-Wan…    182    77 auburn, w… fair       blue-gray       57   male  mascu…\n 7 Anakin …    188    84 blond      fair       blue            41.9 male  mascu…\n 8 Wilhuff…    180    NA auburn, g… fair       blue            64   male  mascu…\n 9 Chewbac…    228   112 brown      unknown    blue           200   male  mascu…\n10 Han Solo    180    80 brown      fair       brown           29   male  mascu…\n# ℹ 50 more rows\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\nYou can apply the expressions mentioned above to filter the data. The “!” operator works a bit different because it will select all cases that do not satisfy a condition. So, for example, if we want to filter all cases that do not have blue eyes, we would write:\n\nstarwars |&gt; \n  filter(!(eye_color == \"blue\"))\n\n# A tibble: 68 × 14\n   name     height  mass hair_color skin_color eye_color birth_year sex   gender\n   &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n 1 C-3PO       167    75 &lt;NA&gt;       gold       yellow         112   none  mascu…\n 2 R2-D2        96    32 &lt;NA&gt;       white, bl… red             33   none  mascu…\n 3 Darth V…    202   136 none       white      yellow          41.9 male  mascu…\n 4 Leia Or…    150    49 brown      light      brown           19   fema… femin…\n 5 R5-D4        97    32 &lt;NA&gt;       white, red red             NA   none  mascu…\n 6 Biggs D…    183    84 black      light      brown           24   male  mascu…\n 7 Obi-Wan…    182    77 auburn, w… fair       blue-gray       57   male  mascu…\n 8 Han Solo    180    80 brown      fair       brown           29   male  mascu…\n 9 Greedo      173    74 &lt;NA&gt;       green      black           44   male  mascu…\n10 Jabba D…    175  1358 &lt;NA&gt;       green-tan… orange         600   herm… mascu…\n# ℹ 58 more rows\n# ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;,\n#   vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\n\nfilter(!(eye_color == \"blue\"))\n\nThe filter() function is used to subset a data frame, retaining all rows that satisfy your conditions. Here we ask to only select cases that do not have a specific eye color. Note that we put an exclamation point around the condition and that the condition is surrouded by brackets.\n\n\nNote again that none of the changes are ‘permanent’. You simply ask R to execute the command in the existing data set ‘temporarily’. If you want to filter on a permanent basis then you would need to create a new object (or assign to the current object). So, for example, if you want to only select the cases whose home planet is ‘Tatooine’, then you would need to write:\n\nnew_starwars &lt;- starwars |&gt; \n  filter(homeworld == \"Tatooine\")\n\n\nnew_starwars &lt;-\n\nThis part of the code creates a new object called ‘new_starwars’.\n\nstarwars |&gt;\n\nThis part of the code takes the starwars tibble as the start of our pipe.\n\nfilter(homeworld == \"Tatooine\")\n\nThis part of the code subset a data frame using the condition as specified.\n\n\n\nOne mistake that people often make in filters is using only one equal sign =, where there should be two ==.",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Filtering, selecting & renaming</span>"
    ]
  },
  {
    "objectID": "data_02_filtering_selecting.html#renaming-variables",
    "href": "data_02_filtering_selecting.html#renaming-variables",
    "title": "2  Filtering, selecting & renaming",
    "section": "2.4 Renaming variables",
    "text": "2.4 Renaming variables\nTo change the names of individual variables we use the rename() function. It uses the order new_name = old_name to rename selected variables.\nIf we want to rename the column name to character.name, you would write:\n\nstarwars |&gt; \n  rename(character.name = name)\n\n# A tibble: 87 × 14\n   character.name  height  mass hair_color skin_color eye_color birth_year sex  \n   &lt;chr&gt;            &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;\n 1 Luke Skywalker     172    77 blond      fair       blue            19   male \n 2 C-3PO              167    75 &lt;NA&gt;       gold       yellow         112   none \n 3 R2-D2               96    32 &lt;NA&gt;       white, bl… red             33   none \n 4 Darth Vader        202   136 none       white      yellow          41.9 male \n 5 Leia Organa        150    49 brown      light      brown           19   fema…\n 6 Owen Lars          178   120 brown, gr… light      blue            52   male \n 7 Beru Whitesun …    165    75 brown      light      blue            47   fema…\n 8 R5-D4               97    32 &lt;NA&gt;       white, red red             NA   none \n 9 Biggs Darkligh…    183    84 black      light      brown           24   male \n10 Obi-Wan Kenobi     182    77 auburn, w… fair       blue-gray       57   male \n# ℹ 77 more rows\n# ℹ 6 more variables: gender &lt;chr&gt;, homeworld &lt;chr&gt;, species &lt;chr&gt;,\n#   films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt;\n\n\nHowever, as was pointed out above, this is not a permanent change. To do this, we need to make sure that it is changed in the existing data frame.\n\nstarwars &lt;- starwars |&gt; \n  rename(character.name = name)\n\n\nstarwars &lt;- starwars |&gt;\n\nThis part of the code overwrites the existing data frame ‘starwars’.\n\nrename(character.name = name)\n\nThis part of the code renames a variable with the general pattern: &lt;new_name&gt; = &lt;old_name&gt;",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Filtering, selecting & renaming</span>"
    ]
  },
  {
    "objectID": "data_03_variables.html",
    "href": "data_03_variables.html",
    "title": "3  Creating, summarising & recoding variables",
    "section": "",
    "text": "3.1 Creating or changing variables\nWe can use the function mutate from package dplyr to create new variables or change existing variables in a data frame. Package dplyr is loaded as part of the tidyverse.\nWe’ll use the variable Pop2006 as an example, which registers the population of countries in 2006:\nhead(dta$Pop2006)\n\n[1]          NA  3137503.17 33347948.22    66900.00 16391381.89    83612.15\nIf we would like to create a variable that registers the population in millions, we can create the new variable as follows:\ndta &lt;- dta |&gt;\n  mutate(Pop2006_million = Pop2006 / 1000000)\nWe can compare the first five cases to check if the transformation worked as intended:\ndta |&gt;\n  select(Pop2006, Pop2006_million) |&gt;   # Select the original and transformed variable\n  head()                                # Display the first few rows\n\n      Pop2006 Pop2006_million\n1          NA              NA\n2  3137503.17      3.13750317\n3 33347948.22     33.34794822\n4    66900.00      0.06690000\n5 16391381.89     16.39138189\n6    83612.15      0.08361215\nOther examples of mutations are:\n# Calculate the difference between the population in 2006 and 2000\ndta &lt;- dta |&gt;\n  mutate(Pop2006_difference = Pop2006 - Pop2000)\n\n# Take the square root of the population\ndta &lt;- dta |&gt;\n  mutate(Pop2006_squared = sqrt(Pop2006))\n\n# Take the natural logarithm of the population\ndta &lt;- dta |&gt;\n  mutate(Pop2006_log = log(Pop2006))  \n\n# Create a new variable with the same value (1) for all cases\ndta &lt;- dta |&gt;\n  mutate(Country = 1)\nImportant things about mutate:",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Creating, summarising & recoding variables</span>"
    ]
  },
  {
    "objectID": "data_03_variables.html#creating-or-changing-variables",
    "href": "data_03_variables.html#creating-or-changing-variables",
    "title": "3  Creating, summarising & recoding variables",
    "section": "",
    "text": "dta &lt;- dta |&gt;\n\nThis part of the code says that we are going to start of with the data frame dta and assign the result to a data frame with the same name. Basically it means: we’re going to change the data frame dta . If you are working with your own data, you would replace this by the name of your own data frame.\nNote that we are using the pipe operator |&gt; here, which means that we are taking the original data frame, and using this in the mutate function (see below).\n\nmutate(...)\n\nThe mutate function creates a new variable or changes an existing one. Within the brackets we specify what kind of mutation we want.\n\nPop2006_million\n\nThis is the name of the variable we’re creating. If you do not write the name of a new variable but instead use the name of an existing variable, this would change the values of that variable. In your own data, replace Pop2006_million by the name of the variable you would like to create.\n\nPop2006 / 1000000\n\nThis is how we would like to create this new variable, in this case by dividing the existing variable Pop2006 by one million. You can apply any kind of function or operator, as long as it works on a vector (in this case: an entire column of a dataset).\n\n\n\n\n\n\n\n\nDo not use the $ operator to select variables from a data frame. You must simply use the name of the variabe.\nDo not forget to assign the result, i.e. start the code with dta &lt;- dta |&gt; (replacing dta by the name of your dataset). If you do not assign the result, R will simply print out the mutated data frame but not save it.\nIf you apply a mutation to a data frame and assign the result, this will not generate any output. When it works succesfully, it will simply change your data frame or create a new one. You can subsequently inspect the data to see if the transformation worked.",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Creating, summarising & recoding variables</span>"
    ]
  },
  {
    "objectID": "data_03_variables.html#summarising-data",
    "href": "data_03_variables.html#summarising-data",
    "title": "3  Creating, summarising & recoding variables",
    "section": "3.2 Summarising data",
    "text": "3.2 Summarising data\nWe can summarise data using the function summarise from pacakge dplyr. Package dplyr is loaded as part of the tidyverse.\n\ndta |&gt;\n  summarise(mean_population = mean(Pop2006, na.rm=TRUE))\n\n  mean_population\n1        34502734\n\n\nThis will simply give us the mean value of Pop2006 for all countries in the world. The most powerful use of summarise is in combination with group_by. For example, the below code groups countries by continent (DD_un_continent_name) and then calculates the mean population size for each continent:\n\ndta |&gt;\n  group_by(DD_un_continent_name) |&gt;\n  summarise(mean_population = mean(Pop2006, na.rm=TRUE))\n\n# A tibble: 6 × 2\n  DD_un_continent_name mean_population\n  &lt;chr&gt;                          &lt;dbl&gt;\n1 \"\"                            32600 \n2 \"Africa\"                   17475659.\n3 \"Americas\"                 25412866.\n4 \"Asia\"                     87338061.\n5 \"Europe\"                   17711125.\n6 \"Oceania\"                   2732066.\n\n\nWe can also group by more than one grouping variable. For example, here we calculate the mean population for democracies (Cheibub2Type = 0) and dictatorships (Cheibub2Type = 1) in each continent:\n\ndta |&gt;\n  group_by(DD_un_continent_name, Cheibub2Type) |&gt;\n  summarise(mean_population = mean(Pop2006, na.rm=TRUE))\n\n# A tibble: 15 × 3\n# Groups:   DD_un_continent_name [6]\n   DD_un_continent_name Cheibub2Type mean_population\n   &lt;chr&gt;                       &lt;dbl&gt;           &lt;dbl&gt;\n 1 \"\"                              0            NaN \n 2 \"\"                             NA          32600 \n 3 \"Africa\"                        0       18924251.\n 4 \"Africa\"                        1       16597725.\n 5 \"Americas\"                      0       26786031.\n 6 \"Americas\"                      1       14770838.\n 7 \"Asia\"                          0      138303981.\n 8 \"Asia\"                          1       63553966.\n 9 \"Asia\"                         NA            NaN \n10 \"Europe\"                        0       18538856.\n11 \"Europe\"                        1        7226530.\n12 \"Europe\"                       NA            NaN \n13 \"Oceania\"                       0        3515919.\n14 \"Oceania\"                       1         380506.\n15 \"Oceania\"                      NA            NaN \n\n\nYou can also calculate multiple summary functions:\n\ndta |&gt;\n  group_by(DD_un_continent_name) |&gt;\n  summarise(mean_population = mean(Pop2006, na.rm=TRUE),\n            median_poplation = Median(Pop2006, na.rm=TRUE),  # Median from pacakge DescTools\n            sd_population = sd(Pop2006, na.rm=TRUE))\n\n# A tibble: 6 × 4\n  DD_un_continent_name mean_population median_poplation sd_population\n  &lt;chr&gt;                          &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n1 \"\"                            32600            32600            NA \n2 \"Africa\"                   17475659.         9244288.     25102665.\n3 \"Americas\"                 25412866.         6016000      59575769.\n4 \"Asia\"                     87338061.        14829470.    253704497.\n5 \"Europe\"                   17711125.         7441475.     28476042.\n6 \"Oceania\"                   2732066.          200462.      5920588.\n\n\nIf you want to save the result to a new data frame instead of printing it out, you can simply assign the result. Note that there is no output from the below code chunk because the result is saved in the data frame summary_data:\n\nsummary_data &lt;- dta |&gt;\n  group_by(DD_un_continent_name) |&gt;\n  summarise(mean_population = mean(Pop2006, na.rm=TRUE),\n            median_poplation = Median(Pop2006, na.rm=TRUE), # Median from pacakge DescTools\n            sd_population = sd(Pop2006, na.rm=TRUE))\n\n\nThe difference between mutate and summarise is that mutate creates a new value for each case in the dataset, while summarise will summarise the data by the grouping variable.",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Creating, summarising & recoding variables</span>"
    ]
  },
  {
    "objectID": "data_03_variables.html#recoding-variables",
    "href": "data_03_variables.html#recoding-variables",
    "title": "3  Creating, summarising & recoding variables",
    "section": "3.3 Recoding variables",
    "text": "3.3 Recoding variables\nRecoding variables means that we change the coding of values. This often applies to nominal or ordinal variables (factors), for example when we would like to group some categories together.\n\n3.3.1 Recoding nominal variables\nWe illustrate this using the variable religion ‘Majority religion’ that we create from Pippa Noris’ Democracy Cross-national Data. We already imported the dataset (dta) and loaded the relevant packages (tidyverse, rio) at the start of this overview.\nFirst, we create variable religion using the function factorize from rio. This creates a factor version of the original (labelled numeric) variable Fox_emajrel.\n\ndta &lt;- dta |&gt;\n  mutate(religion = factorize(Fox_emajrel))\n\nThe variable religion can take the following values:\n\ntable(dta$religion)\n\n\n            Catholic   Orthodox Christian Protestant Christian \n                  43                   12                   16 \n     Other Christian         Islam, Sunni         Islam, Shi'i \n                   0                   33                    3 \n        Islam, Other             Buddhist                Hindu \n                   1                    8                    2 \n              Jewish              Animist                Other \n                   1                    4                    5 \n     Islam (general)                Mixed  Christian (general) \n                   8                   12                   25 \n\n\nWe see that we have various large religions and various smaller categories. We can also see that various Islamic denominations and Christian denominations have been split up. Suppose we want, for the purpose of further analysis, simplify the categorisation to five categories: Christian, Islamic, Hindu, Buddhist and Other.\nWe can use the recode function from dplyr to recode the categories. Package dplyr is loaded as part of the tidyverse.\n\ndta &lt;- dta |&gt;\n  mutate(religion_recoded = recode(religion, \n                                   \"Animist\" = \"Other\",\n                                   \"Catholic\" = \"Christian\",\n                                   \"Islam (general)\" = \"Islam\",\n                                   \"Islam, Other\" = \"Islam\",\n                                   \"Islam, Shi'i\" = \"Islam\",\n                                   \"Islam, Sunni\" = \"Islam\",\n                                   \"Jewish\" = \"Other\",\n                                   \"Mixed\" = \"Other\",\n                                   \"Orthodox Christian\" = \"Christian\",\n                                   \"Protestant Christian\" = \"Christian\",\n                                   \"Other Christian\" = \"Christian\",\n                                   \"Christian (general)\" = \"Christian\"\n                                   )\n         )\n\n\nmutate(religion_recoded =\n\nThis part of the code indicates that we want to create a new variable religion_recoded. If you work with your own data you would of course choose an appropriate name.\n\nrecode(religion,\n\nThis part of the code indicates that we would like to recode the existing variable religion. If you work with your own data, specify the name of the existing variable that you want to recode.\n\n\"Animist\" = \"Other\"\n\nThese are the recoding statements, where we writing the old name on the left and the new name on the right between double quotation marks (“).\nWe can include as many of these statements as we like. If we do not include a value, it will remain unchanged (by default). For example, we do not include a statement for Other, so this value will be the same in the recoded variable.\n\n\nWe can see that the recoding has resulted in the five categories that we would like:\n\ntable(dta$religion_recoded)\n\n\nChristian     Islam  Buddhist     Hindu     Other \n       96        45         8         2        22 \n\n\nWe can also check whether the old values have been correctly recoded in the new values:\n\ntable(dta$religion, dta$religion_recoded)\n\n                      \n                       Christian Islam Buddhist Hindu Other\n  Catholic                    43     0        0     0     0\n  Orthodox Christian          12     0        0     0     0\n  Protestant Christian        16     0        0     0     0\n  Other Christian              0     0        0     0     0\n  Islam, Sunni                 0    33        0     0     0\n  Islam, Shi'i                 0     3        0     0     0\n  Islam, Other                 0     1        0     0     0\n  Buddhist                     0     0        8     0     0\n  Hindu                        0     0        0     2     0\n  Jewish                       0     0        0     0     1\n  Animist                      0     0        0     0     4\n  Other                        0     0        0     0     5\n  Islam (general)              0     8        0     0     0\n  Mixed                        0     0        0     0    12\n  Christian (general)         25     0        0     0     0\n\n\n(For example, all four majority Animist countries have correctly been recoded to ‘Other’).\n\n\n3.3.2 Recoding ordinal variables\nIf you have an ordinal variable you want to recode, you would probably like the order of the variable to be kept.\nFor example, we have variable economy which we create from the Norris dataset. It is a classification of of countries based on their GDP per capita. We already imported the dataset (dta) and loaded the relevant packages (tidyverse, rio) at the start of this overview.\nFirst, we create variable economy using the function factorize from rio. This creates a factor version of the original (labelled numeric) variable TypeEcon2006.\n\ndta &lt;- dta |&gt;\n  mutate(economy = factorize(TypeEcon2006))\n\nThe variable economy can take the following values:\n\ntable(dta$economy)\n\n\n       High ($15,000+) Medium ($2,000-14,999)    Low ($2000 or less) \n                    36                     68                     87 \n\n\nSometimes one wants to merge certain categories, for example, to take together the High and Medium level countries, but preserve the order from low to high. We can achieve this using recode_factor:\n\ndta &lt;- dta |&gt;\n  mutate(economy_recoded = recode_factor(economy,\n                                         \"Low ($2000 or less)\" = \"Lower\",\n                                         \"High ($15,000+)\" = \"Higher\",\n                                         \"Medium ($2,000-14,999)\" = \"Higher\",\n                                         .ordered = TRUE)\n         )\n\n\nmutate(economy_recoded\n\nThis part of the code indicates that we want to create a new variable economy_recoded. If you work with your own data you would choose an appropriate name for the recoded variable.\n\nrecode_factor(economy,\n\nThis part of the code indicates that we would like to recode the existing variable economy. If you work with your own data, specify the name of the existing variable that you want to recode.\n\n\"Low ($2000 or less)\"=\"Lower\"\n\nThese are the recoding statements, where we writing the old name on the left and the new name on the right between double quotation marks (“).\nWe can include as many of these statements as we like. Note that the spelling of the original category needs to be exact.\n\n.ordered = TRUE\n\nThis indicates that we would like to create an ordered factor. Please note the dot before ordered.\n\n\nIf we inspect the first few values, we see that the factor is ordered. The order of the factor is determined by the order in which you have specified the recoding statements (i.e. Lower, then Higher):\n\nhead(dta$economy_recoded)\n\n[1] Lower  Lower  Higher Higher Lower  Higher\nLevels: Lower &lt; Higher\n\n\n\n\n3.3.3 Recoding numeric variables\nRecoding numeric variables works similarly to recoding norminal or ordinal variables.\nAs an example take the Freedom House Democracy Ratings for 2014 (fhrate14), which are epxressed on a scale from 1 to 7. Freedom House also uses a three-point rating: Free (1.0 to 2.5), Partly Free (3.0 to 5.0) and Not Free (5.5 to 7). We already imported the dataset (dta) and loaded the relevant packages (tidyverse, rio) at the start of this overview.\nWe can recode the variable fhrate14 as follows:\n\ndta &lt;- dta |&gt;\n  mutate(fhrate14_recoded = recode(fhrate14,\n                                   \"1\" = 1,\n                                   \"1.5\" = 1,\n                                   \"2.0\" = 1,\n                                   \"2.5\" = 1,\n                                   \"3\" = 2,\n                                   \"3.5\" = 2,\n                                   \"4\" = 2,\n                                   \"4.5\" = 2,\n                                   \"5\" = 2,\n                                   \"5.5\" = 3,\n                                   \"6\" = 3,\n                                   \"6.5\" = 3,\n                                   \"7\" = 3)\n         )\n\n\ntable(dta$fhrate14_recoded)\n\n\n 1  2  3 \n89 55 51 \n\n\nNote: if you have many unique values, this may not be the most efficient way to recode a numeric variable. In such cases using ifelse or case_when will work more efficiently; these functions will be discussed in one of the upcoming weeks.1 There are also other packages that offer recoding functions (such as recode from package car or rec from pacakge sjmisc), but we will not discuss these here.",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Creating, summarising & recoding variables</span>"
    ]
  },
  {
    "objectID": "data_03_variables.html#missing-data",
    "href": "data_03_variables.html#missing-data",
    "title": "3  Creating, summarising & recoding variables",
    "section": "3.4 Missing data",
    "text": "3.4 Missing data\nMany real world datasets are incomplete: they have missing data. For example, in Pippa Norris’ dataset on countries many variables are not observed for each country. We already imported this dataset (dta) and loaded the relevant packages (tidyverse, rio) at the start of this overview.\nFor some countries the dataset contains missing values on the variable Pop2006 (population size in 2006):\n\ndta |&gt;\n  filter(is.na(Pop2006)) |&gt;\n  select(Nation, Pop2006)\n\n       Nation Pop2006\n1 Afghanistan      NA\n2        Iraq      NA\n3      Kosovo      NA\n4  Montenegro      NA\n5       Nauru      NA\n6 South Sudan      NA\n7      Taiwan      NA\n8 Timor Leste      NA\n9      Tuvalu      NA\n\n\nThe term NA means Not Available. In this case there may not have been reliable data for these countries’ population sizes in 2006 (Afghanistan, Iraq) or the country simply did not exist in 2006 (South Sudan). There can be various reasons for missing data in a dataset.\n\n3.4.1 Types of missing data\nIn R, NA is commonly used to signal missing data, but if we load datasets in an SPSS, Stata or other file format, missing data may have different codes. Often, this type of information can be found in the codebook, a separate file (often a PDF) that describes the dataset and its variables.\nOne example is the variable cps19_pidtrad (Traditional party identification) from the 2019 Canadian Election Study (we loaded this data at the start of this overview):\n\nlevels(canada$pes19_pidtrad)\n\n[1] \"Liberal\"                          \"Conservative\"                    \n[3] \"NDP\"                              \"Bloc Québécois\"                  \n[5] \"Green\"                            \"People’s Party\"                  \n[7] \"Another party (please specify)\"   \"None of these\"                   \n[9] \"Don't know/ Prefer not to answer\"\n\n\nThis variable has a category ‘None of these’ and ‘Don’t know/Prefer not to answer’ which for most analysis should be treated as missing data. However, there are currently treated as regular answer categories.\n\nWe recommend to always check the levels or values of a variable to check for missing data issues.\n\nThis type of problem can also be encountered in interval-ratio variables (numeric variables), where in some cases numbers like 999 are used to indicate missing values. Note: this is something we do not recommend, but you may encounter it in real-world data you are working with.\nOne example in which the value 999 has been used to indicate missing data. If we calculate the mean for this variable without telling R that 999 is actually missing data, we will overestimate the mean age:\n\ndata_age &lt;- data.frame(age = c(55, 64, 37, 56, 999, 42, 47, 22, 49, 68, 59, 999))\nmean(data_age$age)  # The result is incorrect, because of the incorrect treatment of the missing values\n\n[1] 208.0833\n\n\n\n\n3.4.2 Recoding missing data\nIf there are values in the data that you would like to treat as missing data, you can use na_if from package dplyr. Package dplyr is loaded as part of the tidyverse.\n\ncanada &lt;- canada |&gt;\n  mutate(pes19_pidtrad = na_if(pes19_pidtrad, \n                               \"Don't know/ Prefer not to answer\")) |&gt;\n  mutate(pes19_pidtrad = na_if(pes19_pidtrad, \n                               \"None of these\")) |&gt;\n  mutate(pes19_pidtrad = droplevels(pes19_pidtrad))\n\ntable(canada$pes19_pidtrad, useNA = \"ifany\") # Display a table including NAs\n\n\n                       Liberal                   Conservative \n                          1746                           1501 \n                           NDP                 Bloc Québécois \n                           693                            186 \n                         Green                 People’s Party \n                           274                             64 \nAnother party (please specify)                           &lt;NA&gt; \n                            23                          33335 \n\n\n\nmutate(pes19_pidtrad = ...\n\nWe are going to change the existing variable pes19_pidtrad.\n\nna_if(pes19_pidtrad, \"Don't know/ Prefer not to answer\")\n\nThis function changes particular values in a variable to NA . In this example we would like to change values of \"Don't know/ Prefer not to answer\" of pes19_pidtrad into missing values (NA). For your own data you will need to insert the appropriate variable name and the value you would like to have changed to NA.\n\nmutate(pes19_pidtrad = droplevels(pes19_pidtrad))\n\nFinally, we use droplevels to ensure that the levels that we recoded as NA are completely removed as levels from factor pes19_pidtrad, so that in any subsequent analyses these are completely ignored. This is not necessary for other types of variables (numeric or character).\n\n\nWe see that there are no more respondents who answer ‘None of these’ or ‘Don’t know/Prefer not to answer’. Note: Because we have two values that we would like to be transformed into NA, we have two mutate statements.\nThis also works for replacing numeric values, like in our data_age example. Here we want to change the value of 999 to NA:\n\ndata_age &lt;- data_age |&gt;\n  mutate(age = na_if(age, 999))\ndata_age$age\n\n [1] 55 64 37 56 NA 42 47 22 49 68 59 NA\n\n\nAnd the mean will be correctly calculated after recoding the missing values:\n\nmean(data_age$age, na.rm=TRUE)\n\n[1] 49.9\n\n\nNote: it is better to use na_if than recode to recode missing values.2\n\n\n3.4.3 Filtering out missing data\nYou can filter out missing data, using the is.na function:\n\ndta |&gt;\n  filter(!is.na(Pop2006)) |&gt;\n  select(Nation, Pop2006) |&gt;\n  head()\n\n             Nation     Pop2006\n1           Albania  3137503.17\n2           Algeria 33347948.22\n3           Andorra    66900.00\n4            Angola 16391381.89\n5 Antigua & Barbuda    83612.15\n6         Argentina 39120455.54\n\n\n\nfilter(!is.na(Pop2006))\n\nWe filter out cases which have a non-missing value on variable Pop2006. Note the ! which means not, so we want only cases that do not have a missing value on Pop2006.",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Creating, summarising & recoding variables</span>"
    ]
  },
  {
    "objectID": "data_03_variables.html#footnotes",
    "href": "data_03_variables.html#footnotes",
    "title": "3  Creating, summarising & recoding variables",
    "section": "",
    "text": "In our example, we could use:\n\ndta &lt;- dta |&gt;\n       mutate(fhrate14_recoded2 = case_when(fhrate14 &lt;= 2.5 ~ 1,\n                                            fhrate14 &lt;= 5 ~ 2,\n                                            fhrate14 &lt;= 7 ~ 3,\n                                            TRUE ~ NA_real_))\ntable(dta$fhrate14_recoded2)\n\n\n 1  2  3 \n89 55 51 \n\n\n↩︎\nThe reason is that if you use recode to recode to missing values, you need to tell R exactly what type of missing data you have, for example NA_character_ instead of just NA for a character variable. Otherwise you will run into incompatible vector problems that are better avoided.↩︎",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Creating, summarising & recoding variables</span>"
    ]
  },
  {
    "objectID": "data_04_missing_data.html",
    "href": "data_04_missing_data.html",
    "title": "4  Missing data",
    "section": "",
    "text": "4.1 Types of missing data\nIn R, NA is commonly used to signal missing data, but if we load datasets in an SPSS, Stata or other file format, missing data may have different codes. Often, this type of information can be found in the codebook, a separate file (often a PDF) that describes the dataset and its variables.\nOne example is the variable cps19_pidtrad (Traditional party identification) from the 2019 Canadian Election Study (we loaded this data at the start of this overview):\nlevels(canada$pes19_pidtrad)\n\n[1] \"Liberal\"                          \"Conservative\"                    \n[3] \"NDP\"                              \"Bloc Québécois\"                  \n[5] \"Green\"                            \"People’s Party\"                  \n[7] \"Another party (please specify)\"   \"None of these\"                   \n[9] \"Don't know/ Prefer not to answer\"\nThis variable has a category ‘None of these’ and ‘Don’t know/Prefer not to answer’ which for most analysis should be treated as missing data. However, there are currently treated as regular answer categories.\nThis type of problem can also be encountered in interval-ratio variables (numeric variables), where in some cases numbers like 999 are used to indicate missing values. Note: this is something we do not recommend, but you may encounter it in real-world data you are working with.\nOne example in which the value 999 has been used to indicate missing data. If we calculate the mean for this variable without telling R that 999 is actually missing data, we will overestimate the mean age:\ndata_age &lt;- data.frame(age = c(55, 64, 37, 56, 999, 42, 47, 22, 49, 68, 59, 999))\nmean(data_age$age)  # The result is incorrect, because of the incorrect treatment of the missing values\n\n[1] 208.0833",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Missing data</span>"
    ]
  },
  {
    "objectID": "data_04_missing_data.html#types-of-missing-data",
    "href": "data_04_missing_data.html#types-of-missing-data",
    "title": "4  Missing data",
    "section": "",
    "text": "We recommend to always check the levels or values of a variable to check for missing data issues.",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Missing data</span>"
    ]
  },
  {
    "objectID": "data_04_missing_data.html#recoding-missing-data",
    "href": "data_04_missing_data.html#recoding-missing-data",
    "title": "4  Missing data",
    "section": "4.2 Recoding missing data",
    "text": "4.2 Recoding missing data\nIf there are values in the data that you would like to treat as missing data, you can use na_if from package dplyr. Package dplyr is loaded as part of the tidyverse.\n\ncanada &lt;- canada |&gt;\n  mutate(pes19_pidtrad = na_if(pes19_pidtrad, \n                               \"Don't know/ Prefer not to answer\")) |&gt;\n  mutate(pes19_pidtrad = na_if(pes19_pidtrad, \n                               \"None of these\")) |&gt;\n  mutate(pes19_pidtrad = droplevels(pes19_pidtrad))\n\ntable(canada$pes19_pidtrad, useNA = \"ifany\") # Display a table including NAs\n\n\n                       Liberal                   Conservative \n                          1746                           1501 \n                           NDP                 Bloc Québécois \n                           693                            186 \n                         Green                 People’s Party \n                           274                             64 \nAnother party (please specify)                           &lt;NA&gt; \n                            23                          33335 \n\n\n\nmutate(pes19_pidtrad = ...\n\nWe are going to change the existing variable pes19_pidtrad.\n\nna_if(pes19_pidtrad, \"Don't know/ Prefer not to answer\")\n\nThis function changes particular values in a variable to NA . In this example we would like to change values of \"Don't know/ Prefer not to answer\" of pes19_pidtrad into missing values (NA). For your own data you will need to insert the appropriate variable name and the value you would like to have changed to NA.\n\nmutate(pes19_pidtrad = droplevels(pes19_pidtrad))\n\nFinally, we use droplevels to ensure that the levels that we recoded as NA are completely removed as levels from factor pes19_pidtrad, so that in any subsequent analyses these are completely ignored. This is not necessary for other types of variables (numeric or character).\n\n\nWe see that there are no more respondents who answer ‘None of these’ or ‘Don’t know/Prefer not to answer’. Note: Because we have two values that we would like to be transformed into NA, we have two mutate statements.\nThis also works for replacing numeric values, like in our data_age example. Here we want to change the value of 999 to NA:\n\ndata_age &lt;- data_age |&gt;\n  mutate(age = na_if(age, 999))\ndata_age$age\n\n [1] 55 64 37 56 NA 42 47 22 49 68 59 NA\n\n\nAnd the mean will be correctly calculated after recoding the missing values:\n\nmean(data_age$age, na.rm=TRUE)\n\n[1] 49.9\n\n\nNote: it is better to use na_if than recode to recode missing values.1",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Missing data</span>"
    ]
  },
  {
    "objectID": "data_04_missing_data.html#filtering-out-missing-data",
    "href": "data_04_missing_data.html#filtering-out-missing-data",
    "title": "4  Missing data",
    "section": "4.3 Filtering out missing data",
    "text": "4.3 Filtering out missing data\nYou can filter out missing data, using the is.na function:\n\ndta |&gt;\n  filter(!is.na(Pop2006)) |&gt;\n  select(Nation, Pop2006) |&gt;\n  head()\n\n             Nation     Pop2006\n1           Albania  3137503.17\n2           Algeria 33347948.22\n3           Andorra    66900.00\n4            Angola 16391381.89\n5 Antigua & Barbuda    83612.15\n6         Argentina 39120455.54\n\n\n\nfilter(!is.na(Pop2006))\n\nWe filter out cases which have a non-missing value on variable Pop2006. Note the ! which means not, so we want only cases that do not have a missing value on Pop2006.",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Missing data</span>"
    ]
  },
  {
    "objectID": "data_04_missing_data.html#footnotes",
    "href": "data_04_missing_data.html#footnotes",
    "title": "4  Missing data",
    "section": "",
    "text": "The reason is that if you use recode to recode to missing values, you need to tell R exactly what type of missing data you have, for example NA_character_ instead of just NA for a character variable. Otherwise you will run into incompatible vector problems that are better avoided.↩︎",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Missing data</span>"
    ]
  },
  {
    "objectID": "data_05_advanced_recoding.html",
    "href": "data_05_advanced_recoding.html",
    "title": "5  Advanced recoding of variables",
    "section": "",
    "text": "5.1 Recoding variables using case_when\nFrequently, we need to modify or transform data based on various possible conditions. We can do this using the case_when() function from the dplyr package.\nWe will illustrate the usage of this function on a data set with GPA grades (available from the openintro package).\nThe data frame contains the variables ‘gpa’ and ‘study_hours’ for a sample of 193 undergraduate students who took an introductory statistics course in 2012 at a private US university. The data is shown as tibble below:\nlibrary(openintro) \nlibrary(tidyverse) #needed for displaying the data set as tibble\nas_tibble(gpa_study_hours)\n\n# A tibble: 193 × 2\n     gpa study_hours\n   &lt;dbl&gt;       &lt;dbl&gt;\n 1  4             10\n 2  3.8           25\n 3  3.93          45\n 4  3.4           10\n 5  3.2            4\n 6  3.52          10\n 7  3.68          24\n 8  3.4           40\n 9  3.7           10\n10  3.75          10\n# ℹ 183 more rows\nAssume that we want to recode the numeric ‘gpa’ scores into a character variable called ‘grades’ which uses the letter “A” as the highest grade. For simplicity reasons, we do not make a distinction into A+, A, A-, etc. but only focus on ‘whole grades’ (A, B, C, etc.).\nFollowing a common grade conversion we want the outcome to be: A (GPA between 3.7 - 4.0), B (2.7 - 3.3), C (1.7 – 2.3), D (1.0 – 1.3). The letter F as a grade is equivalent to a 0.0 GPA. Hence, our recoding rules are:\ncase_when() works by providing information on two ‘sides’: on the “left hand side”, there is a condition and on the “right hand side” we have the output value if this condition is true. Both are separated by a tilde (~).\ncase_when(condition ~ value)\nThere are a number of important functions and operators that are useful when constructing the expressions used to recode the data:\ngpa_study_hours &lt;- gpa_study_hours |&gt;\n  mutate(gpa_grade = case_when(\n    gpa &gt;= 3.7 ~ \"A\",\n    gpa &gt;= 2.7 ~ \"B\",\n    gpa &gt;= 1.7 ~ \"C\",\n    gpa &gt;= 1.3 ~ \"D\",\n    gpa &lt; 1.3 ~ \"F\"))  # Note the two brackets at the end (!)\ngpa_study_hours\n\n# A tibble: 193 × 3\n     gpa study_hours gpa_grade\n   &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;    \n 1  4             10 A        \n 2  3.8           25 A        \n 3  3.93          45 A        \n 4  3.4           10 B        \n 5  3.2            4 B        \n 6  3.52          10 B        \n 7  3.68          24 B        \n 8  3.4           40 B        \n 9  3.7           10 A        \n10  3.75          10 A        \n# ℹ 183 more rows\nNote: if none of the above conditions is true (for example if gpa is NA), then case_when will return a missing value for that case.\nHowever, we will most likely deal with recoding numeric variables or character variables. Make sure that you use quotation marks around character variables. So, for example, if want to recode the character variable ‘gpa_grade’ into a numeric grade ‘gpa_num’ (that has the values 1, 2, 3, 4, 6), we would write:\ngpa_study_hours &lt;- gpa_study_hours |&gt;\n  mutate(gpa_num = case_when(\n    gpa_grade == \"A\" ~ 1,\n    gpa_grade == \"B\" ~ 2,\n    gpa_grade == \"C\" ~ 3,\n    gpa_grade == \"D\" ~ 4,\n    gpa_grade == \"F\" ~ 6))\nOf course, if you want to recode a numberic variable into a numeric variable you do not use quotation marks. These are only used if one of the variables is a character variable.",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Advanced recoding of variables</span>"
    ]
  },
  {
    "objectID": "data_05_advanced_recoding.html#recoding-variables-using-case_when",
    "href": "data_05_advanced_recoding.html#recoding-variables-using-case_when",
    "title": "5  Advanced recoding of variables",
    "section": "",
    "text": "If the score is greater than or equal to 3.7, assign an “A”\nElse if the score is greater than or equal to (&gt;=) 2.7, assign a “B”\nElse if the score is greater than or equal to (&gt;=) 1.7, assign a “C”\nElse if the score is greater than or equal to (&gt;=) 1.3, assign a “D”\nElse, assign an “F”\n\n\n\n\n\n== means ‘equal to’\n!= means ‘not equal to’\n&lt; means ‘smaller than’\n&gt; means ‘larger than’\n&lt;= means ‘equal to or smaller than’\n&gt;= means ‘equal to or larger than’\n& means ‘AND’\n| means ‘OR’\n! means ‘NOT’\n\n\nTo use case_when(), we must tell R where to save the result: either by assigning the result to the current variable, or by assigning it to a new variable in our recoding procedure. For this, we use mutate(). It is very important that you specify a new variable with mutate() while recoding (or an existing variable that will be overwritten). Otherwise R will not know where to put the new, recoded data.\n\n\n\ngpa_study_hours &lt;-\n\nThis first part of the code specifies that we overwrite the existing dataframe ‘gpa_study_hours’.\n\ngpa_study_hours |&gt;\n\nThis part of the code specifies that we are working with the gpa_study_hours data. Note that we use the native pipe operator (|&gt;), see week 2.\n\nmutate(gpa_grade = case_when(\n\nHere we create a new variable called gpa_grade using mutate(). The content will depend on what we specify starting with case_when(. For your own data, you need to change the name of the new variable.\n\ngpa &gt;= 3.7 ~ \"A\",\n\nHere we start specifying our conditions and the output. GPA scores (variable gpa) equal to or greater than 3.7 should become the character A (see the quotation marks around the letter).\nNote: the general form is thus condition ~ value . Multiple statements are separated by a comma.\n\ngpa &gt;= 2.7 ~ \"B\", gpa &gt;= 1.7 ~ \"C\", gpa &gt;= 1.3 ~ \"D\",\n\nHere we continue specifying our conditions and the output. The lines essentially mean ‘else if’, i.e. else if gpa is equal to or larger than 2.7 assign a B, else if gpa is equal to or larger than 1.7 assign a C, etc.\n\ngpa &lt; 1.3 ~ \"F\"))\n\nLastly, we specify that the letter F should be assigned to all gpa values smaller than 1.3.\n\n\n\n\nThe case_when() function is very versatile and can be used to deal with different situations. It is, for example, possible to ‘chain’ various commands and use ‘AND’ or ‘OR’ statements within your code. For those who are interested in learning more, you can have a look at the RDocumentation of the package here.\n\n\n\n\ngpa_study_hours &lt;-\n\nThis first part of the code specifies that we overwrite the existing dataframe ‘gpa_study_hours’.\n\ngpa_study_hours |&gt;\n\nThis part of the code specifies that we are working with the gpa_study_hours data. Note that we use the native pipe operator (|&gt;), see week 2.\n\nmutate(gpa_num = case_when(\n\nHere we create a new variable called gpa_num using mutate(). The content will depend on what we specify starting with case_when(. For your own data, you need to change the names of the new variable as well as the existing variable\n\ngpa_grade == \"A\" ~ 1,\n\nHere we start specifying our conditions and the output. Because gpa_grade is a character vector, we use double quotation marks. The GPA grade “A” should be recoded into the number 1 (without quotation marks).\n\ngpa_grade == \"B\" ~ 2, gpa_grade == \"C\" ~ 3, gpa_grade == \"D\" ~ 4,\n\nHere we continue specifying our conditions and the output.\n\ngpa_grade == \"F\" ~ 6))\n\nLastly, we specify that the number 6 should be assigned to all values with an “F” in gpa_grade.\n\n\n\n\n5.1.1 Multiple comparisons\nThe conditions used by case_when can refer to multiple variables. In the below example we would like to calculate a variable cum laude, which is equal to 1 when the ‘gpa’ is 3.3 or over and the number of study hours is more than 30, and equal to 0 otherwise:\n\ngpa_study_hours &lt;- gpa_study_hours |&gt;\n  mutate(cum_laude = case_when(\n    gpa &gt;= 3.3 & study_hours &gt; 30 ~ 1, \n    gpa &gt;= 3.3 ~ 0,\n    gpa &lt; 3.3 ~ 0))\n\n\nmutate(cum_laude = case_when(\n\nHere we create a new variable called cum_laude using mutate().\n\ngpa &gt;= 3.3 & study_hours &gt; 30 ~ 1,\n\nOur first condition is that gpa needs to be 3.3 or higher and that study_hours needs to be larger than 30. If this condition is met, cum_laude will be equal to 1.\n\ngpa &gt;= 3.3 ~ 0, gpa &lt; 3.3 ~ 0))\n\nWe also need to specify the alternatives. First, if the previous condition is not met, but gpa is over 3.3, assign a 0. Additionally, if the previous conditions are not met, but gpa is under 3.3, assign a 0 to the new variable ‘cum_laude’.\n\n\n\nWhen working with your own (existing) data sets, have a close look at the ‘existing’ variables, i.e. the one you wish to recode. Make sure that you correctly specify all alternatives, in particular if your data has missing values on one (or multiple) variables. After recoding, we generally advise you to inspect the outcome variable carefully to see whether the outcome is exactly how you intended it to be.",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Advanced recoding of variables</span>"
    ]
  },
  {
    "objectID": "data_06_merging_data.html",
    "href": "data_06_merging_data.html",
    "title": "6  Combining & joining data sets",
    "section": "",
    "text": "6.1 Adding rows or columns",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combining & joining data sets</span>"
    ]
  },
  {
    "objectID": "data_06_merging_data.html#adding-rows-or-columns",
    "href": "data_06_merging_data.html#adding-rows-or-columns",
    "title": "6  Combining & joining data sets",
    "section": "",
    "text": "6.1.1 Adding rows\nIf we have two datasets with the same columns (variables), we can add the rows of the two data sets together using bind_rows from package dplyr (this package is loaded with the tidyverse).\nAs an example, we have two data sets with the same variables, names and age:\n\ndta1 &lt;- data.frame(name = c(\"Billy\", \"Xin\", \"Hugo\"), age = c(20, 30, 40))\ndta2 &lt;- data.frame(name = c(\"Theresa\", \"Elin\", \"Lena\"), age = c(25, 35, 45))\n\ndta1 \n\n   name age\n1 Billy  20\n2   Xin  30\n3  Hugo  40\n\ndta2\n\n     name age\n1 Theresa  25\n2    Elin  35\n3    Lena  45\n\n\nWe can combine these data sets as follows:\n\ndta_combined &lt;- bind_rows(dta1, dta2)\ndta_combined\n\n     name age\n1   Billy  20\n2     Xin  30\n3    Hugo  40\n4 Theresa  25\n5    Elin  35\n6    Lena  45\n\n\n\n\n6.1.2 Adding columns\nIf we want to add additional columns to a data frame, we can use bind_cols from package dplyr (this package is loaded with the tidyverse).\nFor example, if we have two datasets, one with name and age of people, and another with their self-reported gender:\n\ndta &lt;- data.frame(name = c(\"Billy\", \"Xin\", \"Hugo\"), age = c(20, 30, 40))\ngender &lt;- data.frame(gender = c(\"Non-binary\", \"Female\", \"Male\"))\n\n\ndta\n\n   name age\n1 Billy  20\n2   Xin  30\n3  Hugo  40\n\ngender\n\n      gender\n1 Non-binary\n2     Female\n3       Male\n\n\nWe can combine this, using bind_cols:\n\nbind_cols(dta, gender)\n\n   name age     gender\n1 Billy  20 Non-binary\n2   Xin  30     Female\n3  Hugo  40       Male\n\n\nImportant: bind_cols will match by position, so the order of rows must be exactly the same. For more flexible ways of adding columns to a dataset, see ‘joining of data sets’ below.",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combining & joining data sets</span>"
    ]
  },
  {
    "objectID": "data_06_merging_data.html#joining-data-sets",
    "href": "data_06_merging_data.html#joining-data-sets",
    "title": "6  Combining & joining data sets",
    "section": "6.2 Joining data sets",
    "text": "6.2 Joining data sets\nIf we have two datasets with a common variable (i.e. a variable that has the same name and comparable coding, for example a country name or a unique identifier), we can combine the datasets, using join from dplyr.\nLet’s start with some toy data on 4 countries:\n\ncountry_dta1 &lt;- data.frame(country = c(\"USA\", \"Germany\", \"Netherlands\", \"Kenya\"),\n                           population = c(332, 84, 18, 56))\n\ncountry_dta2 &lt;- data.frame(country = c(\"Netherlands\", \"Germany\", \"Kenya\", \"Argentina\"),\n                          official_name = c(\"Nederland\", \"Bundesrepublik Deutschland\", \"Republic of Kenya\", \"República Argentina\"))\n\ncountry_dta1\n\n      country population\n1         USA        332\n2     Germany         84\n3 Netherlands         18\n4       Kenya         56\n\ncountry_dta2\n\n      country              official_name\n1 Netherlands                  Nederland\n2     Germany Bundesrepublik Deutschland\n3       Kenya          Republic of Kenya\n4   Argentina        República Argentina\n\n\nNote that only three countries feature in both datasets, but the variable country is present in both data frames and the values are the same for the three countries that are in both datasets.\nWe can merge the data in these datasets as follows, using so called ‘joins’ from pacakge dplyr. The function full_join returns all rows in both datasets:\n\njoined_data &lt;- full_join(x = country_dta1, \n                         y = country_dta2, \n                         by = c(\"country\"))\n\n\nx = country_dta1\n\nThis specifies the first of the two datasets. Replace with your own dataset when working with your own data.\n\ny = country_dta2\n\nThis specifies the second of the two datasets.\n\nby = c(\"country\")\n\nThis specifies the column on which we would like to match values of the two data frames (specified as a vector, i.e. between double parentheses). In our example, we use the variable country, as this variable is comparable between our two data sets.\n\n\n\njoined_data\n\n      country population              official_name\n1         USA        332                       &lt;NA&gt;\n2     Germany         84 Bundesrepublik Deutschland\n3 Netherlands         18                  Nederland\n4       Kenya         56          Republic of Kenya\n5   Argentina         NA        República Argentina\n\n\nWe can see that all five countries are present in the joined data set. The USA is missing from country_dta2, so has a missing value (NA) on official_name in the joined data set. Argentina is missing from country_dta1, so has a missing value on population in the joined data set.\nThere are four types of joins:\n\n\n\nFunction\nIncludes\n\n\n\n\ninner_join()\nAll rows in x and y.\n\n\nleft_join()\nAll rows in x.\n\n\nright_join()\nAll rows in y.\n\n\nfull_join()\nAll rows in x or y.\n\n\n\nWe can see the result if we run and print the four types of joins:\n\n# Inner join: only the three countries that are in both data sets\ninner_join(x = country_dta1, y = country_dta2, by = c(\"country\"))\n\n      country population              official_name\n1     Germany         84 Bundesrepublik Deutschland\n2 Netherlands         18                  Nederland\n3       Kenya         56          Republic of Kenya\n\n# Left join: only the four countries in the first data set\nleft_join(x = country_dta1, y = country_dta2, by = c(\"country\"))\n\n      country population              official_name\n1         USA        332                       &lt;NA&gt;\n2     Germany         84 Bundesrepublik Deutschland\n3 Netherlands         18                  Nederland\n4       Kenya         56          Republic of Kenya\n\n# Right join: only the four countries in the second data set\nright_join(x = country_dta1, y = country_dta2, by = c(\"country\"))\n\n      country population              official_name\n1     Germany         84 Bundesrepublik Deutschland\n2 Netherlands         18                  Nederland\n3       Kenya         56          Republic of Kenya\n4   Argentina         NA        República Argentina\n\n# Full join: all five countries\nfull_join(x = country_dta1, y = country_dta2, by = c(\"country\"))\n\n      country population              official_name\n1         USA        332                       &lt;NA&gt;\n2     Germany         84 Bundesrepublik Deutschland\n3 Netherlands         18                  Nederland\n4       Kenya         56          Republic of Kenya\n5   Argentina         NA        República Argentina\n\n\n\n6.2.1 Joining with different variables\nIf we have two data frames with different names, we need to instruct R which variables are to be compared.\nFor example, suppose we have a third data frame with country information:\n\ncountry_dta3 &lt;- data.frame(country_name = c(\"USA\", \"Netherlands\", \"Germany\"),\n                           capital_city = c(\"Washington DC\", \"Amsterdam\", \"Berlin\"))\ncountry_dta3\n\n  country_name  capital_city\n1          USA Washington DC\n2  Netherlands     Amsterdam\n3      Germany        Berlin\n\n\nWe note that the variable containing the country name is called country_name in this data frame. In order to join it with country_dta1, we need to specify by as follows:\n\nfull_join(x = country_dta1, y = country_dta3, \n          by = c(\"country\" = \"country_name\"))\n\n      country population  capital_city\n1         USA        332 Washington DC\n2     Germany         84        Berlin\n3 Netherlands         18     Amsterdam\n4       Kenya         56          &lt;NA&gt;\n\n\n\nby = c(\"country\" = \"country_name\")\n\nThe syntax \"country\" = \"country_name\" means that we are comparing variable country from the first data set to variable country_name from the second data set.\n\n\nNote that this solution only works when the country names are spelled identically (and only the variable name is different). The below will not work properly, because the country names are not comparable between the two datasets:\n\ncountry_dta4 &lt;- data.frame(country = c(\"United States of America\", \"Deutschland\", \"Nederland\"),\n                           capital_city = c(\"Washington DC\", \"Berlin\", \"Amsterdam\"))\n\ncountry_dta4\n\n                   country  capital_city\n1 United States of America Washington DC\n2              Deutschland        Berlin\n3                Nederland     Amsterdam\n\nfull_join(country_dta1, country_dta4)\n\n                   country population  capital_city\n1                      USA        332          &lt;NA&gt;\n2                  Germany         84          &lt;NA&gt;\n3              Netherlands         18          &lt;NA&gt;\n4                    Kenya         56          &lt;NA&gt;\n5 United States of America         NA Washington DC\n6              Deutschland         NA        Berlin\n7                Nederland         NA     Amsterdam\n\n\nIn such cases, the solution would be to first recode the variable that is used for joining, for example:\n\ncountry_dta4_recoded &lt;- country_dta4 |&gt;\n  mutate(country = recode(country, \n                          \"United States of America\" = \"USA\",\n                          \"Deutschland\" = \"Germany\",\n                          \"Nederland\" = \"Netherlands\"))\n\nfull_join(country_dta1, country_dta4_recoded)\n\n      country population  capital_city\n1         USA        332 Washington DC\n2     Germany         84        Berlin\n3 Netherlands         18     Amsterdam\n4       Kenya         56          &lt;NA&gt;",
    "crumbs": [
      "Working with data in R",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Combining & joining data sets</span>"
    ]
  },
  {
    "objectID": "part_statistical_analysis.html",
    "href": "part_statistical_analysis.html",
    "title": "Statistical analysis in R",
    "section": "",
    "text": "In this part, we discuss the R code necessary for running various types of statistical analysis discussed in the course.",
    "crumbs": [
      "Statistical analysis in R"
    ]
  },
  {
    "objectID": "analysis_01_descriptives.html",
    "href": "analysis_01_descriptives.html",
    "title": "7  Measures of central tendency and dispersion",
    "section": "",
    "text": "7.1 Measures of central tendency\nThe most commonly used measures of central tendency are the mean, median and the mode. To show how we calculate them using R, we will use the three variables:\ndirections &lt;- factor(c(\"East\", \"West\", \"East\", \"North\", \"North\", \"East\", \"West\", \"West\", \"West\", \"East\", \"North\"))\ntemperature &lt;- factor(c(\"low\", \"high\", \"medium\", \"high\", \"low\", \"medium\", \"high\"), levels = c(\"low\", \"medium\", \"high\"), ordered = TRUE)\nexam_points &lt;- c(2, 7, 3, 4, 2, 0)\n\ndirections #nominal\n\n [1] East  West  East  North North East  West  West  West  East  North\nLevels: East North West\n\ntemperature #ordinal\n\n[1] low    high   medium high   low    medium high  \nLevels: low &lt; medium &lt; high\n\nexam_points #interval/ratio\n\n[1] 2 7 3 4 2 0",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Measures of central tendency and dispersion</span>"
    ]
  },
  {
    "objectID": "analysis_01_descriptives.html#measures-of-central-tendency",
    "href": "analysis_01_descriptives.html#measures-of-central-tendency",
    "title": "7  Measures of central tendency and dispersion",
    "section": "",
    "text": "7.1.1 Mode\nThe mode is the value that has highest number of occurrences in a set of data. We can first have a look at the distribution of the values with the table() function\n\ntable(directions)\n\nBased on this, we can see that there are two modes (East and West).\n\ndirections\n East North  West \n    4     3     4\n\nIf we want to calculate the mode, we can use a package called DescTools. This is a collection of miscellaneous basic statistic functions for efficiently describing data. The package contains the Mode() (notice the upper case M) function.\nWe load the necessary packages as follows:\n\nlibrary(DescTools) # This loads DescTools\n\nTo calculate the mode, we write:\n\nMode(directions)\n\n[1] East West\nattr(,\"freq\")\n[1] 4\nLevels: East North West\n\n\nThe results show that [1] East West are the two modes.\n\n\n7.1.2 Median\nThe median is the value that, assuming the dataset is ordered from smallest to largest, falls in the middle. To calculate it, we use the Median() command from the DescTools package (again, notice the upper case M). This can deal with factors:\n\nMedian(temperature)\n\n\n&gt; Median(temperature)\n[1] medium\nLevels: low &lt; medium &lt; high\n\n\n\n7.1.3 Mean\nThe mean of a set of observations is calculated by adding up all the values and then divide by the total number of values. Let us first calculate the sum of all values via sum().\n\nsum(exam_points)\n\n[1] 18\n\n\nNext, we calculate the number of observations via length().\n\nlength(exam_points)\n\n[1] 6\n\n\nTo calculate the mean we can simply combine these two:\n\nsum(exam_points)/length(exam_points)\n\n[1] 3\n\n\nor we can simply use the mean() function:\n\nmean(exam_points, na.rm = TRUE)\n\n[1] 3\n\n\n\n, na.rm = TRUE\n\nWe add the last part , na.rm = TRUE to tell R to omit any possible missing values from the calculation. Here, there were no missing values but in most existing data sets you will find them.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Measures of central tendency and dispersion</span>"
    ]
  },
  {
    "objectID": "analysis_01_descriptives.html#measures-of-dispersion",
    "href": "analysis_01_descriptives.html#measures-of-dispersion",
    "title": "7  Measures of central tendency and dispersion",
    "section": "7.2 Measures of dispersion",
    "text": "7.2 Measures of dispersion\nTo find the minimum and maximum value of a vector or column we can use the max and min functions.\n\nmin()\nmax()\n\nApplied to the ordinal and interval/ratio variable that we have created:\n\nmin(temperature, na.rm = TRUE)\n\n[1] low\nLevels: low &lt; medium &lt; high\n\nmax(exam_points, na.rm = TRUE)\n\n[1] 7\n\n\n\n, na.rm = TRUE\n\nWe add the last part , na.rm = TRUE to tell R to omit any possible missing values from the calculation. Here, there were no missing values but in most existing data sets you will find them.\n\n\n\n7.2.1 Range and interquartile range\nrange() returns a vector containing the minimum and maximum of all the given arguments.\n\nrange(x, na.rm = TRUE)\n\n\n, na.rm = TRUE\n\nWe add the last part , na.rm = TRUE in the range() function to tell R to omit any possible missing values from the calculation. Here, there were no missing values but in most existing data sets you will find them.\n\n\nWe can calculate the range of the ordinal and interval/ratio variable that we have created:\n\nrange(temperature, na.rm = TRUE)\n\n[1] low  high\nLevels: low &lt; medium &lt; high\n\nrange(exam_points, na.rm = TRUE)\n\n[1] 0 7\n\n\n\n7.2.1.1 Interquatile range\nTo get an overview of the interquartile range, we can use the summary() function:\n\nsummary(exam_points)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    2.00    2.50    3.00    3.75    7.00 \n\n\n\n\n\n7.2.2 Standard deviation and variance\nYou can calculate standard deviation in R using the sd() function. By default, this will generate the sample standard deviation. If you wish to use it to generate the population standard deviation, you can make the appropriate adjustment (multiply by sqrt((n-1)/n)).\n\nsd(exam_points, na.rm = TRUE)\n\n[1] 2.366432\n\n\n\n, na.rm = TRUE\n\nWe add the last part , na.rm = TRUE to tell R to omit any possible missing values from the calculation. Here, there were no missing values but in most existing data sets you will find them.\n\n\nTo calculate the variance, we can simply use the var() function:\n\nvar(exam_points, na.rm = TRUE)\n\n[1] 5.6\n\n\n\n, na.rm = TRUE\n\nWe add the last part , na.rm = TRUE to tell R to omit any possible missing values from the calculation. Here, there were no missing values but in most existing data sets you will find them.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Measures of central tendency and dispersion</span>"
    ]
  },
  {
    "objectID": "analysis_01_descriptives.html#doing-operations-in-data-frames",
    "href": "analysis_01_descriptives.html#doing-operations-in-data-frames",
    "title": "7  Measures of central tendency and dispersion",
    "section": "7.3 Doing operations in data frames",
    "text": "7.3 Doing operations in data frames\nAs explained in ?sec-data-week1, you use the “$” symbol to call variables in data frames. Therefore, if we want to use any of the functions that were covered so far (mean(), table(), sd(), var(), etc.) you simply use thus operator to access specific variables in data frames. If we want to calculate the mean and standard deviation of movie scores (‘Score’) in ‘deniro_data’ we would write:\n\nlibrary(rio)\ndeniro_data &lt;- import(file = \"deniro.csv\") \n\n\nmean(deniro_data$Score, na.rm = TRUE)\n\n[1] 58.1954\n\nsd(deniro_data$Score, na.rm = TRUE)\n\n[1] 28.06754\n\n\n\n, na.rm = TRUE\n\nWe add the last part , na.rm = TRUE to tell R to omit any possible missing values from the calculation. Here, there were no missing values but in most existing data sets you will find them.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Measures of central tendency and dispersion</span>"
    ]
  },
  {
    "objectID": "analysis_01_descriptives.html#descriptive-statistics-for-an-entire-data-frame",
    "href": "analysis_01_descriptives.html#descriptive-statistics-for-an-entire-data-frame",
    "title": "7  Measures of central tendency and dispersion",
    "section": "7.4 Descriptive statistics for an entire data frame",
    "text": "7.4 Descriptive statistics for an entire data frame\nThere are many summary statistics available in R. An easy way to get a basic overview of a data frame is the describe() function from the ‘psych’ package. If you need to install the pakcges, you can do so using install.packages(\"DescTools\") or install.packages(\"psych\") (not necessary on University PCs).\nTo use the describe() function from the ‘psych’ package, we write:\n\nlibrary(psych)\n\n\nAttaching package: 'psych'\n\n\nThe following objects are masked from 'package:DescTools':\n\n    AUC, ICC, SD\n\ndescribe(deniro_data, na.rm = TRUE, skew = FALSE, ranges = TRUE)\n\n       vars  n    mean    sd  min  max range   se\nYear      1 87 1995.98 12.94 1968 2016    48 1.39\nScore     2 87   58.20 28.07    4  100    96 3.01\nTitle*    3 87   44.00 25.26    1   87    86 2.71\n\n\n\n, na.rm = TRUE\n\nWe add , na.rm = TRUE to tell R to omit missing values.\n\n, skew = FALSE\n\nVia this part of the code, we tell R whether it should calculate the skewness of the variable. I would recommend to leave it out but if you wish to include it, change it to , skew = TRUE.\n\n, ranges = TRUE\n\nWe add , ranges = TRUE to tell R to calculate the range. If you do not want this, you can set it to , ranges = FALSE\n\n\nAs you can see, this produces a relatively straightforward summary table.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Measures of central tendency and dispersion</span>"
    ]
  },
  {
    "objectID": "analysis_02_graphs.html",
    "href": "analysis_02_graphs.html",
    "title": "8  Graphing using ggplot2",
    "section": "",
    "text": "8.1 General introduction to ggplot\nPlots using ggplot 2 are designed in layers.\nEvery ggplot starts with the ggplot function, in which you define the dataset that is used and the main variables. For example in the graph below we define loan50 as the data . Next, we ‘map’ the variables that we are using using the aes function, which maps variables to elements of the graph. In the below example we indicate that we want to use variable total_income on the x-axis and loan_amount on the y-axis.\ndata(loan50) # This loads the dataset loan50 from openintro\nggplot(data = loan50, \n       mapping = aes(x = total_income, y = loan_amount))\nThe above code produces an ‘empty’ graph, because we have not yet told R what kind of graph we would like to produce: perhaps a line graph, scatter plot or something else? We need to add a geom layer to the graph in order to produce points, lines or bars in the graph. Below we add points to the graph using geom_point(). Note that we also add a plus sign (+) after the second line, which ensures that we add the points to our graph:\nggplot(data = loan50, \n       mapping = aes(x = total_income, y = loan_amount)) +\n  geom_point()\nWe can also add additional layers to make the graph look differently, change labels or add further elements to the graph. You will find examples of this for each of the graph types below.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Graphing using ggplot2</span>"
    ]
  },
  {
    "objectID": "analysis_02_graphs.html#general-introduction-to-ggplot",
    "href": "analysis_02_graphs.html#general-introduction-to-ggplot",
    "title": "8  Graphing using ggplot2",
    "section": "",
    "text": "8.1.1 Saving a ggplot to a file\nIf you would like to use a graph in, for example, a Word document or Powerpoint, you can export the ggplot using the ggsave command. This saves the last plotted ggplot to a file:\n\nggplot(data = loan50, \n       mapping = aes(x = total_income, y = loan_amount)) +\n  geom_point()\n\nggsave(filename = \"scatterplot_example.png\", \n       width=7, \n       height=7)\n\n\nfilename = \"scatterplot_example.png\"\n\nYou need to give the file a name and an extension. In this example, the file name is set to scatterplot_example.png. This creates a PNG file, which often works well if you want to use the graph in a text document or presentation. You can also create other file formats, such as a jpeg or pdf file, by changing the extension, i.e. scatterplot_example.pdf.\n\nwidth = 7\n\nThis provides the width of the graph in inches.\n\nheight = 7\n\nThis provides the height of the graph in inches.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Graphing using ggplot2</span>"
    ]
  },
  {
    "objectID": "analysis_02_graphs.html#scatterplot",
    "href": "analysis_02_graphs.html#scatterplot",
    "title": "8  Graphing using ggplot2",
    "section": "8.2 Scatterplot",
    "text": "8.2 Scatterplot\nA scatterplot provides an overview of each unique point for two numerical values. It is most useful when there are many unique values.\nIn the below example we plot total_income on the x-axis (horizontally) and loan_amount on the y-axis (vertically).\n\ndata(loan50) # This loads the dataset loan50 from openintro\nggplot(data = loan50, \n       mapping = aes(x = total_income, y = loan_amount)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\ndata = loan50\n\nThis bit of code says that the data frame we are using is called loan50. For your own graph, you would replace loan50 by the name of the data.frame you are using.\n\nmapping = aes(x = total_income, y = loan_amount)\n\nThis part of the code says that total_income is the variable we would like to display on the x axis and loan_amount is to be displayed on the y axis. For your own graph, you would thus replace total_income and loan_amount by your own variables.\n\ngeom_point()\n\nThis tells ggplot2 that we would like to create a scatterplot with points for the two variables. We do not require any extra arguments for a basic scatterplot.\n\n\n\n8.2.1 Scatterplot: additional options\nTo make the scatterplot look somewhat nicer, we can add extra options. Note that to add options to a plot we simply use the + sign at the end of the line:\n\ndata(loan50)\nggplot(data = loan50, \n       mapping = aes(x = total_income, y = loan_amount)) +\n  geom_point(size=2, colour = \"grey\") +\n  labs(title = \"Total income and loan amount\",\n       x = \"Total Income\",\n       y = \"Loan Amount\") +\n  scale_x_continuous(labels=scales::label_dollar()) +\n  scale_y_continuous(labels=scales::label_dollar()) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ngeom_point(size = 2, colour = \"grey\")\n\nThese options allow us to set the size and the colour of the dots. Note that the colour name is a string and needs to be put in quotation marks: “grey”.\n\nlabs(title = \"Title\", x = \"x axis title\", y = \"y axis title\")\n\nThis option adds nicer names for the title of the graph, and the titles of the x and y axis.\n\nscale_x_continuous(labels=scales::label_dollar())\n\nThis options and its ‘sister’ scale_y_continuous change how the values and axes are presented. In this case we would like to display the values in dollars. This can be done with scales::label_dollar().\n\ntheme_minimal()\n\nIn order to change the entire look of a graph, you can use the theme_* functions (where in place of star you can add various options, such as theme_minimal(), theme_classic() or theme_light().\n\n\n\n\n8.2.2 Scatterplot: multiple groups\nSometimes you have different groups in your data that you would like to visualise. In this case you can modify the geom_point to change the colour or shape of the points by a group. In this example, the colour of the dot will indicate home ownership:\n\ndata(loan50)\nggplot(data = loan50, \n       mapping = aes(x = total_income, y = loan_amount)) +\n  geom_point(aes(colour = homeownership)) \n\n\n\n\n\n\n\n\n\ngeom_point(aes(colour = homeownership))\n\nThis indicates that the colour of the points will vary by homeownership (rent, mortgage, own). R will automatically choose a colour for each group. For your own graph, you would change homeownership to your own grouping variable name. Note: don’t forget to put colour = homeownership inside aes().\n\n\n\ndata(loan50)\nggplot(data = loan50, \n       mapping = aes(x = total_income, y = loan_amount)) +\n  geom_point(aes(shape = homeownership)) \n\n\n\n\n\n\n\n\n\ngeom_point(aes(shape = homeownership))\n\nThis indicates that the shape of the points will vary by homeownership (rent, mortgage, own). R will automatically choose a shape for each group. For your own graph, you would change homeownership to your own grouping variable name. Note: don’t forget to put shape = homeownership inside aes().\n\n\n\n\n8.2.3 Scatterplot: separate graphs per group\nSometimes instead of using different colours or shapes for a group you would like to produce a separate graph for each group. These are called ‘facets’ and can be produced like this:\n\ndata(loan50)\nggplot(data = loan50, \n       mapping = aes(x = total_income, y = loan_amount)) +\n  geom_point() +\n  facet_wrap(vars(homeownership))\n\n\n\n\n\n\n\n\n\nfacet_wrap(vars(homeownership))\n\nThis indicates that we would like to produce a separate ‘facet’ for each value of homeownership (rent, mortgage, own). For your own graph, you would change homeownership to your own grouping variable name. Note: don’t forget to put the variable name within vars(). There are additional options for the function facet_wrap to control how these are displayed, for example the number of rows (nrow) and columns (ncol).",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Graphing using ggplot2</span>"
    ]
  },
  {
    "objectID": "analysis_02_graphs.html#dot-plot",
    "href": "analysis_02_graphs.html#dot-plot",
    "title": "8  Graphing using ggplot2",
    "section": "8.3 Dot plot",
    "text": "8.3 Dot plot\nA dot plot summarises the values for a single variable.\n\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = interest_rate)) +\n  geom_dotplot()\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\n\n\n\n\ndata = loan50\n\nThis bit of code says that the data frame we are using is called loan50. For your own graph, you would replace loan50 by the name of the data.frame you are using.\n\nmapping = aes(x = interest_rate)\n\nThis part of the code says that interest_rate is the variable we would like to display. For your own graph, you would thus replace interest_rate by your own variables.\n\ngeom_dotplot()\n\nThis tells ggplot2 that we would like to create a dotplot. We do not require additional options for a basic dot plot.\n\n\n\n8.3.1 Dot plot: additional options\n\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = interest_rate)) +\n  geom_dotplot() +\n  labs(title = \"Dot plot of interest rate\",\n       x = \"Interest rate\",\n       y = \"\") +\n  scale_y_continuous(labels=NULL) +\n  scale_x_continuous(labels = scales::label_percent(scale=1),\n                     breaks=seq(5,25,by=5)) +\n  theme_minimal()\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\n\n\n\n\n\nlabs(title = \"Title\", x = \"x axis title\", y = \"\")\n\nThis option adds nicer names for the title of the graph, and the titles of the x and y axis. In the example we remove the y axis title by setting it to nothing (\"\")\n\nscale_x_continuous(labels = scales::label_percent(scale=1), breaks=seq(5,25,by=5)\n\nThis option changes how the x-axis is presented. In this case we would like to display the values in percentages. This can be done with scales::percent_format(). We also set breaks=seq(5,25, by=5) to tell R that we would like to have x-axis values displayed at 5%, 10%, 15%, 20% and 25%.\n\ntheme_minimal()\n\nIn order to change the entire look of a graph, you can use the theme_* functions (where in place of star you can add various options, such as theme_minimal(), theme_classic() or theme_light().",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Graphing using ggplot2</span>"
    ]
  },
  {
    "objectID": "analysis_02_graphs.html#histogram",
    "href": "analysis_02_graphs.html#histogram",
    "title": "8  Graphing using ggplot2",
    "section": "8.4 Histogram",
    "text": "8.4 Histogram\nA histogram provide an overview of a numerical variable, by presenting the counts of (binned) values.\n\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = interest_rate)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\ndata = loan50\n\nThis bit of code says that the data frame we are using is called loan50. For your own graph, you would replace loan50 by the name of the data.frame you are using.\n\nmapping = aes(x = interest_rate)\n\nThis part of the code says that interest_rate is the variable we would like to display. For your own graph, you would thus replace interest_rate by your own variable.\n\ngeom_histogram()\n\nThis tells ggplot2 that we would like to create a histogram. This produces a basic histogram with 30 bins (see below for options that changes this default).\n\n\n\n8.4.1 Histogram: controlling bin size\nThere are various options to control how the data of the variable is grouped: controlling the width of the bins, the number of bins or setting manual break points:\n\n8.4.1.1 Width of the bins\n\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = interest_rate)) +\n  geom_histogram(binwidth = 2.5)\n\n\n\n\n\n\n\n\n\ngeom_histogram(binwidth = 2.5)\n\nThe option binwidth sets the width of the bins, in this example to 2.5.\n\n\n\n\n8.4.1.2 Number of bins\n\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = interest_rate)) +\n  geom_histogram(bins = 10)\n\n\n\n\n\n\n\n\n\ngeom_histogram(bins = 10)\n\nThe option bins sets the number of bins, in this example to 10.\n\n\n\n\n8.4.1.3 Manual breakpoints\n\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = interest_rate)) +\n  geom_histogram(breaks=seq(5,27.5,by=2.5))\n\n\n\n\n\n\n\n\n\ngeom_histogram(breaks=seq(5,27.5,by=2.5)\n\nThe option breaks sets exact breakpoints for the bins in the histograms. In this example we set breakpoints from 5 to 27.5 by increments of 2.5 (i.e. the first bin is 5-7.5, the second one 7.5-10, etc.).\n\n\n\n\n\n8.4.2 Histogram: additional options\n\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = interest_rate)) +\n  geom_histogram(breaks=seq(5,27.5,by=2.5), colour = \"black\", fill=\"grey\") +\n  labs(title = \"Histogram of interest rate\",\n       x = \"Interest Rate\", y= \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ngeom_histogram(colour = \"black\", fill=\"grey\")\n\nThis controls the look and feel of the bars. In this example we add a black border to the bar by setting the colour and change the fill colour to grey.\n\nlabs(title = \"Title\", x = \"x axis title\", y = \"y axis title\")\n\nThis option adds nicer names for the title of the graph, and the titles of the x and y axis.\n\ntheme_minimal()\n\nIn order to change the entire look of a graph, you can use the theme_* functions (where in place of star you can add various options, such as theme_minimal(), theme_classic() or theme_light().",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Graphing using ggplot2</span>"
    ]
  },
  {
    "objectID": "analysis_02_graphs.html#box-plot",
    "href": "analysis_02_graphs.html#box-plot",
    "title": "8  Graphing using ggplot2",
    "section": "8.5 Box plot",
    "text": "8.5 Box plot\nA box plot summarizes a variable, using five statistics, including the median, Q1 and Q3.\n\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = interest_rate)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\ndata = loan50\n\nThis bit of code says that the data frame we are using is called loan50. For your own graph, you would replace loan50 by the name of the data.frame you are using.\n\nmapping = aes(x = interest_rate)\n\nThis part of the code says that interest_rate is the variable we would like to display. For your own graph, you would thus replace interest_rate by your own variable.\n\ngeom_boxplot()\n\nThis tells ggplot2 that we would like to create a boxplot. This produces a basic boxplot.\n\n\n\n8.5.1 Box plot: additional options\nA box plot summarizes a variable, using five statistics, including the median, Q1 and Q3.\n\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(y = interest_rate)) +\n  geom_boxplot(fill = \"grey\") +\n  labs(title = \"Boxplot of interest rate\", \n       y = \"Interest rate\") +\n  theme_minimal() +\n  theme(axis.text.x=element_blank(),axis.ticks.x=element_blank())\n\n\n\n\n\n\n\n\n\naes(y = interest_rate)\n\nIf we map interest_rate to the y-axis (rather than the x-axis) we change the orientation of the boxplot.\n\ngeom_boxplot(fill = \"grey\")\n\nThe option fill sets the colour of the boxes. Note that the colour has to be provided in between quotation marks (i.e. \"grey\").\n\nlabs(title = \"Title\", x = \"x axis title\", y = \"y axis title\")\n\nThis option adds nicer names for the title of the graph, and the titles of the x and y axis.\n\ntheme_minimal()\n\nIn order to change the entire look of a graph, you can use the theme_* functions (where in place of star you can add various options, such as theme_minimal(), theme_classic() or theme_light().\n\ntheme(axis.text.x=element_blank(),axis.ticks.x=element_blank())\n\nIn order to make sure no labels and ticks are printed on the x-axis we remove them (since these are meaningless).\n\n\n\n\n8.5.2 Box plot: multiple groups\n\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = interest_rate, y = homeownership)) +\n  geom_boxplot() \n\n\n\n\n\n\n\n\n\naes(x = interest_rate, y = homeownership)\n\nIn this example we display interest rate by type of home ownership (own, mortgage, rent). Here we map interest_rate to the x-axis and homeownership to the y-axis. Note the second variable (in this case homeownership) needs to be a factor or character variable (i.e. categorical).",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Graphing using ggplot2</span>"
    ]
  },
  {
    "objectID": "analysis_02_graphs.html#bar-plot",
    "href": "analysis_02_graphs.html#bar-plot",
    "title": "8  Graphing using ggplot2",
    "section": "8.6 Bar plot",
    "text": "8.6 Bar plot\nA bar plot can be used to display counts or proportions of categorical variables. You can also use it to display summary statistics (e.g. means) for various groups.\n\nNote that a histogram is used to display frequencies of (binned) numerical (interval-ratio) variables, while a bar plot is used to display frequencies of categorical variables.\n\n\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = homeownership)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\ndata = loan50\n\nThis bit of code says that the data frame we are using is called loan50. For your own graph, you would replace loan50 by the name of the data.frame you are using.\n\nmapping = aes(x = homeownership)\n\nThis part of the code says that homeownership is the variable we would like to display. For your own graph, you would thus replace homeownership by your own variable.\n\ngeom_bar()\n\nThis tells ggplot2 that we would like to create a barplot. This produces a basic barplot.\n\n\n\n8.6.1 Bar plot: additional options\n\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = homeownership)) +\n  geom_bar(fill = \"grey\", colour = \"black\") +\n  labs(title = \"Homeownership\",\n       x = \"Home ownership type\",\n       y = \"Count\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\ngeom_bar(fill = \"grey\", colour = \"black\")\n\nThe option fill sets the colour of the bars and colour sets the colour of the border. Note that the colour has to be provided in between quotation marks (i.e. \"grey\").\n\nlabs(title = \"Title\", x = \"x axis title\", y = \"y axis title\")\n\nThis option adds nicer names for the title of the graph, and the titles of the x and y axis. Note: if you would like to change the way the categories are presented (i.e. ‘Rent’ instead of ‘rent’), you would need to recode the variable homeownership.\n\ntheme_minimal()\n\nIn order to change the entire look of a graph, you can use the theme_* functions (where in place of star you can add various options, such as theme_minimal(), theme_classic() or theme_light().\n\n\n\n\n8.6.2 Bar plot: multiple groups\nWhen you have two categorical variables, you can create a bar plot that displays both variables. In the below case we display homeownership and verified_income.\n\n8.6.2.1 Stacked bar plot\n\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = homeownership)) +\n  geom_bar(aes(fill = verified_income))\n\n\n\n\n\n\n\n\n\ngeom_bar(aes(fill = verified_income))\n\nThe option fill (within aes ) indicates that we want to subdivide each bar by the categories of verified_income.\n\n\nNote: if you would like to change the labels in the legend for this graph, the best thing to do is to rename and recode the variable (verified_income).\n\n\n8.6.2.2 Side-by-side bar plot\n\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = homeownership)) +\n  geom_bar(aes(fill = verified_income), position=\"dodge\")\n\n\n\n\n\n\n\n\n\ngeom_bar(aes(fill = verified_income), position = \"dodge\")\n\nThe option fill (within aes ) indicates that we want to subdivide each bar by the categories of verified_income. We add position = \"dodge\" to create a side-by-side bar plot instead of a stacked bar plot.\n\n\n\n\n8.6.2.3 Percent stacked bar plot\nThis type of bar plot stacks the subcategories, but calculates them as a percentage.\n\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = homeownership)) +\n  geom_bar(aes(fill = verified_income), position = \"fill\") +\n  scale_y_continuous(labels = scales::label_percent()) + \n  labs(y = \"Percentage\")\n\n\n\n\n\n\n\n\n\ngeom_bar(aes(fill = verified_income), position = \"fill\")\n\nThe option fill (within aes ) indicates that we want to subdivide each bar by the categories of verified_income.\n\nscale_y_continuous(labels = scales::label_percent())\n\nThis ensures that percentages rather than proportions are displayed on the y-axis.\n\nlabs(y = \"Percentage\")\n\nTo ensure that the y-axis says ‘Percentage’ instead of ‘counts’, we modify the label of the y axis.\n\n\n\n\n\n8.6.3 Bar plot of means\nWe can also use bar plots to display statistics (for example means) of a numerical variable for each category of a categorical variable. For example, let’s plot the mean interest_rate per type of homeownership.\nFirst, we need to produce a data frame that shows the mean interest rate per type of home ownership. We can do this using group_by and summarise from the dplyr package. We will discuss these functions later on in the course in more detail. For now it is enough to understand that we are calculating the mean interest rate for each type of home ownership:\n\ndata(loan50)\nloan50_means &lt;- loan50 |&gt;\n  group_by(homeownership) |&gt;\n  summarise(interest_rate = mean(interest_rate, na.rm=TRUE))\nloan50_means\n\n# A tibble: 3 × 2\n  homeownership interest_rate\n  &lt;fct&gt;                 &lt;dbl&gt;\n1 rent                   10.8\n2 mortgage               11.9\n3 own                    13.9\n\n\nUsing this new data frame loan50_means, we can create a bar plot of these means, using geom_col():\n\nggplot(data = loan50_means,\n       mapping = aes(x = homeownership, y = interest_rate)) +\n  geom_col()\n\n\n\n\n\n\n\n\n\ndata = loan50_means\n\nNote that we are using the dataset loan50_means here, which we created above. It contains the mean interest_rate per type of homeownership.\n\nmapping = aes(x = homeownership, y = interest_rate)\n\nThis part of the code gives the categorical (x) variable and the numeric (y) variable.\n\ngeom_col()\n\nThis tells ggplot2 that we would like to create a barplot where we want to display the values in the data (not the counts per group, as with geom_bar).",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Graphing using ggplot2</span>"
    ]
  },
  {
    "objectID": "analysis_02_graphs.html#describing-graphs",
    "href": "analysis_02_graphs.html#describing-graphs",
    "title": "8  Graphing using ggplot2",
    "section": "8.7 Describing graphs",
    "text": "8.7 Describing graphs\nWhen describing graphs, the list below provides some general guidelines for describing the common types of plots and charts.\n\n8.7.1 Dotplot:\n\nThe range of the data.\nThe mode(s) of the data.\nThe frequency or count of each value.\nThe symmetry or skewness of the distribution.\n\n\n\n8.7.2 Histogram:\n\nThe shape of the distribution (e.g., bell-shaped, skewed, bimodal).\nThe range and frequency of values within each bin.\nThe mode(s) of the data.\nAny outliers or unusual patterns in the data.\n\n\n\n8.7.3 Boxplot:\n\nFocus on the summary statistics: The median, quartiles, and range of the data.\nAny outliers or extreme values.\nWhen displayed for several groups, differences in the distribution of the data between different groups.\n\n\n\n8.7.4 Scatterplot:\n\nThe strength and direction of the relationship between two variables.\nAny other visible patterns or trends in the data.\nAny outliers or extreme values.\n\n\n\n8.7.5 Barplot:\n\nThe frequency or proportion of data points in each category. variables have no natural order, it does not make sense to discuss the shape for nominal variables.\nDifferences in the distribution of the categorical variable between different groups or time periods.\nWhen a second categorical variable is used (e.g. stacked barplot): Differences in the distribution of the data wiuthin different groups.\nAny patterns or trends in the data. Note: This depends on the variable. As the categories of nominal",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Graphing using ggplot2</span>"
    ]
  },
  {
    "objectID": "analysis_03_tables.html",
    "href": "analysis_03_tables.html",
    "title": "9  Tables",
    "section": "",
    "text": "9.1 Frequency tables\nA frequency table displays the number of times a value is present in the data. We have already encountered the function table which provides a simple table of counts. To create a more elaborate frequency table that also includes percentages, we are using package expss. Our example uses data from package openintro:\nlibrary(expss)\nlibrary(openintro)\ndata(loan50)\nWe create a frequency table with the function fre:\nfre(loan50$homeownership)\n\n\n\n\nloan50$homeownership\n Count \n Valid percent \n Percent \n Responses, % \n Cumulative responses, % \n\n\n\n\n rent \n21\n42\n42\n42\n42\n\n\n mortgage \n26\n52\n52\n52\n94\n\n\n own \n3\n6\n6\n6\n100\n\n\n #Total \n50\n100\n100\n100\n\n\n\n &lt;NA&gt; \n0\n\n0",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tables</span>"
    ]
  },
  {
    "objectID": "analysis_03_tables.html#frequency-tables",
    "href": "analysis_03_tables.html#frequency-tables",
    "title": "9  Tables",
    "section": "",
    "text": "fre\n\nThis is the function to create a frequency table using the expss package\n\nloan50$homeownership\n\nWe specify the dataset and variable used using the dollar sign notation, i.e. the name of the data frame before the dollar sign and the name of the variable after the dollar sign.\n\n\n\n\n\n\n\n\nReporting\n\n\n\nFor a frequency table, reporting the counts and valid percentages usually suffices. This is achieved by selecting the first three columns of a frequency table and removing missing values:\n\nfre(loan50$homeownership)[,1:3] |&gt; drop_na() \n\n\n\n\nloan50$homeownership\n Count \n Valid percent \n\n\n\n\n rent \n21\n42\n\n\n mortgage \n26\n52\n\n\n own \n3\n6\n\n\n #Total \n50\n100",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tables</span>"
    ]
  },
  {
    "objectID": "analysis_03_tables.html#contingency-tables",
    "href": "analysis_03_tables.html#contingency-tables",
    "title": "9  Tables",
    "section": "9.2 Contingency tables",
    "text": "9.2 Contingency tables\nA contingency table is a two-way table consisting of columns and rows. It is also known as a pivot table, a multi-dimensional table, a cross table (or cross tab) and two-way table.\nIn order to make a contingency table, your data must meet the following requirements:\n\nTwo categorical variables (nominal or ordinal level of measurement)\nTwo or more categories (groups) for each variable.\n\nHowever, contingency tables should only be used when there are a limited number of categories. Below is a contingency table of two variables: a respondent’s sex and whether the respondent smokes.\n\nThe table above shows the observed frequencies. This is not how contingency tables should be presented. Instead, there are two basic layouts that are commonly used and that can both be used for this course.\n\n9.2.1 Two layout options for contingency tables\nThere are two basic layouts that are commonly used and that can both be used for this course.\n\n9.2.1.1 Layout 1\nIn the first layout you show the percentages per category of the variable in the rows and also the observed frequencies. For the percentages you divide the observed frequencies through the total number of observations in each column. In the column ‘row totals’, you only show the observed frequencies.\n\nApplied to the data above, the contingency table would look like this:\n\n\n\n9.2.1.2 Layout 2\nIn the second layout you show only the percentages per category of the variable in the rows, except for the total row at the bottom. Again, you calculate the percentages per column by dividing the number of observed frequencies by the total number of observations. In the last column you also show the percentages of the row totals.\n\nApplied to the data above (respondent’s sex and smoking), the contingency table would look like this:\n\n\n\n\n9.2.2 Contingency tables in R\nBasic tables can be created using table(), but in order to add column percentages and totals and allow exporting the able to Word/HTML, we are using the package flextable:\n\nlibrary(openintro)  # We use data from this package\nlibrary(flextable) \n\n\ndata(loans_full_schema)\ntable_example &lt;- proc_freq(x = loans_full_schema, \n                           row = \"application_type\", \n                           col = \"homeownership\", \n                           include.row_percent = FALSE, \n                           include.table_percent = FALSE) \ntable_example\n\napplication_typehomeownershipMORTGAGEOWNRENTTotalindividualCount3,8391,1703,4968,505Col. pct80.2%86.5%90.6%jointCount9501833621,495Col. pct19.8%13.5%9.4%TotalCount4,7891,3533,85810,000\n\n\n\ntable_example = proc_freq(….)\n\nWe define that we want to create a table called table_example using the function proc_freq.\n\nx = loans_full_schema\n\nThis specifies which data set (data.frame) we would like to use.\n\nrow = \"application_type\"\n\nThis specifies the variable we want to use in the rows of the cross table.\n\ncol = \"homeownership\"\n\nThis specifies the variable we want to use in the column of the cross table.\n\ninclude.row_percent = FALSE\n\nThis specifies that we do not want to include row percentages. Note that column percentages will be included by default.\n\ninclude.table_percent = TRUE\n\nThis specifies that we do not want to include table percentages.\n\n\nUsing the following code you can save this to a Word file (save_as_docx) and an HTML file (save_as_html). Note that this file is saved to the current working directory.\n\nsave_as_docx(table_example, path = \"table_example.docx\")\nsave_as_html(table_example, path = \"table_example.html\")\n\n\ntable_example\n\nThis specifies which table we would like to export.\n\npath = \"table_example.docx\"\n\nThis specifies the file name for the file to be exported.\n\n\nNote that this table does require some further (manual) editing if you want to only include the percentages in the cells (see layout 2). Also do not forget to include a title for the table and a better label for the variables.\n\n9.2.2.1 Contingency tables using expss\nAn alternative solution requires slightly longer R code, but produces a table that does not require further editing for layout option 2. This solutions uses packages expss and huxtable:\n\nlibrary(openintro)  # We use data from this package\nlibrary(huxtable)\nlibrary(expss)\n\ndata(loans_full_schema) # Load the data set\n\ncross_table &lt;- loans_full_schema |&gt;\n  tab_cells(`Application type`= application_type) |&gt;\n  tab_cols(`Home ownership`= homeownership, total(homeownership)) |&gt;\n  tab_total_label(\"Total\") |&gt;\n  tab_stat_cpct() |&gt;\n  tab_pivot() |&gt;\n  drop_empty_rows() |&gt;\n  drop_empty_columns() |&gt;\n  as_huxtable() |&gt;\n  theme_article() |&gt;\n  set_number_format(row=everywhere,col=everywhere,value= \"%.1 0f %%\" ) |&gt;\n  set_number_format(row=final(1),col=everywhere,value=0)\n\ncross_table\n\n\nHome ownership#Total\n\nMORTGAGEOWNRENT\n\nApplication typeindividual 80.2 % 86.5 % 90.6 % 85.0 %\n\njoint 19.8 % 13.5 % 9.4 % 14.9 %\n\n#Total4789    1353    3858    10000    \n\n\n\ncross_table = loans_full_schema\n\nThis defines that we are creating a table called cross_table using the dataset loans_full_schema. When creating your own table, you would of course rename the latter to the name of your own dataset.\n\ntab_cells(`Application type`= application_type)\n\nThis specifies that we would like to use the variable application_type in the rows. We also specify that we would like this variable to be displayed as Application type, using `Application type` (note the use of the so-called backtick (`) ).\n\ntab_cols(`Home ownership`= homeownership, total(homeownership))\n\nThis specifies that we would like to use the variable homeownership in the columns and also include a Total column. We also specify that we would like the variable to be displayed as Home ownership.\n\ntab_total_label(\"Total\")\n\nWe would like the total label to be displayed as Total.\n\ntab_stat_cpct()\n\nWe would like the table to contain column percentages.\n\ntab_pivot()\n\nThis function actually creates the table.\n\ndrop_empty_rows()\n\nDelete any empty rows from the table\n\ndrop_empty_columns()\n\nDelete any empty columns from the table\n\nas_huxtable()\n\nThis transforms this table into a table that the huxtable package can work with, which allows further modification and exporting of the table.\n\ntheme_article()\n\nApply a theme to the table which makes it suitable for publication in a scientific journal.\n\nset_number_format(row=everywhere,col=everywhere,value= \"%.0f %%\" )\n\nRound percentages to 0 decimals and add percentage symbol.\n\nset_number_format(row=final(1),col=everywhere,value=0)\n\nRound case counts to 0 decimals.\n\n\n\nNote: you only need to change the first three lines of this code to use it for your own data: the name of the data set and the variables.\n\nThis table can be saved to a Word document (quick_docx) and/or HTML file (quick_html) in the following way:\n\nquick_docx(cross_table,\n           file = \"cross_table.docx\")\nquick_html(cross_table,\n           file = \"cross_table.html\")\n\n\ncross_table\n\nThis specifies which table we would like to export.\n\nfile = \"cross_table.docx\"\n\nThis specifies the file name for the file to be exported.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tables</span>"
    ]
  },
  {
    "objectID": "analysis_03_tables.html#presentation-of-contingency-tables",
    "href": "analysis_03_tables.html#presentation-of-contingency-tables",
    "title": "9  Tables",
    "section": "9.3 Presentation of contingency tables",
    "text": "9.3 Presentation of contingency tables\n\n9.3.1 Example of contingency tables (fictitious data):\nBelow I show two contingency tables concerning the relationship of level of satisfaction with Brexit negotiations and vote intention using the different styles.\n\n9.3.1.1 Layout 1\nIn the first layout you show the percentages per category of the variable in the rows and also the observed frequencies. For the percentages you divide the observed frequencies through the total number of observations in each column. In the column ‘row totals’, you only show the observed frequencies.\n\n\n\nTable 1: Relationship of level of satisfaction with Brexit negotiations and vote intention (layout 1)\n\n\n\n\n9.3.1.2 Layout 2\nIn the second layout you show only the percentages per category of the variable in the rows, except for the total row at the bottom. Again, you calculate the percentages per column by dividing the number of observed frequencies by the total number of observations. In the last column you also show the percentages of the row totals.\n\n\n\nTable 1: Relationship of level of satisfaction with Brexit negotiations and vote intention (layout 2)",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tables</span>"
    ]
  },
  {
    "objectID": "analysis_03_tables.html#instructions",
    "href": "analysis_03_tables.html#instructions",
    "title": "9  Tables",
    "section": "9.4 Instructions",
    "text": "9.4 Instructions\n\nUse the above layout with three horizontal lines: one at the top, one under the categories of the independent variables (columns) and one at the bottom.\nThe variable labels should be bold.\nPut a title above the table. Start the title with ‘Table’ and the number of the table and then use an informative title that summarizes the two variables that are used.\nAlthough, in principle, the row and column variables in a contingency table can be used interchangeably we use this general guideline for placement: Put the independent variable (here: How well do you think the UK government is handling the Brexit negotiations?) in the columns and the dependent variable (here: Vote for Labour or Conservatives at the next election?) in the rows. This is a convention and you should be consistent to make it easier for your readers.\nCalculate percentages of the variables across the columns. Each column must add up to 100%.\nIn case of ordinal variables, keep the ranking (i.e. low, medium, high).\nBecause we know that the totals of the columns are 100%, you state the numbers in the row ‘Total’ (the last row). In this way, the reader can, if desired, calculate the observed frequencies of each cell, e.g. 39.5% of 681 = 0.395 * 681 = 278.\nIn general, the use of one digit after the decimal point is sufficient.\nAt the bottom of the table the source can be mentioned if necessary.\nTo interpret the table, we also compare the percentages across the rows: for example, we see that a majority of those who look more favourably on the government’s strategy concerning the Brexit negotiations (59.1%), intend to vote for the Conservatives at the next election, while 60.5% of those who are undecided as well as 81.6% of the respondents who are unhappy with the government’s strategy intend to vote for Labour.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Tables</span>"
    ]
  },
  {
    "objectID": "analysis_04_probability.html",
    "href": "analysis_04_probability.html",
    "title": "10  Probability in R",
    "section": "",
    "text": "10.1 Dice rolling\nWe can use R to calculate the probabilities of various dice-rolling events, such as the probability of getting specific numbers when rolling a six-sided dice several times. This can be helpful, for example, to check your manual calculations and to see if you grasped the concepts of probability correctly. For dice-rolling events, we can use the dice package. If you are working on your personal computer you may need to install the package first using the command install.packages(\"dice\"). Installing the package is not necessary on university computers.\nYou can load the package as follows:\nlibrary(dice) # Import required package\n\nLoading required package: gtools\nFor a specified dice-rolling process, the command getEventProb() calculates the probability of an event. We can specify this by passing a list object in to eventList. The package can simulate various scenarios. I will demonstrate the basic functions but you may want to have a look at the additional functions, see the manual.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Probability in R</span>"
    ]
  },
  {
    "objectID": "analysis_04_probability.html#dice-rolling",
    "href": "analysis_04_probability.html#dice-rolling",
    "title": "10  Probability in R",
    "section": "",
    "text": "10.1.1 Probability of rolling a 6 when rolling one six-sided dice\n\ngetEventProb(nrolls = 1,\n             ndicePerRoll = 1,\n             nsidesPerDie = 6,\n             eventList = list(6))\n\n[1] 0.1666667\n\n\n\ngetEventProb(\n\nThis part of the code specifies that we want to get the probability for an event.\n\nnrolls = 1,\n\nThis integer represents the number of dice rolls to make. In this case, we roll the die once.\n\nndicePerRoll = 1,\n\nThis integer represents the number of dice to use in each dice roll.\n\nnsidesPerDie = 6,\n\nThis specifies the number of sides of the dice. You can, for example, change this if you would like to work with a 10 side dice. If you wand to simulate a six-side die, leave it at 6. One short remark here: Modern English considers dice as both singular and plural nouns. However, the R function still uses ‘Die’. You must write the function exactly like this. R is, as mentioned earlier, case sensitive and can only find the function if you write it as nsidesPerDie.\n\neventList = list(6))\n\nThis specifies the event that we are interested in. Note that you have to use a list() command. A list is a type of object in R. For now, you do not need to know more about this. If you want to get the probability of e.g. rolling a 4, you need to change this part of the code to eventList = list(4))\n\n\n\n\n10.1.2 Probability of rolling a 1 or a 4 when rolling one six-sided die\nWe can change the code according to the event that we are interested in. If we want to know the probability of rolling either a 1 or a 4 when rolling one six-sided die, we would write:\n\ngetEventProb(nrolls = 1,\n             ndicePerRoll = 1,\n             nsidesPerDie = 6,\n             eventList = list(c(1,4)))\n\n[1] 0.3333333\n\n\n\ngetEventProb(\n\nThis part of the code specifies that we want to get the probability for an event.\n\nnrolls = 1,\n\nThis integer represents the number of dice rolls to make.\n\nndicePerRoll = 1,\n\nThis integer represents the number of dice to use in each dice roll.\n\nnsidesPerDie = 6,\n\nThis specifies the number of sides of the dice.\n\neventList = list(c(1,4)))\n\nThis specifies the event that we are interested in. Here, we are interested in a 1 or a 4. You write it by including c(1,4) in your list. You can add more numbers. For example, if you want to calculate the probaility of rolling a 1, 2 or a 5 you would write eventList = list(c(1,2,5))).\n\n\n\n\n10.1.3 Probability of rolling two 1’s when rolling a six-sided die twice\nIf we want to know the probability of rolling two 1’s when rolling a six-sided die twice, we would write:\n\ngetEventProb(nrolls = 2, \n             ndicePerRoll = 1,\n             nsidesPerDie = 6,\n             eventList = list(1,1),\n             orderMatters = TRUE)\n\n[1] 0.02777778\n\n\n\ngetEventProb(\n\nThis part of the code specifies that we want to get the probability for an event.\n\nnrolls = 2,\n\nThis integer represents the number of dice rolls to make.\n\nndicePerRoll = 1,\n\nThis integer represents the number of dice to use in each dice roll.\n\nnsidesPerDie = 6,\n\nThis specifies the number of sides of the dice.\n\neventList = list(1,1))\n\nThis specifies the event that we are interested in. Here, we are interested in two 1’s. Note that this is different than before because we do not write c(). Instead, we specify that the outcome of interest is, in this example, 1, followed by a 1. For other events, change the numbers in the bracket.\n\norderMatters = TRUE\n\nThis option indicates that the order of conditions in evenList matters. In this example, it makes no difference.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Probability in R</span>"
    ]
  },
  {
    "objectID": "analysis_04_probability.html#deck-of-cards",
    "href": "analysis_04_probability.html#deck-of-cards",
    "title": "10  Probability in R",
    "section": "10.2 Deck of cards",
    "text": "10.2 Deck of cards\nWe can use R to calculate the probabilities of drawing combinations of cards from a deck of cards. A standard deck of cards has 52 cards in 13 values and 4 suits. The suits are Spade, Club, Diamond and Heart. Each suit has 13 card values: 2-10, 3 “face cards” Jack, Queen, King (J, Q, K) and an Ace. Unfortunately, there is no R package available similar to the dice rolling example. However, the openintro data contains a pre-defined deck of cards which contains all the cards in a standard deck:\n\ndata(cards, package = \"openintro\")  # Specify that we want to use the dataset cards from openintro\n\nThere are 52 observations on 4 variables in the data set.\n\nvalue\n\na factor with levels 10 2 3 4 5 6 7 8 9 A J K Q\n\ncolor\n\na factor with levels black red\n\nsuit\n\na factor with levels Club Diamond Heart Spade\n\nface\n\na logical vector (TRUE for face cards and FALSE for all other cards)\n\n\nTo calculate the probability of an ‘Ace’ card we can check how often such a card occurs. This can be easily done in R with the filter() function from the tidyverse package. The package is installed on all university computers.\n\nlibrary(tidyverse) # Import required package\n\nWe can then use the filter() function to pick cases based on their values. The function was introduced above. For our purpose here, we use a specific way to select cards in our deck as follows:\n\ncards |&gt; \n  filter(value == \"A\")\n\n# A tibble: 4 × 4\n  value color suit    face \n  &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;   &lt;lgl&gt;\n1 A     red   Heart   TRUE \n2 A     red   Diamond TRUE \n3 A     black Spade   TRUE \n4 A     black Club    TRUE \n\n\n\ncards |&gt;\n\nThis part of the code specifies that we are working with the ‘cards’ data frame. |&gt; is called the pipe operator in R (see week 2).\n\nfilter(value == \"A\")\n\nHere we ask R to pick cases (i.e. filter) if any of the cards (note that this variable is named ‘value’ equals the string ‘A’. Please note that the function is case sensitive (i.e. ‘a’ will not work).\n\n\nNow that we know that there are 4 aces and because we know that there are 52 cards in our deck, we can simply divide 4 by 52 to get the probability.\n\n4/52\n\n[1] 0.07692308\n\n\nSimilarly, we can test how many ‘Diamond’ cards there are and calculate the probability:\n\ncards |&gt; \n  filter(suit == \"Diamond\") \n\n# A tibble: 13 × 4\n   value color suit    face \n   &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;   &lt;lgl&gt;\n 1 2     red   Diamond FALSE\n 2 3     red   Diamond FALSE\n 3 4     red   Diamond FALSE\n 4 5     red   Diamond FALSE\n 5 6     red   Diamond FALSE\n 6 7     red   Diamond FALSE\n 7 8     red   Diamond FALSE\n 8 9     red   Diamond FALSE\n 9 10    red   Diamond FALSE\n10 J     red   Diamond TRUE \n11 Q     red   Diamond TRUE \n12 K     red   Diamond TRUE \n13 A     red   Diamond TRUE \n\n13/52\n\n[1] 0.25\n\n\nIf we are interested in face cards, our code changes slightly because this is a TRUE/FALSE vector. We do not include quotation marks but simply write:\n\ncards |&gt; \n  filter(face == TRUE) \n\n# A tibble: 16 × 4\n   value color suit    face \n   &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;   &lt;lgl&gt;\n 1 J     red   Heart   TRUE \n 2 Q     red   Heart   TRUE \n 3 K     red   Heart   TRUE \n 4 A     red   Heart   TRUE \n 5 J     red   Diamond TRUE \n 6 Q     red   Diamond TRUE \n 7 K     red   Diamond TRUE \n 8 A     red   Diamond TRUE \n 9 J     black Spade   TRUE \n10 Q     black Spade   TRUE \n11 K     black Spade   TRUE \n12 A     black Spade   TRUE \n13 J     black Club    TRUE \n14 Q     black Club    TRUE \n15 K     black Club    TRUE \n16 A     black Club    TRUE \n\n16/52\n\n[1] 0.3076923\n\n\nWe can find the occurrence of combinations, e.g. find all cards that are either Ace or a Diamond. To do this, we use the “|” symbol to indicate ‘or’.\n\ncards |&gt; \n  filter(suit == \"Diamond\" | value == \"A\")\n\n# A tibble: 16 × 4\n   value color suit    face \n   &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;   &lt;lgl&gt;\n 1 A     red   Heart   TRUE \n 2 2     red   Diamond FALSE\n 3 3     red   Diamond FALSE\n 4 4     red   Diamond FALSE\n 5 5     red   Diamond FALSE\n 6 6     red   Diamond FALSE\n 7 7     red   Diamond FALSE\n 8 8     red   Diamond FALSE\n 9 9     red   Diamond FALSE\n10 10    red   Diamond FALSE\n11 J     red   Diamond TRUE \n12 Q     red   Diamond TRUE \n13 K     red   Diamond TRUE \n14 A     red   Diamond TRUE \n15 A     black Spade   TRUE \n16 A     black Club    TRUE \n\n\nBased on this, there are 16 cards that are either an Ace or a Diamond card. Therefore, the probability of drawing either an Ace card or a Diamond card is 16 divided by 52.\n\n16/52\n\n[1] 0.3076923\n\n\nYou can also use the “&” symbol to indicate ‘AND’, for example to get the number of cards that are red and an Ace.\n\ncards |&gt; \n  filter(color == \"red\" & value == \"A\")\n\n# A tibble: 2 × 4\n  value color suit    face \n  &lt;fct&gt; &lt;fct&gt; &lt;fct&gt;   &lt;lgl&gt;\n1 A     red   Heart   TRUE \n2 A     red   Diamond TRUE \n\n\nYou can extend the code, for example by writing cards |&gt; filter(value %in% c(\"A\", \"K\") | suit == \"Diamond\") if you want to find the number of cards that are either Diamond, or Ace, or King.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Probability in R</span>"
    ]
  },
  {
    "objectID": "analysis_04_probability.html#conditional-probabilities-with-a-contingency-table",
    "href": "analysis_04_probability.html#conditional-probabilities-with-a-contingency-table",
    "title": "10  Probability in R",
    "section": "10.3 Conditional probabilities with a contingency table",
    "text": "10.3 Conditional probabilities with a contingency table\nWe can explore probabilities within a contingency table. For this illustration, we use the data set from the book called photo_classify from the openintro package. This is a simulated data set for photo classifications based on a machine learning algorithm versus what the true classification is for those photos. While the data are not real, they resemble performance that would be reasonable to expect in a well-built classifier. For more information, see chapter 3.2 in the book.\nFirst, we make a contingency table of the two variables mach_lean and truth:\n\nlibrary(flextable) \n\n\nAttaching package: 'flextable'\n\n\nThe following object is masked from 'package:purrr':\n\n    compose\n\n\nThis code displays the percentages across columns:\n\nlibrary(openintro)\ndata(photo_classify)\n\ntable_example &lt;- proc_freq(x = photo_classify, \n                           row = \"mach_learn\", \n                           col = \"truth\", \n                           include.row_percent = FALSE, \n                           include.table_percent = FALSE) \ntable_example\n\nmach_learntruthfashionnotTotalpred_fashionCount19722219Col. pct63.8%1.5%pred_notCount1121,4911,603Col. pct36.2%98.5%TotalCount3091,5131,822\n\n\nThe flextable package also allows us to display the table percentages. The code below creates a table with joint probabilities for the photo_classify data. The proportions are calculated by dividing the count in each cell by the table’s total (1822).\n\ntable_example2 &lt;- proc_freq(x = photo_classify, \n                           row = \"mach_learn\", \n                           col = \"truth\", \n                           include.row_percent = FALSE,\n                           include.column_percent = FALSE,\n                           include.table_percent = TRUE,\n                           include.column_total = TRUE) \ntable_example2\n\nmach_learntruthfashionnotTotalpred_fashion197 (10.8%)22 (1.2%)219 (12.0%)pred_not112 (6.1%)1,491 (81.8%)1,603 (88.0%)Total309 (17.0%)1,513 (83.0%)1,822 (100.0%)\n\n\n\ntable_example = proc_freq(…)\n\nWe define that we want to create a table called table_example2 using the function proc_freq.\n\nx = photo_classify\n\nThis specifies which data set (data.frame) we would like to use.\n\nrow = \"mach_learn\",\n\nThis specifies the variable we want to use in the rows of the cross table.\n\ncol = \"truth\",\n\nThis specifies the variable we want to use in the column of the cross table.\n\ninclude.row_percent = FALSE\n\nThis specifies that we do not want to include row percentages.\n\ninclude.column_percent = FALSE,\n\nThis specifies that we do not want to include column percentages.\n\ninclude.table_percent = TRUE\n\nThis specifies that we do want to include table percentages.\n\ninclude.column_total = TRUE)\n\nThis specifies that we want to include column totals.\n\n\nBased on this we can see that in 10.81 % of the cases the classifier correctly predicted the fashion photos (see cell fashion, pred_fashion) and in 6.15 % of the cases, the classifier did not correctly predict a fashion photo. Likewise, in 1.21 % of the cases the classifier predicted a photo that was not a fashion photo as ‘fashion’ and in 81.83 % of the cases the classifier was correct in its assessment that a photo which was not a fashion photo was indeed not a fashion photo.\nThis is the same table as displayed on p. 96 of the book.\n\n10.3.1 Conditional probability\nTo further investigate conditional probabilities, we can use the information from the table that we just created:\nAssume we want to calculate the probability that a photo was about fashion (truth is fashion) given that the prediction was that the photo is about fashion (mach_learn is pred_fashion). We can see that there were 219 cases in which the prediction was ‘fashion’ and the photo was, in fact, a fashion photo in 197 cases.\nP(truth is fashion given mach_learn is pred_fashion ) = \\((\\frac{197}{219})= 0.900\\)\nIn R, we can calculate the value like this:\n\n197/219\n\n[1] 0.8995434",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Probability in R</span>"
    ]
  },
  {
    "objectID": "analysis_05_normal_distribution.html",
    "href": "analysis_05_normal_distribution.html",
    "title": "11  Normal distribution",
    "section": "",
    "text": "11.1 Normal distribution and z-scores\nR has several built-in functions to generate the normal distribution. We can use these functions to demonstrate various aspects of probability distributions.\nOne of them is the dnorm() function. This function gives the height of the probability distribution at each point for a given mean and standard deviation. It allows us to specify a normal distribution using three elements:\nTo plot a standard normal distribution (mean = 0 and sd = 1), we need to write:\nx &lt;- seq(-10, 10, by = .1)\ncurve(dnorm(x, mean = 0, sd = 1), from=-4, to=4)\nWe can display different types of normal distributions. In the book, cumulative SAT scores are said to be approximately normally distributed with \\(\\mu\\) = 1100 and \\(\\sigma\\) = 200.\nTo plot the normal distribution of SAT scores (mean = 1100 and sd = 200), we need to write:\nx &lt;- seq(-10, 10, by = .1)\ncurve(dnorm(x, mean = 1100, sd = 200), from=200, to=2000)",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Normal distribution</span>"
    ]
  },
  {
    "objectID": "analysis_05_normal_distribution.html#normal-distribution-and-z-scores",
    "href": "analysis_05_normal_distribution.html#normal-distribution-and-z-scores",
    "title": "11  Normal distribution",
    "section": "",
    "text": "x is a vector of numbers.\nmean is the mean value.\nsd is the standard deviation.\n\n\n\n\nx &lt;- seq(-10, 10, by = .1)\n\nThis code creates a sequence of numbers between -10 and 10 incrementing by 0.1.\n\ncurve(dnorm(x, mean = 0, sd = 1), from=-4, to=4)\n\nThis creates a normal distribution with a mean of 0 and a standard deviation of 1. We can set the boundaries manually from -4 to 4. If you change them the x-axis of the plot will get wider. However, for the standard normal distribution the range -4 to 4 is sufficient.\n\n\n\n\n\n\nx &lt;- seq(-10, 10, by = .1)\n\nThis code creates a sequence of numbers between -10 and 10 incrementing by 0.1.\n\ncurve(dnorm(x, mean = 1100, sd = 200), from=200, to=2000)\n\nThis creates a normal distribution with a mean of 1100 and a standard deviation of 200. We can set the boundaries manually from 200 to 2000 to make the normal distribution fit.\n\n\n\n11.1.1 Calculating z-scores\nThe z-score is a measure that shows how far below or above of the mean a specific value in a given data set is. The formula for the z-score is:\nz = \\(\\frac{x-\\mu}\\sigma\\)\nWe use the example of cumulative SAT scores (\\(\\mu\\) = 1100 and \\(\\sigma\\) = 200) to illustrate the calculation of z-scores. To calculate the z-score of a value of 1190, we would calculate:\nz = \\(\\frac{x-\\mu}\\sigma\\) = \\(\\frac{1190-1100}{200}\\)\n\n(1190-1100)/200\n\n[1] 0.45\n\n\nThis indicate that z score is positive (0.45) and indicates that it is 0.45 standard deviations above the average.\nTo find the area in a standard normal (z) distribution, we can use the pnorm() function. Watch out though: It always gives the area, or probability, below a specific z-value (or, if you want, of the left tail):\n\npnorm(0.45)\n\n[1] 0.6736448\n\n\nThe value therefore, indicates that 67.36 % of the values are below a z-value of 0.45. So if we would be interested in knowing the area above a z-score of 0.45 then we would need to compute 1 - 0.6736448 = 0.3263552. Therefore, approximately 32.65 % of values are above an SAT score of 1190. If we need to calculate the area below a z-value, the pnorm() function displays the correct value.\nWe can also calculate the area between two z-scores. If, for example, we are interested in the area between SAT scores of 950 and 1200, we would calculate two z-scores.\n\n(950-1100)/200\n\n[1] -0.75\n\n(1200-1100)/200\n\n[1] 0.5\n\n\nThe z-score of an SAT score of 950 is - 0.75, the z-score of an SAT score of 1200 is 0.5. The area, or the probability, below these specific z-values (or, if you want, of the left tail) are:\n\npnorm(-0.75)\n\n[1] 0.2266274\n\npnorm(0.5)\n\n[1] 0.6914625\n\n\nRemember that both indicate the size of the area to the left. Therefore, to find the area under the curve between the two SAT scores we can subtract the smaller value (corresponding to an SAT score of 950) from the larger value. This gives us:\n\npnorm(0.5) - pnorm(-0.75)\n\n[1] 0.4648351\n\n\nNote that we can simply write pnorm(0.5) - pnorm(-0.75) and R will subtract the value of pnorm(-0.75) (which is 0.2266274) from pnorm(0.5) (which is 0.6914625)\nYou can also calculate quantities directly without having to calculate the z-values first. The pnorm() function allows us to immediately specify the value we are looking for, as well as the mean and standard deviation of our normal distribution:\n\npnorm(950, mean = 1100, sd = 200)\n\n[1] 0.2266274\n\npnorm(1200, mean = 1100, sd = 200)\n\n[1] 0.6914625\n\n\n\n\n11.1.2 Find the boundary value that determines an area\nOf course, it is also possible to do the reverse operation, i.e. if we are interested what SAT score is required to belong to the 10% best scores. For this, we use the function qnorm(). This function comes standard with R and is used to find the boundary value that determines an area. For example, suppose you want to find that 90th percentile of a normal distribution whose mean is 1100 and whose standard deviation is 200. To do this, we write:\n\nqnorm(0.9, mean = 1100, sd = 200)\n\n[1] 1356.31\n\n\n\nqnorm(0.9, mean = 1100, sd = 200)\n\nThis code calculates the point under the curve for which 90% of students in a population that is normally distributed with mean 1100 and standard deviation 200 will lie below. You can change the values depending on the situation. If you wish to calculate the 45th percentile of a normal distribution, then write qnorm(0.45, , mean = 1100, sd = 200),\n\n\n\n\n11.1.3 Display the area under the curve using the visualize package\nAlternatively, we can use the visualize package to graph probability distributions. This package is very convenient because it allows us to also highlight the area or probability in user defined locations. In other words, you can use it to indicate the ‘area under the curve’ that you are looking for quite easily and it calculates the size of the area for you. The package is able to provide lower tail, bounded, upper tail, and two tail calculations.\n\nlibrary(visualize)\n\nSuppose we want to plot the area under the curve below SAT scores of 950 in a normal distribution of SAT scores (mean = 1100 and sd = 200), we need to write:\n\nvisualize.norm(stat = 950, \n               mu = 1100, \n               sd = 200, \n               section = \"lower\")\n\n\n\n\n\n\n\n\n\nvisualize.norm(stat = 950,\n\nvisualize.norm() generates a plot of the Normal distribution with user specified parameters. We first specify the value that limits our area (in this example an SAT score of 950).\n\nmu = 1100,\n\nThis specifies the mean of the normal distribution.\n\nsd = 200,\n\nThis specifies the standard deviation of the normal distribution.\n\nsection = \"lower\")\n\nHere you select what section you want to be displayed. You can also use “upper” if you want the area on the ‘right’ side under the curve.\n\n\nTo plot the area under the curve between SAT scores of 950 and 1200 in a normal distribution of SAT scores (mean = 1100 and sd = 200), we need to write:\n\nvisualize.norm(stat = c(950, 1200), \n               mu = 1100, \n               sd = 200, \n               section = \"bounded\")\n\n\n\n\n\n\n\n\n\nvisualize.norm(stat = c(950, 1200),\n\nvisualize.norm() generates a plot of the Normal distribution with user specified parameters. We now have two limits and therefore the parameter as stat = c(lower_bound, upper_bound).\n\nmu = 1100,\n\nThis specifies the mean of the normal distribution.\n\nsd = 200,\n\nThis specifies the standard deviation of the normal distribution.\n\nsection = \"bounded\")\n\nHere you select what section you want to be displayed. Because we are interested in the area between the two values in stat, we need to use bounded.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Normal distribution</span>"
    ]
  },
  {
    "objectID": "analysis_06_proportions.html",
    "href": "analysis_06_proportions.html",
    "title": "12  Inference for proportions",
    "section": "",
    "text": "12.1 Inference for a single proportion",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Inference for proportions</span>"
    ]
  },
  {
    "objectID": "analysis_06_proportions.html#inference-for-a-single-proportion",
    "href": "analysis_06_proportions.html#inference-for-a-single-proportion",
    "title": "12  Inference for proportions",
    "section": "",
    "text": "12.1.1 Confidence interval for a single proportion\n\n12.1.1.1 Calculating ‘by hand’ using R\nOne approach is to calculate the normal approximation of the binomial distribution (Wald interval), as described in the OpenIntro book. This is basically the same as doing the ‘manual’ calculation, but in R.\nAs an example, we use a survey of voters in which 23% indicate to support the Conservatives. We estimate a 95% confidence interval for this estimate:\n\n# Define input (change these you appropriate values)\np_hat = 0.23\nn = 1000\nconfidence = 0.95\n\n\n# Perform calculations (no need to change anything here)\nse = sqrt(p_hat * (1 - p_hat)/ n)     # Calculate SE\nz_star = qnorm((1 + confidence) / 2)  # Calculate z*-value \nlower = p_hat - z_star * se           # Lower bound CI\nupper = p_hat + z_star * se           # Upper bound CI\nc(lower, upper)\n\n[1] 0.203917 0.256083\n\n\n\n\n12.1.1.2 Using summary data\nWhen you have only summary data, i.e. information about the sample size and sample proportion, we recommend using prop.test for calculating a confidence interval for a single proportion.[^3] The function prop.test is part of the package stats, which is one of the few packages that R automatically loads when it starts.\n\n# Define input\np_hat = 0.23\nn = 1000\n\n# Run the actual test\nprop.test(x = p_hat * n, \n          n = n, \n          conf.level = 0.95)\n\n\n    1-sample proportions test with continuity correction\n\ndata:  p_hat * n out of n, null probability 0.5\nX-squared = 290.52, df = 1, p-value &lt; 2.2e-16\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.2045014 0.2576046\nsample estimates:\n   p \n0.23 \n\n\nNote: The results from the calculation by hand and from the function prop.test are slightly different. This is due to the fact that prop.test uses a slightly more complicated formula for calculating the confidence interval (Wilson score interval), also incorporating a ‘continutiy correction’ (which accounts for the fact that we are using a continuous normal distribution to approximate a discrete phenomenon, i.e. the number of successes).\n\nprop.test\n\nThis is the function that conducts a test for a proportion and its confidence interval.\n\nx = p_hat * n\n\nThe first value specified should be the number of successes. In our example his is the number of people supporting the Conservatives. We can calculate this as the sample proportion (\\(\\hat{p}\\)) times the sample size.\n\nn = n\n\nThe second value specified should be the number of trials (read: the number of observations in our dataset). In our case: the number of respondents in the dataset.\n\nconf.level = 0.95\n\nThis determines the confidence level. The default is 0.95 which corresponds to a 95% confidence interval.\n\n\n\n\n12.1.1.3 Variables in a data frame\nIf you have a data frame with a variable that represents successes (or not) for each case, we can use the following procedure. In our example we have a variable that records the vote intention of a respondent, which is either Conservative or Other party:\n\n# For this example, we create a dataset of 1000 respondents with 230 expressing support for the Conservatives\nexample_data = data.frame(party_choice = factor(c(rep(\"Conservatives\", 230), \n                                                  rep(\"Other party\", 770))))\ntable(example_data$party_choice)\n\n\nConservatives   Other party \n          230           770 \n\n\nIf we have data like this, we can directly calculate the confidence interval by running prop.test for the table:\n\nprop.test(table(example_data$party_choice),\n          conf.level = 0.95)\n\n\ntable(example_data$party_choice)\n\nThe first argument is a table of our variable of interest, which we can create by this code. If you use your own data, replace example_data with the name of your data frame and party_choice with the name of the variable of interest.1\nNote: The table should include only two categories. R will calculate the confidence interval for the first category in the table (in our case: Conservatives).2\n\nconf.level = 0.95\n\nThis determines the confidence level. The default is 0.95 which corresponds to a 95% confidence interval.\n\n\n\n\n\n    1-sample proportions test with continuity correction\n\ndata:  table(example_data$party_choice), null probability 0.5\nX-squared = 290.52, df = 1, p-value &lt; 2.2e-16\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.2045014 0.2576046\nsample estimates:\n   p \n0.23 \n\n\n\n\n\n12.1.2 Hypothesis tests for a single proportion\n\n12.1.2.1 Summary data\nWhen you only have information about the sample size and the proportion, we recommend using prop.test for conducting a hypothesis test.3\n\n# Define input\np_hat = 0.23\nn = 1000\n\n# Run the actual test\nprop.test(x = p_hat * n, \n          n = n, \n          p = 0.25,\n          alternative = \"two.sided\")\n\n\n    1-sample proportions test with continuity correction\n\ndata:  p_hat * n out of n, null probability 0.25\nX-squared = 2.028, df = 1, p-value = 0.1544\nalternative hypothesis: true p is not equal to 0.25\n95 percent confidence interval:\n 0.2045014 0.2576046\nsample estimates:\n   p \n0.23 \n\n\n\nprop.test\n\nThis is the function that conducts a test for a proportion.\n\nx = p_hat * n\n\nThe first value specified should be the number of successes. We can calculate this as the sample proportion (\\(\\hat{p}\\)) times the sample size.\n\nn = n\n\nThe second value specified should be the number of trials (read: the number of observations in our dataset). In our case: the number of respondents in the dataset.\n\np = 0.25\n\nThis specifies the hypothesized null value. In this example this is 0.25 or 25%, so we are testing the null hypothesis \\(\\mu_0 = 0.25\\)\n\nalternative = \"two.sided\"\n\nDetermine whether we want to use a two sided-test, or a one-sided test. Options are “two.sided” (default), “less” (when \\(H_1: \\mu &lt; p\\)) or “greater” (when \\(H_1: \\mu &gt; p\\)).\n\n\n\n\n12.1.2.2 Variables in a data frame\nIf you have a data frame with a variable that represents successes (or not) for each case, we can input this data directly into prop.test. In our example we have a variable that records the vote intention of a respondent, which is either Conservative or Other party (for the preparation of the data see [Single proportion confidence intervals for variables in a data frame]).\n\nprop.test(table(example_data$party_choice),\n          p = 0.25,\n          alternative = \"two.sided\")\n\n\ntable(example_data$party_choice)\n\nThe first argument is a table of our variable of interest, which we can create by this code. If you use your own data, replace example_data with the name of your data frame and party_choice with the name of the variable of interest.\nNote: The table should include only two categories. R will perform the test that the proportion for the first category is equal to the hypothesized value (p, see below).\n\np = 0.25\n\nThis specifies the hypothesized null value. In this example this is 0.25 or 25%, so we are testing the null hypothesis \\(\\mu_0 = 0.25\\)\n\nalternative = \"two.sided\"\n\nDetermine whether we want to use a two sided-test, or a one-sided test. Options are “two.sided” (default), “less” (when \\(H_1: \\mu &lt; p\\)) or “greater” (when \\(H_1: \\mu &gt; p\\)).\n\n\n\n\n\n    1-sample proportions test with continuity correction\n\ndata:  table(example_data$party_choice), null probability 0.25\nX-squared = 2.028, df = 1, p-value = 0.1544\nalternative hypothesis: true p is not equal to 0.25\n95 percent confidence interval:\n 0.2045014 0.2576046\nsample estimates:\n   p \n0.23",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Inference for proportions</span>"
    ]
  },
  {
    "objectID": "analysis_06_proportions.html#reporting-the-results-from-a-hypothesis-test-for-a-single-proportion",
    "href": "analysis_06_proportions.html#reporting-the-results-from-a-hypothesis-test-for-a-single-proportion",
    "title": "12  Inference for proportions",
    "section": "12.2 Reporting the results from a hypothesis test for a single proportion",
    "text": "12.2 Reporting the results from a hypothesis test for a single proportion\n\n#Obtain z-value based on manual calculation\n\n# Define input\np_hat = 0.12\nn = 1500\np = 0.10\n\nz &lt;- (p_hat-p)/(sqrt((p*(1-p)/n)))\nz\n\n[1] 2.581989\n\n2*pnorm(q=z, lower.tail=FALSE)\n\n[1] 0.009823275\n\n# Run the actual test\nprop.test(x = p_hat * n, \n          n = n, \n          p = 0.10,\n          alternative = \"two.sided\",\n          correct = FALSE)\n\n\n    1-sample proportions test without continuity correction\n\ndata:  p_hat * n out of n, null probability 0.1\nX-squared = 6.6667, df = 1, p-value = 0.009823\nalternative hypothesis: true p is not equal to 0.1\n95 percent confidence interval:\n 0.1045180 0.1374233\nsample estimates:\n   p \n0.12 \n\n\n\n\n\n\n\n\nOutput explanation\n\n\n\n\nthe probability of finding the observed (\\(z\\) or \\(\\chi^2\\), given the null hypothesis (p-value) is given as follows:\n\nin R, see p-value = 0.009823. Note: If the value is very close to zero, R may use the scientific notation for small numbers (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022). In these cases, write p &lt; 0.001 in your report.\n\n\n\n\n\n12.2.0.1 Reporting\nIf you calculate the results by hand and obtain a z-score, then the correct report includes:\n\nA conclusion about the null hypothesis; followed by\nInformation about the sample percentage and the population percentage.\n\\(z\\) = the value of z.\np = p-value. When working with statistical software, you should report the exact p-value that is displayed.\n\nin R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p &lt; 0.001 in your report.\n\n\nIf you calculate the results using prop.test and obtain a \\(\\chi^2\\)-score, then the correct report includes:\n\nA conclusion about the null hypothesis; followed by\nInformation about the sample percentage and the population percentage.\n\\(\\chi^2\\) = the value of chi-square, followed by the degrees of freedom in brackets.\np = p-value. When working with statistical software, you should report the exact p-value that is displayed.\n\nin R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p &lt; 0.001 in your report.\n\n\n\n\n\n\n\n\nReport\n\n\n\n✓ The percentage of supporters found in our sample (N = 1500) who support the Socialist Party (12%) is statistically significantly different from the percentage of the entire population (10%), z=2.58, p=0.1394.\n✓ The percentage of supporters found in our sample (N = 1500) who support the Socialist Party (12%) is statistically significantly different from the percentage of the entire population (10%), \\(\\chi^2\\) (1)=6.6667, p=0.0098.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Inference for proportions</span>"
    ]
  },
  {
    "objectID": "analysis_06_proportions.html#comparing-two-proportions",
    "href": "analysis_06_proportions.html#comparing-two-proportions",
    "title": "12  Inference for proportions",
    "section": "12.3 Comparing two proportions",
    "text": "12.3 Comparing two proportions\nLast week, we calculated a confidence interval for a single proportion. This week we cover two (independent) proportions. The calculations below apply to the case where the two proportions are drawn from different samples or subsamples, for example the support for a party in two separate opinion polls or the left-right position of respondents who live in the capital city and those who do not live there (these groups are independent because you can only belong to one).\n\n12.3.1 Confidence interval for the difference between two proportions\nWe use the CPR data set from the openintro package (see p. 218). The data set contains data on patients who were randomly divided into a treatment group where they received a blood thinner or the control group where they did not receive a blood thinner. The outcome variable of interest was whether the patients survived for at least 24 hours.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(openintro)\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nlibrary(flextable)\n\n\nAttaching package: 'flextable'\n\nThe following object is masked from 'package:purrr':\n\n    compose\n\ndata(cpr)\n\n# Refactor variables to ensure the order is the same as in the textbook table\ncpr &lt;- cpr |&gt;\n  mutate(group = factor(group, levels = c(\"control\", \"treatment\"), ordered = TRUE),\n         outcome = factor(outcome, levels = c(\"survived\", \"died\"), ordered = TRUE))\n\ntable_example &lt;- proc_freq(x = cpr, \n                           row = \"group\", \n                           col = \"outcome\", \n                           include.row_percent = FALSE, \n                           include.column_percent = FALSE, \n                           include.table_percent = FALSE) \ntable_example\n\ngroupoutcomesurviveddiedTotalcontrol113950treatment142640Total256590\n\n\nNote that we usually put the independent variable in the columns. However, the book does not follow this convention.\n\n12.3.1.1 Calculating ‘by hand’ using R\nTo calculate a 90 % confidence interval of the difference for the survival rates (\\(p_{1}\\) and \\(p_{2}\\)) by hand, we can write:\n\n# Define input (change these according to your values)\np_hat_1 = 14 / 40  # Treatment group\np_hat_2 = 11 / 50  # Control group\nn_1 = 40\nn_2 = 50\nconfidence = 0.9\n\n# Perform calculations (no need to change anything here)\np_hat = p_hat_1 - p_hat_2\nse = sqrt((p_hat_1*(1-p_hat_1)/n_1) + (p_hat_2*(1-p_hat_2)/n_2))\nz_star = qnorm((1 + confidence) / 2)  # Calculate z*-value \nlower = p_hat - z_star * se   # Lower bound CI\nupper = p_hat + z_star * se   # Upper bound CI\nc(lower, upper)\n\n[1] -0.02707706  0.28707706\n\n\nNote: we follow the order of the book and take p1 as the percentage for the treatment group and p2 as the percentage for the control group.\n\n\n12.3.1.2 Summary data\nWhen you have only summary data, i.e. information about the sample size and sample proportion, we recommend using prop.test for calculating a confidence interval for the difference between proportions in two samples. The function prop.test is part of the package stats, which is one of the few packages that R automatically loads when it starts.\n\nprop.test(x = c(14, 11),\n          n = c(40, 50),\n          conf.level = 0.90,\n          correct=FALSE)\n\n\nprop.test\n\nThis is the function that conducts a test for proportions.\n\nx = c(14, 11)\n\nHere we specify the number of ‘successes’ for each group (in this case the number of survivors in each group).\n\nn = c(40, 50)\n\nThe second value specified should be the number of trials for each of the two samples (read: the number of observations in our dataset). In our case: the number of participants in both groups.\n\nconf.level = 0.90\n\nThis determines the confidence level. The default is 0.95 which corresponds to a 95% confidence interval. We set the interval to 0.90.\n\ncorrect = FALSE\n\nThis sets the continuity correction to FALSE. This should provide the same results as the manual calculations above.\n\n\n\n\n\n    2-sample test for equality of proportions without continuity correction\n\ndata:  c(14, 11) out of c(40, 50)\nX-squared = 1.872, df = 1, p-value = 0.1712\nalternative hypothesis: two.sided\n90 percent confidence interval:\n -0.02707706  0.28707706\nsample estimates:\nprop 1 prop 2 \n  0.35   0.22 \n\n\n\n\n\n12.3.2 Hypothesis test for the difference between two proportions\nWe use the mammogram data set from the openintro package. The data set contains data from an experiment where 89,835 women were randomized to either get a mammogram or a non-mammogram breast screening. The response measured was whether they had died from breast cancer within 25 years.\n\nlibrary(openintro)\nlibrary(flextable) \ndata(mammogram)\n\n# Refactor variables to control the order of categories in the cross table\nmammogram &lt;- mammogram |&gt;\n  mutate(breast_cancer_death = factor(breast_cancer_death, levels = c(\"yes\", \"no\"), ordered=TRUE)) |&gt;\n  mutate(treatment = factor(treatment, levels = c(\"mammogram\", \"control\"), ordered = TRUE))\n\ntable_example &lt;- proc_freq(x = mammogram, \n                           row = \"treatment\", \n                           col = \"breast_cancer_death\", \n                           include.row_percent = FALSE, \n                           include.column_percent = FALSE, \n                           include.table_percent = FALSE) \ntable_example\n\ntreatmentbreast_cancer_deathyesnoTotalmammogram50044,42544,925control50544,40544,910Total1,00588,83089,835\n\n\n \nThis table is the same as Table 6.2 on p. 219.\n\n12.3.2.1 Calculation by hand using R\nTo test the hypothesis whether there was a difference in breast cancer deaths in the two groups by hand, we can write:\n\n# Define input (change these according to your values)\np_hat_1 = 500 / (500 + 44425)\np_hat_2 = 505 / (505 + 44405)\nn_1 = 500 + 44425 #this is the total number of subjects in the first group\nn_2 = 505 + 44405 #this is the total number of subjects in the second group\nnull_value = 0\n\n# Perform calculations (no need to change anything here)\np_hat_pooled = (p_hat_1 * n_1 + p_hat_2 * n_2) / (n_1 + n_2)\npoint_est = p_hat_1 - p_hat_2\nse = sqrt((p_hat_pooled*(1-p_hat_pooled)/n_1)+(p_hat_pooled*(1-p_hat_pooled)/n_2))\nz = (point_est - null_value)/se\npnorm(z)\n\n[1] 0.434892\n\n\nThe lower tail area is 0.4349 (small difference compared to the book due to rounding). The p-value, represented by both tails together, is 0.434892*2 = 0.869784. Because this value \\(p &gt; 0.05\\), we do not reject the null hypothesis.\nWe can visualize this as follows:\n\nlibrary(visualize)\nvisualize.norm(stat = c(-z, z), section = \"tails\")\n\n\n\n\n\n\n\n\n\n\n12.3.2.2 Summary data\nAlternatively, we can use the R function prop.test() to test for the difference between the two groups. We used this function in week 4 already for the calculation of a single proportion. The function prop.test is part of the package stats, which is one of the few packages that R automatically loads when it starts. For our purpose, we use it as follow:\n\nresult &lt;- prop.test(x = c(500, 505), \n                    n = c(44925, 44910),\n                    alternative = \"two.sided\",\n                    correct = FALSE)\nresult\n\n\n    2-sample test for equality of proportions without continuity correction\n\ndata:  c(500, 505) out of c(44925, 44910)\nX-squared = 0.026874, df = 1, p-value = 0.8698\nalternative hypothesis: two.sided\n95 percent confidence interval:\n -0.001490590  0.001260488\nsample estimates:\n    prop 1     prop 2 \n0.01112966 0.01124471 \n\n\n\nprop.test(\n\nThis is the function that conducts a test for a proportion.\n\nx = c(500, 505),\n\nHere we indicate the number of cases that are in our two groups. In this example, 500 patients who received a mammogram and died and 505 patients who did not receive a mammogram and died. Because these are two values, we combine them using ‘c()’.\n\nn = c(44925, 44910),\n\nThe second value specified should be the total number of trials. In our case: the total number of patients in the two groups. Because these are two values, we combine them using ‘c()’.\n\nalternative = \"two.sided\"\n\nDetermine whether we want to use a two sided-test, or a one-sided test. Options are “two.sided” (default), “less” (when \\(H_1: \\mu &lt; p\\)) or “greater” (when \\(H_1: \\mu &gt; p\\)).\n\ncorrect = FALSE)\n\nWith this, we indicate that we do not want to calculate the confidence interval using a ‘continuity correction’. By default, this value is set to ‘TRUE’.\n\n\n\n\n12.3.2.3 Data in a data frame\nIf you have a data frame with a variable that, for each case, represents one of two possible outcomes (in statistical terms “success” and “failure”), we can use prop.test.\n\nprop.test(table(mammogram$treatment, mammogram$breast_cancer_death), \n          alternative = \"two.sided\",\n          correct = FALSE)\n\n\n    2-sample test for equality of proportions without continuity correction\n\ndata:  table(mammogram$treatment, mammogram$breast_cancer_death)\nX-squared = 0.026874, df = 1, p-value = 0.8698\nalternative hypothesis: two.sided\n95 percent confidence interval:\n -0.001490590  0.001260488\nsample estimates:\n    prop 1     prop 2 \n0.01112966 0.01124471 \n\n\n\nprop.test(table(mammogram$treatment, mammogram$breast_cancer_death),\n\nThis is the function that conducts a test for a proportion. We select the independent variable (mammogram$treatment) and dependent variable (mammogram$breast_cancer_death). Note that the order of the variables matters for the confidence interval: so list the independent first and then the dependent variable.\n\nalternative = \"two.sided\"\n\nDetermine whether we want to use a two sided-test, or a one-sided test. Options are “two.sided” (default), “less” (when \\(H_1: \\mu &lt; p\\)) or “greater” (when \\(H_1: \\mu &gt; p\\)).\n\ncorrect = FALSE\n\nWith this, we indicate that we do not want to calculate the confidence interval using a ‘continuity correction’. By default, this value is set to ‘TRUE’.\n\n\nThe results are identical to the example above that used the summary data.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Inference for proportions</span>"
    ]
  },
  {
    "objectID": "analysis_06_proportions.html#reporting-the-results-from-a-hypothesis-test-for-the-difference-in-two-proportions",
    "href": "analysis_06_proportions.html#reporting-the-results-from-a-hypothesis-test-for-the-difference-in-two-proportions",
    "title": "12  Inference for proportions",
    "section": "12.4 Reporting the results from a hypothesis test for the difference in two proportions",
    "text": "12.4 Reporting the results from a hypothesis test for the difference in two proportions\n\n# Define input (change these according to your values)\np_hat_1 = 70 / 330\np_hat_2 = 90 / 470\nn_1 = 330 #this is the total number of subjects in the first group\nn_2 = 470 #this is the total number of subjects in the second group\nnull_value = 0\n\n# Perform calculations (no need to change anything here)\np_hat_pooled = (p_hat_1 * n_1 + p_hat_2 * n_2) / (n_1 + n_2)\npoint_est = p_hat_1 - p_hat_2\nse = sqrt((p_hat_pooled*(1-p_hat_pooled)/n_1)+(p_hat_pooled*(1-p_hat_pooled)/n_2))\nz = (point_est - null_value)/se\nz\n\n[1] 0.7181896\n\n2*pnorm(q=z, lower.tail=FALSE)\n\n[1] 0.4726404\n\n# Results using prop.test\nprop.test(x = c(70, 90), \n                    n = c(330, 470),\n                    alternative = \"two.sided\",\n                    correct = FALSE)\n\n\n    2-sample test for equality of proportions without continuity correction\n\ndata:  c(70, 90) out of c(330, 470)\nX-squared = 0.5158, df = 1, p-value = 0.4726\nalternative hypothesis: two.sided\n95 percent confidence interval:\n -0.03603276  0.07729646\nsample estimates:\n   prop 1    prop 2 \n0.2121212 0.1914894 \n\n\n\n\n\n\n\n\nOutput explanation\n\n\n\n\nthe probability of finding the observed (\\(z\\) or \\(\\chi^2\\), given the null hypothesis (p-value) is given as follows:\n\nin R, see p-value = 0.009823. Note: If the value is very close to zero, R may use the scientific notation for small numbers (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022). In these cases, write p &lt; 0.001 in your report.\n\n\n\n\n\n12.4.0.1 Reporting\nIf you calculate the results by hand and obtain a z-score, then the correct report includes:\n\nA conclusion about the null hypothesis; followed by\nInformation about the sample percentage and the population percentage.\n\\(z\\) = the value of z.\np = p-value. When working with statistical software, you should report the exact p-value that is displayed.\n\nin R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p &lt; 0.001 in your report.\n\n\nIf you calculate the results using prop.test and obtain a \\(\\chi^2\\)-score, then the correct report includes:\n\nA conclusion about the null hypothesis; followed by\nInformation about the sample percentage and the population percentage.\n\\(\\chi^2\\) = the value of chi-square, followed by the degrees of freedom in brackets.\np = p-value. When working with statistical software, you should report the exact p-value that is displayed.\n\nin R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p &lt; 0.001 in your report.\n\n\n\n\n\n\n\n\nReport\n\n\n\n✓ There is no statistically significant difference between the percentage of citizens who were somewhat dissatisfied with democracy before the election (21.21%, n = 330) and after the election (19.14%, n = 470), z = 0.72, p = 0.47.\n✓ There is no statistically significant difference between the percentage of citizens who were somewhat dissatisfied with democracy before the election (21.21%, n = 330) and after the election (19.14%, n = 470), \\(\\chi^2\\) (1) = 0.51, p = 0.47.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Inference for proportions</span>"
    ]
  },
  {
    "objectID": "analysis_06_proportions.html#footnotes",
    "href": "analysis_06_proportions.html#footnotes",
    "title": "12  Inference for proportions",
    "section": "",
    "text": "If you really like pipes, you can also use: example_data |&gt; pull(party_choice) |&gt; table() .↩︎\nIf you would like to calculate the confidence interval for the second category, you can use, for example, relevel to re-order the categories of the first variable:\n\nprop.test(table(relevel(example_data$party_choice, ref = \"Other party\")),\n          conf.level = 0.95)\n\n\n    1-sample proportions test with continuity correction\n\ndata:  table(relevel(example_data$party_choice, ref = \"Other party\")), null probability 0.5\nX-squared = 290.52, df = 1, p-value &lt; 2.2e-16\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.7423954 0.7954986\nsample estimates:\n   p \n0.77 \n\n\n↩︎\nThis uses a slightly more complicated formula for calculating the confidence interval (Wilson score interval), also incorporating a ‘continutiy correction’ (which accounts for the fact that we are using a continuous normal distribution to approximate a discrete phenomenon, i.e. the number of successes)↩︎",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Inference for proportions</span>"
    ]
  },
  {
    "objectID": "analysis_07_chi_squared.html",
    "href": "analysis_07_chi_squared.html",
    "title": "13  Chi-squared and measures of association",
    "section": "",
    "text": "13.1 Chi-square test for a one-way table\nIn R, the function chisq.test performs chi-square tests.\nWe can use a chi-square test to determine if a sample is representative of the general population. In the book, data from a random sample of 275 jurors in a small county is presented. Assume we have such a one-way table which shows frequency counts for a categorical variable and the population proportion. In this case, we can calculate the chi-square test as follows:\n# Openintro example from p. 229 - 235\nchisq &lt;- chisq.test(x = c(205, 26, 25, 19), \n                    p = c(0.72, 0.07, 0.12, 0.09))\nWe can see the results by looking at the object chisq.\nchisq\n\n\n    Chi-squared test for given probabilities\n\ndata:  c(205, 26, 25, 19)\nX-squared = 5.8896, df = 3, p-value = 0.1171\nThe output indicates the title of the test, which variables have been used, the \\(\\chi^2\\) test statistic, the degrees of freedom and the p-value.\nYou can get the expected frequencies via:\nchisq$expected\n\n[1] 198.00  19.25  33.00  24.75",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chi-squared and measures of association</span>"
    ]
  },
  {
    "objectID": "analysis_07_chi_squared.html#chi-square-test-for-a-one-way-table",
    "href": "analysis_07_chi_squared.html#chi-square-test-for-a-one-way-table",
    "title": "13  Chi-squared and measures of association",
    "section": "",
    "text": "chisq &lt;- chisq.test(\n\nThis conducts a chi-square test and stores the results in an object called chisq. You can choose a different name for chisq.\n\nx = c(205, 26, 25, 19),\n\nThese are the selected jurors (same data as presented in the book).\n\np = c(0.72, 0.07, 0.12, 0.09))\n\nThese are the population proportions.\n\n\n\n\n\n\n\n\nchisq$expected\n\nThis gives you a vector with expected frequencies. If you have chosen an different name for chisq, change it here as well.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chi-squared and measures of association</span>"
    ]
  },
  {
    "objectID": "analysis_07_chi_squared.html#chi-square-test-for-a-contingency-table",
    "href": "analysis_07_chi_squared.html#chi-square-test-for-a-contingency-table",
    "title": "13  Chi-squared and measures of association",
    "section": "13.2 Chi-square test for a contingency table",
    "text": "13.2 Chi-square test for a contingency table\nWe demonstrate the use of chi-square test for a contingency table with two variables from the 2019 Canadian Election Study:\n\n# Loading the data sets\nlibrary(rio)\ncanada &lt;- import(\"2019 Canadian Election Study.rds\")\n\nThe first variable cps19_fed_gov_sat measures the general satisfaction with the government and the second variable measures the overall satisfaction with democracy (cps19_demsat).\nFirst, we treat the answer option “Don’t know/ Prefer not to answer” as missing data (see section ‘Recoding missing data’ in week 4).\n\nlibrary(tidyverse) # Load tidyverse for data operations\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(flextable) # Load flextable for frequency table\n\n\nAttaching package: 'flextable'\n\nThe following object is masked from 'package:purrr':\n\n    compose\n\n# Define missing values and drop factor levels that are not present in the data\ncanada &lt;- canada |&gt;\n  mutate(cps19_fed_gov_sat = na_if(cps19_fed_gov_sat, \"Don't know/ Prefer not to answer\")) |&gt;\n  mutate(cps19_demsat = na_if(cps19_demsat, \"Don't know/ Prefer not to answer\")) |&gt;\n  mutate(cps19_fed_gov_sat = droplevels(cps19_fed_gov_sat)) |&gt;\n  mutate(cps19_demsat = droplevels(cps19_demsat))\n\n#Create a contingency table\ntable_example &lt;- proc_freq(x = canada, \n                           row = \"cps19_demsat\", \n                           col = \"cps19_fed_gov_sat\", \n                           include.row_percent = FALSE, \n                           include.table_percent = FALSE) \ntable_example\n\ncps19_demsatcps19_fed_gov_satVery satisfiedFairly satisfiedNot very satisfiedNot at all satisfiedMissingTotalVery satisfiedCount1,6042,407913804525,780Col. pct55.5%18.2%9.2%7.2%7.7%Fairly satisfiedCount1,1099,0775,9774,67330921,145Col. pct38.4%68.7%60.1%42.1%45.8%Not very satisfiedCount1151,3952,5703,8261218,027Col. pct4.0%10.6%25.8%34.5%18.0%Not at all satisfiedCount221372511,497281,935Col. pct0.8%1.0%2.5%13.5%4.2%MissingCount40199232300164935Col. pct1.4%1.5%2.3%2.7%24.3%TotalCount2,89013,2159,94311,10067437,822\n\n\nTo calculate \\(\\chi^2\\), we use the chisq.test() function.\n\nchisq &lt;- chisq.test(canada$cps19_demsat, canada$cps19_fed_gov_sat)\nchisq\n\n\n    Pearson's Chi-squared test\n\ndata:  canada$cps19_demsat and canada$cps19_fed_gov_sat\nX-squared = 9053.6, df = 9, p-value &lt; 2.2e-16\n\n\n\nchisq &lt;- chisq.test(\n\nThis conducts a chi-square test and stores the results in an object called chisq. You can choose a different name for chisq.\n\ncanada$cps19_demsat, canada$cps19_fed_gov_sat)\n\nWe indicate the two variables that we want to use. Note that you have to use the dollar sign notation here, i.e. &lt;dataset&gt;$&lt;variable&gt;\n\n\nThe output indicates the title of the test, which variables have been used, the \\(\\chi^2\\) test statistic, the degrees of freedom and the p-value.\nNote that the \\(\\chi^2\\) value might be rounded if it is very large (of it is larger than 5 digits). In any case, you can get the exact \\(\\chi^2\\) value by writing:\n\nchisq$statistic \n\nX-squared \n 9053.595 \n\n\nYou can get the expected frequencies via:\n\nchisq$expected\n\n                      canada$cps19_fed_gov_sat\ncanada$cps19_demsat    Very satisfied Fairly satisfied Not very satisfied\n  Very satisfied             448.7671        2049.5271           1529.115\n  Fairly satisfied          1632.4216        7455.2980           5562.262\n  Not very satisfied         619.4051        2828.8340           2110.541\n  Not at all satisfied       149.4062         682.3408            509.082\n                      canada$cps19_fed_gov_sat\ncanada$cps19_demsat    Not at all satisfied\n  Very satisfied                  1700.5910\n  Fairly satisfied                6186.0186\n  Not very satisfied              2347.2194\n  Not at all satisfied             566.1709\n\n\n\nchisq$expected\n\nThis gives you a table with expected frequencies. If you have chosen an different name for chisq, change it here as well. Depending on your screen size, the table might be broken into different parts (see ‘Not at all satisfied’).\n\n\n\n13.2.1 When expected frequencies are small\nIf the smallest expected frequencies is lower than 5, you can either:\n\ncombine some levels with a small number of observations to increase the number of observations in these subgroups, or\nuse alternative tests, such as the Fisher’s exact test.\n\nAssume you have the following data of 20 countries for which we have gathered data on their OECD membership and their economic development:\n\n# Define dataset\ndata &lt;- data.frame(oecd = c(rep(\"no\", 9), rep(\"no\", 1), rep(\"yes\", 2), rep(\"yes\", 8)), \n                   econ = c(rep(\"low\", 9), rep(\"high\", 1), rep(\"low\", 2), rep(\"high\", 8)))\n# Print a cross table of the two variables in data\ntable(data$econ, data$oecd)\n\n      \n       no yes\n  high  1   8\n  low   9   2\n\n\nThe expected frequencies in some of the cells will be &lt; 5.\nWe can calculate the \\(\\chi^2\\) value with chisq.test() as we did previously:\n\nchisq &lt;- chisq.test(data$econ, data$oecd)\n\nWarning in chisq.test(data$econ, data$oecd): Chi-squared approximation may be\nincorrect\n\nchisq\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  data$econ and data$oecd\nX-squared = 7.2727, df = 1, p-value = 0.007001\n\n\nThe output indicates that R automatically calculates ‘Pearson’s Chi-squared test with Yates’ continuity correction’ (see the title of the test). The rest of the output stays the same (which variables have been used, the \\(\\chi^2\\) test statistic, the degrees of freedom and the p-value). However, Yates continuity correction is not our preferred option.\n\nIn some instances, R may give you a warning such as “Chi-squared approximation may be incorrect”. This means that the expected values will be very small and therefore the approximations of p may not be right.\n\nInstead, we want to conduct our independence test for a small sample with the Fisher’s exact test. To perform this test in R, use the fisher.test() function as you would do for the Chi-square test:\n\nfisher.t &lt;- fisher.test(data$econ, data$oecd)\nfisher.t\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  data$econ and data$oecd\np-value = 0.005477\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.0005746857 0.4859089384\nsample estimates:\nodds ratio \n0.03659475 \n\n\n\nfisher.test &lt;- fisher.test(\n\nThis conducts the Fisher’s exact test and stores the results in an object called fisher.t. You can choose a different name for fisher.t.\n\nfisher.test(data$econ, data$oecd)\n\nWe mention the two variables for the function fisher.test().\n\n\nThe output indicates the title of the test, which variables have been used and the p-value. We report the output with a statement about the null hypothesis followed by (p = p-value, Fisher’s exact test)",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chi-squared and measures of association</span>"
    ]
  },
  {
    "objectID": "analysis_07_chi_squared.html#reporting-a-chi-square-test-and-fishers-exact-test",
    "href": "analysis_07_chi_squared.html#reporting-a-chi-square-test-and-fishers-exact-test",
    "title": "13  Chi-squared and measures of association",
    "section": "13.3 Reporting a Chi square test and Fisher’s Exact Test",
    "text": "13.3 Reporting a Chi square test and Fisher’s Exact Test\nIn a scientific paper, you do not include the output from the statistical program (R, SPSS) but report the results in the text. For this example. we use the following data:\n\nExample output R (do not include the output directly in an academic paper):\n\nchisq &lt;- chisq.test(df$study_choice, df$pet_choice)\n\nchisq\n\n\n    Pearson's Chi-squared test\n\ndata:  df$study_choice and df$pet_choice\nX-squared = 124.9, df = 2, p-value &lt; 2.2e-16\n\n\n\n\n\n\n\n\nOutput explanation\n\n\n\n\n124.9 is the observed chi square value (\\(\\chi^2\\)).\ndf is the degrees of freedom (here: 2).\nthe probability of finding the observed (\\(\\chi^2\\), given the null hypothesis (p-value) is given as follows:\n\nin R, see p-value &lt; 2.2e-16. 2.2e-16 is the scientific notation of 0.00000000000000022. This means the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p &lt; 0.001 in your report. \n\n\nNote: If you calculate the results by hand you write p &lt; “the chosen \\(\\alpha\\)-value”, for example, p &lt; 0.05.\n\n\n\n13.3.0.1 Reporting\nThe correct report includes:\n\nA conclusion about the null hypothesis; followed by\n\\(\\chi^2\\)(df) = the value of chi square and the degrees of freedom in brackets. The degrees of freedom is calculated as (number of rows – 1)*( number of columns– 1) and can be obtained from the output.\np = p-value. When working with statistical software, you should report the exact p-value that is displayed.\n\nin R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p &lt; 0.001 in your report. \n\n\nNote: If you calculate the results by hand you write p &lt; “the chosen \\(\\alpha\\)-value”, for example, p &lt; 0.05.\n\n\n\n\n\n\nReport\n\n\n\n✓ There is a significant relationship between the type of pet a respondent wants and the choice of study program (\\(\\chi^2\\)(2) = 124.9, p\\(&lt;\\) 0.001)",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chi-squared and measures of association</span>"
    ]
  },
  {
    "objectID": "analysis_07_chi_squared.html#fishers-exact-test",
    "href": "analysis_07_chi_squared.html#fishers-exact-test",
    "title": "13  Chi-squared and measures of association",
    "section": "13.4 Fisher’s Exact Test",
    "text": "13.4 Fisher’s Exact Test\nFisher’s Exact Test should be used in the case of small expected frequencies. Assume you have the following data of 20 countries for which we have gathered data on their OECD membership and their economic development:\n\n\n      \n       no yes\n  high  1   8\n  low   9   2\n\n\nExample output R (do not include the output directly in an academic paper):\n\nfisher.test(data$econ, data$oecd)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  data$econ and data$oecd\np-value = 0.005477\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.0005746857 0.4859089384\nsample estimates:\nodds ratio \n0.03659475 \n\n\n\n\n\n13.4.0.1 Reporting\nFor Fisher’s Exact test, simply write a statement about the null hypothesis followed by the p-value (e.g. p = p-value, Fisher’s exact test).\n\n\n\n\n\n\nReport\n\n\n\n✓ There is a significant relationship between the membership status of a country to the OECD and its economic development, p \\(=\\) 0.005, Fisher’s exact test).",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chi-squared and measures of association</span>"
    ]
  },
  {
    "objectID": "analysis_07_chi_squared.html#measures-of-association",
    "href": "analysis_07_chi_squared.html#measures-of-association",
    "title": "13  Chi-squared and measures of association",
    "section": "13.5 Measures of association",
    "text": "13.5 Measures of association\n\n13.5.1 Phi/Cramér’s V\nPhi and Cramér’s V are measures of the strength of association between two nominal or ordinal variables. They range from 0 to 1. The DescTools package contains the functions Phi (with a capital P) and CramerV (with a capital C and a capital V). If it is not yet installed you can do so via install.packages(\"DescTools\").\n\nlibrary(DescTools)\n\nYou can then calculate the measure of association. Note that you can only use the function Phi for 2x2 cross-tables. CramerV works for 2x2 cross-tables (which will give the same result as Phi) and larger cross-tables (Cramér’s V).\n\nPhi(data$econ, data$oecd) #2x2 cross-table\n\n[1] 0.7035265\n\nCramerV(data$econ, data$oecd) #2x2 cross-table\n\n[1] 0.7035265\n\nCramerV(canada$cps19_demsat, canada$cps19_fed_gov_sat) #larger cross-table\n\n[1] 0.2880292\n\n\n\n\n13.5.2 Goodman-Kruskal’s Lambda\nGoodman-Kruskal’s Lambda (\\(\\lambda\\)) can be calculated using a function from the DescTools package.\n\nlibrary(DescTools)\n\nWe use Lambda for any sample with an independent variable and a dependent variable. We demonstrate its use with two variables from the 2019 Canadian Election Study. As independent variable we use a variable regarding the respondents’ gender (cps19_gender) and as dependent variable we use party the respondent intents to vote for (cps19_votechoice). We again treat the answer option “Don’t know/ Prefer not to answer” as missing data.\n\n# Define missing values and drop factor levels that are not present in the data\ncanada &lt;- canada |&gt;\n  mutate(cps19_votechoice = na_if(cps19_votechoice, \"Don't know/ Prefer not to answer\")) |&gt;\n  mutate(cps19_votechoice = droplevels(cps19_votechoice)) \n\n#Create a contingency table\ntable_example &lt;- proc_freq(x = canada, \n                           row = \"cps19_votechoice\", \n                           col = \"cps19_gender\", \n                           include.row_percent = FALSE, \n                           include.table_percent = FALSE) \ntable_example\n\ncps19_votechoicecps19_genderA manA womanOther (e.g. Trans, non-binary, two-spirit, gender-queer)TotalLiberal PartyCount3,7765,122518,949Col. pct24.3%23.3%17.5%Conservative PartyCount4,2824,388438,713Col. pct27.5%20.0%14.8%ndpCount1,3532,896794,328Col. pct8.7%13.2%27.1%Bloc QuébécoisCount71068861,404Col. pct4.6%3.1%2.1%Green PartyCount9121,522222,456Col. pct5.9%6.9%7.6%People's PartyCount3152864605Col. pct2.0%1.3%1.4%Another party (please specify)Count100983201Col. pct0.6%0.4%1.0%MissingCount4,1036,9808311,166Col. pct26.4%31.8%28.5%TotalCount15,55121,98029137,822\n\n\nTo calculate Lambda, write:\n\nLambda(x = canada$cps19_votechoice, \n       y = canada$cps19_gender,\n       direction = \"row\")\n\n[1] 0.03015756\n\n\n\nLambda\n\nThis calculates Goodman-Kruskal’s Lambda. Make sure to use a capital ‘L’ for the function.\n\nx = canada$cps19_votechoice\n\nInclude the variable that is in the rows here (the dependent variable).\n\ny = canada$cps19_gender\n\nInclude the variable that is in the columns here (the independent variable).\n\ndirection = \"row\"\n\nDirection can take three values: \"symmetric\" (default), \"row\" or \"column\". If our dependent variable is in the rows, we suggest to set this to row, which calculates the improvement in predicting the row variable if we have information about the column variable.\n\n\n\n13.5.2.1 Goodman-Kruskal’s Gamma\nGoodman-Kruskal’s Gamma (\\(\\gamma\\)) can also be calculated using a function from the DescTools package.\nGoodman-Kruskal’s Gamma is appropriate only when both variables lie on an ordinal scale. We use the two variables from above (the general satisfaction with the government and the overall satisfaction with democracy). To calculate it, write:\n\nGoodmanKruskalGamma(canada$cps19_demsat, canada$cps19_fed_gov_sat)\n\n[1] 0.5528955\n\n\n\nGoodmanKruskalGamma(\n\nThis calculates Goodman-Kruskal’s Gamma Make sure to write the whole function correctly (including capitalization).\n\ncanada$cps19_demsat, canada$cps19_fed_gov_sat)\n\nThe two variables that we use for our calculation. The order of the variable names does not matter for the calculation but it is best to keep the same order as usual.\n\n\n\nThe order of values is very important for the calculation of Gamma. Therefore, always check whether the categories in the variables are in the correct order (for example by making a cross table).",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chi-squared and measures of association</span>"
    ]
  },
  {
    "objectID": "analysis_07_chi_squared.html#reporting-measures-of-association-for-categorical-variables",
    "href": "analysis_07_chi_squared.html#reporting-measures-of-association-for-categorical-variables",
    "title": "13  Chi-squared and measures of association",
    "section": "13.6 Reporting measures of association for categorical variables",
    "text": "13.6 Reporting measures of association for categorical variables\nIf you want to include a measure of association for the test result, you can add this to the report.\n\n13.6.1 Phi (\\(\\phi\\)) and Cramér’s V\nR will directly provide you with the value of Phi (\\(\\phi\\)) and Cramér’s V when you use the functions Phi() and CramerV().\nExample output R (do not include the output directly in an academic paper):\nFor the OECD data, the value of Phi is:\n\nPhi(data$econ, data$oecd) #2x2 cross-table\n\n[1] 0.7035265\n\n\nFor the data concerning study choice and pet choice, the value of Cramér’s V is:\n\nCramerV(df$study_choice, df$pet_choice) #larger cross-table\n\n[1] 0.2991134\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nPhi (\\(\\phi\\)) runs from 0 to 1, where:\n\n0 is no relationship.\n1 is a perfect association. Visually, in such cases all of your observations fall along the diagonal cells in the cross table.\n\nResearchers typically use Cohen’s guidelines of interpreting the magnitude of \\(\\phi\\) [@cohen1988]:\n\nA value of at least 0.1 represents a small association.\nA value of at least 0.3 represents a medium association.\nA value of at least 0.5 represents a large association.\n\nThe interpretation of Cramér’s V is the same as for Phi (\\(\\phi\\)). It runs from 0 to 1 and researchers typically use Cohen’s guidelines of interpreting the magnitude. Squaring (\\(\\phi\\)) and Cramér’s V will give you the approximate amount of shared variance between the two variables.\nNote that these guidelines are “crude estimates” for interpreting strengths of relationships. As always with rules of thumbs, be careful and consider the type of data that you are working with.\n\n\n\n13.6.1.1 Reporting\nPhi (\\(\\phi\\)) and Cramér’s V are usually included after the chi-squared test, for example:\n\n\n\n\n\n\nReport \\(\\phi\\)\n\n\n\n✓ There is a significant relationship between the OECD membership status of a country and the country’s economic development, \\(\\chi^2\\)(1) = 9.90, p = 0.01. This represents a large association, \\(\\phi\\) = 0.704.\n\n13.6.1.1.1 Report Cramér’s V\n✓ There is a significant relationship between the type of pet a respondent wants and the choice of study program (\\(\\chi^2\\)(2) = 124.9, p\\(&lt;\\) 0.001). This represents a medium association, Cramér’s V = 0.299.\n\n\n\n\n\n\n13.6.2 Goodman & Kruskal’s Lambda (\\(\\lambda\\)).\nLambda is an asymmetrical measure of association. This means that the value may vary depending on which variable is considered the independent variable and which the dependent variable. In the example above the study choice was the dependent variable.\nExample output R (do not include the output directly in an academic paper):\nR will directly provide you with the value of Lambda (\\(\\lambda\\)) when you use the function Lambda().\n\nLambda(table(df$study_choice, df$pet_choice),\n       direction = \"row\")\n\n[1] 0.09902913\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThe range of Lambda runs from 0.0 to 1.0. Because it is a measure of proportional reduction in error, a lambda of 0.xx indicates that we make xx% less errors when we have information about the independent variable (compared to when we do not have this information).\nA lambda of 0.0 indicates that there is nothing to be gained by using the independent variable to predict the dependent variable. A lambda of 1.0 indicates that the independent variable perfectly predicts of the dependent variable. In other words, by using the independent variable as a predictor, we can predict the dependent variable without any error.\nThere is no formal way to determine if the value for \\(\\lambda\\) is high or low, and the rules of thumb often depend on the field (e.g. biology, medicine, business, etc.). Rea and Parker (1992) suggest the following:\n\n± 0.00 &lt; 0.10 - Negligible\n± 0.10 &lt; 0.20 - Weak\n± 0.20 &lt; 0.40 - Moderate\n± 0.40 &lt; 0.60 - Relatively strong\n± 0.60 &lt; 0.80 - Strong\n± 0.80 &lt; 1.00 - Very strong\n\n\n\n\n13.6.2.1 Reporting\n\n\n\n\n\n\nReport\n\n\n\n✓ There is a weak relationship between the type of pet a respondent wants and the choice of study program λ = 0.099.\n\n\n\n\n\n13.6.3 Goodman & Kruskal’s Gamma (\\(\\gamma\\))\nGoodman-Kruskal’s Gamma (\\(\\gamma\\)) is appropriate only when both variables lie on an ordinal scale. Gamma is defined as an symmetrical measure of association which means that you will get the same value for \\(\\gamma\\) if you switch the dependent and independent variable in your contingency stable. We demonstrate \\(\\gamma\\) using two ordinal variables on class ranks and alcohol consumption of students.\n\nExample output R (do not include the output directly in an academic paper):\nR will directly provide you with the value of Gamma (\\(\\gamma\\)) when you use the functions GoodmanKruskalGamma().\n\nGoodmanKruskalGamma(gammadf$alcohol, gammadf$class_rank)\n\n[1] 0.3177245\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThe range of gamma is -1.0 to +1.0. A gamma of 0.0 indicates that there is no relationship between the two variables. In other words, the independent variable does not help at all to predict the dependent variable. A gamma of 1.0 indicates that the dependent variable can be predicted by the independent variable without any error and that the relationship between the variables is positive. Likewise, when gamma is -1.0, the independent variable can perfectly predict the dependent variable with no error but the relationship is negative.\nFor example, if the value for \\(\\gamma\\) is 0.30, this means that by knowing about the level of the independent variable we can make a 30% better estimate about the dependent variable. Given that the value is positive, we also know the direction: as the level of the independent variable goes up, the level of the dependent variable goes up, too.\nThere is no formal way to determine if the value for \\(\\gamma\\) is high or low, and the rules of thumb often depend on the field (e.g. biology, medicine, business, etc.). Rea and Parker (1992) suggest the following:\n\n± 0.00 &lt; 0.10 - Negligible\n± 0.10 &lt; 0.20 - Weak\n± 0.20 &lt; 0.40 - Moderate\n± 0.40 &lt; 0.60 - Relatively strong\n± 0.60 &lt; 0.80 - Strong\n± 0.80 &lt; 1.00 - Very strong\n\n\n\n\n13.6.3.1 Reporting\n\n\n\n\n\n\nReport\n\n\n\n✓ There is a ‘medium’ sized (or ‘moderate’) positive relationship between the class rank of a respondent and the frequency of drinking alcohol, \\(\\gamma\\) = 0.318",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Chi-squared and measures of association</span>"
    ]
  },
  {
    "objectID": "analysis_08_t-test.html",
    "href": "analysis_08_t-test.html",
    "title": "14  T-tests for means",
    "section": "",
    "text": "14.1 Standard error of the mean\nThe standard error of the mean can be estimated as \\(\\frac{s}{\\sqrt{n}}\\). In R we can use the function MeanSE from package DescTools:\nlibrary(DescTools)\nexample_vector &lt;- rnorm(20)  # Example data of 20 normally distributed random numbers.\n\nMeanSE(x = example_vector, \n       na.rm = TRUE)\n\n[1] 0.1819438\nYou can also use MeanSE for a variable in a data frame:\n# Using $ to select a variable from a data frame\nMeanSE(canada$cps19_age, na.rm = TRUE)  \n\n[1] 0.08541655\n\n# Using function summarise\ncanada |&gt;\n  summarise(SE_age = MeanSE(cps19_age, na.rm = TRUE))\n\n      SE_age\n1 0.08541655\nThe describe function in package psych provides the Standard Error for the Mean for all variables in a data frame. It is particularly useful when we would like to quickly calculate the standard error for multiple variables. In this example we select three interval-ratio variables from the 2019 Canadian Election Study (which we imported above):\nlibrary(psych)\n\n# Select three variables from 'canada' and assign to dataset 'canada_selection'\ncanada_selection &lt;- canada |&gt; \n  select(cps19_age, cps19_lr_parties_1, cps19_lr_parties_2)\n\n# Use describe to calculate summary statistics for 'canada_selection'\ndescribe(canada_selection)\n\n                   vars     n  mean    sd median trimmed   mad min max range\ncps19_age             1 37822 48.69 16.61     49   48.66 20.76  18  99    81\ncps19_lr_parties_1    2 27743  4.27  2.79      4    4.19  2.97   0  10    10\ncps19_lr_parties_2    3 28210  6.90  2.79      8    7.28  2.97   0  10    10\n                    skew kurtosis   se\ncps19_age           0.04    -0.91 0.09\ncps19_lr_parties_1  0.19    -0.77 0.02\ncps19_lr_parties_2 -0.97     0.14 0.02\nThe column se displays the standard error of the mean (by default rounded to two decimals).",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>T-tests for means</span>"
    ]
  },
  {
    "objectID": "analysis_08_t-test.html#standard-error-of-the-mean",
    "href": "analysis_08_t-test.html#standard-error-of-the-mean",
    "title": "14  T-tests for means",
    "section": "",
    "text": "MeanSE(…)\n\nThis function calculates the standard error of the mean for a vector of numbers.\n\nx = example_vector\n\nWe want to calculate the SE of the Mean for the values in example_vector. For your own data, you would change this to the appropriate vector name.\n\nna.rm = TRUE\n\nThis option ensures that any missing values are ignored.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>T-tests for means</span>"
    ]
  },
  {
    "objectID": "analysis_08_t-test.html#t-tests",
    "href": "analysis_08_t-test.html#t-tests",
    "title": "14  T-tests for means",
    "section": "14.2 T-tests",
    "text": "14.2 T-tests\n\n14.2.1 One sample t-test\nTo calculate a one sample t-test we use the function t.test:\nIn the below example we measure whether the age of respondents is different from a hypothesized mean of 48.5:1\n\nt.test(formula = cps19_age ~ 1,\n       data = canada,\n       alternative = \"two.sided\",\n       mu = 48.5,\n       conf.level = 0.95)\n\n\n    One Sample t-test\n\ndata:  cps19_age\nt = 2.2395, df = 37821, p-value = 0.02513\nalternative hypothesis: true mean is not equal to 48.5\n95 percent confidence interval:\n 48.52387 48.85871\nsample estimates:\nmean of x \n 48.69129 \n\n\n\nformula = cps19_age ~ 1\n\nAs we have only one variable in a one sample t-test, we specify the formula in the form &lt;variable name&gt; ~ 1.\n\ndata = canada\n\nWe specify the data frame that we want to use.\n\nalternative = \"two.sided\"\n\nDetermines whether we want to use a two sided-test, or a one-sided test. Options are “two.sided” (default), “less” (when \\(H_1: \\mu &lt; p\\)) or “greater” (when \\(H_1: \\mu &gt; p\\)).\n\nmu = 48.5\n\nThe mu parameter should be set to the value of the mean under the null hypothesis.\n\nconf.level = 0.95\n\nThis specifies the confidence level of the confidence interval reported. The default is 0.95 (a 95% confidence interval).\n\n\n\n\n14.2.2 Reporting a one-sample t-test\nWe illustrate the one-sample t-test using data on the fruit consumption of students. We test whether the fruit consumption is significantly different from a population value of 100.\nExample output R (do not include the output directly in an academic paper):\n\nMeanSE(fruit$fruitconsumption)\n\n[1] 1.714986\n\nt.test(x = fruit$fruitconsumption,\n           alternative = \"two.sided\",\n           mu = 100,\n           conf.level = 0.95)\n\n\n    One Sample t-test\n\ndata:  fruit$fruitconsumption\nt = -5.831, df = 33, p-value = 1.587e-06\nalternative hypothesis: true mean is not equal to 100\n95 percent confidence interval:\n 86.51084 93.48916\nsample estimates:\nmean of x \n       90 \n\n\n\n\n\n\n\n\n\n\nOutput explanation\n\n\n\n\nIn R, the output shows:\n\nthe mean of the observations in the sample (see ‘mean of x’).\nthe calculated t-value (see ‘t =’).\nthe degrees of freedom (see ‘df =’).\nthe p-value (i.e. the probability of finding the obtained t-value, given the null hypothesis).\nthe expected value under the null hypothesis (here 100, see “true mean is not equal to 100”).\nthe standard error of the observations in the sample is obtained separately via MeanSE().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.2.2.1 Reporting\nThe correct report includes:\n\nA conclusion about the null hypothesis; followed by\nthe mean (in the text or as M = …) and the standard error (SE = …) of the sample.\nt(degrees of freedom)\np = p-value. When working with statistical software, you should report the exact p-value that is displayed.\n\nin R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p &lt; 0.001 in your report. \n\nIf you calculate the t-value by hand you would write p &lt; / = / &gt; your chosen \\(\\alpha\\)-level.\n\n\n\n\n\n\n\nReport\n\n\n\n✓ The mean fruit consumption of students was 90 (SE = 1.71). This is significantly different from the mean fruit consumption of the whole population (t(33) = -5.83, p &lt; 0.001).\n\n\nBelow you find an example of a non-significant result. In this case we test whether the fruit consumption is significantly different from a population value of 92.\nExample output R (do not include the output directly in an academic paper):\n\nMeanSE(fruit$fruitconsumption, na.rm = TRUE)\n\n[1] 1.714986\n\nt.test(x = fruit$fruitconsumption,\n           alternative = \"two.sided\",\n           mu = 92,\n           conf.level = 0.95)\n\n\n    One Sample t-test\n\ndata:  fruit$fruitconsumption\nt = -1.1662, df = 33, p-value = 0.2519\nalternative hypothesis: true mean is not equal to 92\n95 percent confidence interval:\n 86.51084 93.48916\nsample estimates:\nmean of x \n       90 \n\n\n\n\n\n\n\n\n\n\nReport\n\n\n\n✓ The mean fruit consumption of students was 90 (SE = 1.71). This is not significantly different from the mean fruit consumption of the whole population (t(33) = -1.167, p = 0.252).\n\n\n\n\n\n14.2.3 Paired samples t-test\nIn a paired samples t-test we compare the mean value of two interval-ratio variables.\nIn the below example we test the null hypothesis that the mean difference of the left-right placement of the Liberal party (variable cps_lr_parties_1) and the Conservative party (variable cps19_lr_parties_2) is equal to 0 in the population.\nWe can specify the test as follows:2\n\nt.test(formula = Pair(cps19_lr_parties_1, cps19_lr_parties_2) ~ 1,\n       data = canada,\n       alternative = \"two.sided\",\n       mu = 0,\n       conf.level = 0.95)\n\n\n    Paired t-test\n\ndata:  Pair(cps19_lr_parties_1, cps19_lr_parties_2)\nt = -95.406, df = 26718, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -2.691519 -2.583155\nsample estimates:\nmean difference \n      -2.637337 \n\n\n\nformula = Pair(cps19_lr_parties_1, cps19_lr_parties_2) ~ 1\n\nWe have two paired interval-ratio variables and therefore use a formula in the form Pair(&lt;variable name 1&gt;, &lt;variable name 2&gt;) ~ 1\n\ndata = canada\n\nWe specify the data frame that we want to use.\n\nalternative = \"two.sided\"\n\nDetermines whether we want to use a two sided-test, or a one-sided test. Options are “two.sided” (default), “less” (when \\(H_1: \\mu &lt; p\\)) or “greater” (when \\(H_1: \\mu &gt; p\\)).\n\nmu = 0\n\nThe mu parameter should be set to the value of the mean under the null hypothesis. In the case of a paired sample t-test we usually hypothesize that the difference between the two means is 0 in the population, thus mu = 0.\n\nconf.level = 0.95\n\nThis specifies the confidence level of the confidence interval of the difference. The default is 0.95 (a 95% confidence interval).\n\n\n\n\n14.2.4 Reporting a paired samples t-test\nIn a paired samples t-test we compare the mean value of two interval-ratio variables. In the below example we test the null hypothesis that the mean difference of the left-right placement of the Liberal party (variable cps_lr_parties_1) and the Conservative party (variable cps19_lr_parties_2) is equal to 0 in the population.\n\nlibrary(dplyr)\n# Calculate the standard error of the mean for both variables, excluding missing observations\nMeanSE(canada$cps19_lr_parties_1, na.rm = TRUE)\n\n[1] 0.01674762\n\nMeanSE(canada$cps19_lr_parties_2, na.rm = TRUE)\n\n[1] 0.01660731\n\nt.test(x = canada$cps19_lr_parties_1, \n           y = canada$cps19_lr_parties_2,\n           data = canada,\n           alternative = \"two.sided\",\n           mu = 0,\n           paired = TRUE,\n           conf.level = 0.95)\n\n\n    Paired t-test\n\ndata:  canada$cps19_lr_parties_1 and canada$cps19_lr_parties_2\nt = -95.406, df = 26718, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -2.691519 -2.583155\nsample estimates:\nmean difference \n      -2.637337 \n\n\n\n\n\n\n\n\n\n\nOutput explanation\n\n\n\n\nIn R, the output shows: +the mean difference of the observations in the sample (see ‘mean difference’). +the calculated t-value (see ‘t =’). +the degrees of freedom (see ‘df =’). +the p-value (i.e. the probability of finding the obtained t-value, given the null hypothesis), see p-value &lt; 2.2e-16. This is a very small number which is why R displays it like this. +the expected value under the null hypothesis (here true mean difference is not equal to 0). +the standard errors of both variables in the sample are obtained separately via MeanSE().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.2.4.1 Reporting\nThe correct report includes:\n\nA conclusion about the null hypothesis;\nthe mean (in the text or as M = …) and the standard error (SE = …) of each variable.\nThe difference in the means (here -2.637337),\nthe degrees of freedom\np = p-value. When working with statistical software, you should report the exact p-value that is displayed.\n\nin R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p &lt; 0.001 in your report. \n\n\nIf you calculate the results by hand you write p &lt; “the chosen α-value”, for example, p &lt; 0.05.\n\n\n\n\n\n\nReport\n\n\n\n✓ The left-right placement of the Liberal party (M = 4.25; SE = 0.017) was lower than the left-right placement of the Conservative party (M = 6.88; SE = 0.017). This difference, -2.64, was statistically significant, t(26718) = -95.406, p &lt; 0.001.\n\n\n\n\n\n14.2.5 Independent-samples t-test\nThe independent samples t-test is used to compare whether the means of two groups are statistically significantly different. We thus have a numeric variable, for which we can calculate a mean, and a grouping variable, which is a categorical variable that determines the group membership. In our example we test whether there is a statistically significant difference in the mean placement of the Liberal party by those who are born in Canada and those who are not.\nFirst we inspect the grouping variable:\n\ntable(canada$cps19_bornin_canada)\n\n\n                          Yes                            No \n                        31556                          6046 \nDon't know/ Prefer not to say \n                          220 \n\n\nIt turns out this variable has three categories. We would like to ignore the Don’t know category, so we treat this as missing:\n\ncanada &lt;- canada |&gt;\n  mutate(cps19_bornin_canada = na_if(cps19_bornin_canada, \"Don't know/ Prefer not to say\")) \n\nNow we can run the t-test:\n\nt.test(formula = cps19_lr_parties_1 ~ cps19_bornin_canada,\n       data = canada,\n       alternative = \"two.sided\", \n       mu = 0,\n       conf.level = .95)\n\n\nformula = cps19_lr_parties_1 ~ cps19_bornin_canada\n\nWe have one interval-ratio variable and one categorical variable (factor) that captures to which group an observation belongs, thus we use a formula of the form &lt;interval-ratio variable&gt; ~ &lt;categorical variable&gt;.\n\ndata = canada\n\nWe specify the data frame that we want to use.\n\nalternative = \"two.sided\"\n\nDetermines whether we want to use a two sided-test, or a one-sided test. Options are “two.sided” (default), “less” (when \\(H_1: \\mu &lt; p\\)) or “greater” (when \\(H_1: \\mu &gt; p\\)).\n\nmu = 0\n\nThe mu parameter should be set to the value of the mean under the null hypothesis. In the case of an independent samples t-test we usually hypothesize that the difference between the two group means is 0 in the population, thus mu = 0.\n\nconf.level = 0.95\n\nThis specifies the confidence level of the confidence interval of the difference. The default is 0.95 (a 95% confidence interval).\n\n\n\n\n\n    Welch Two Sample t-test\n\ndata:  cps19_lr_parties_1 by cps19_bornin_canada\nt = -8.9025, df = 6809.2, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group Yes and group No is not equal to 0\n95 percent confidence interval:\n -0.4886007 -0.3122543\nsample estimates:\nmean in group Yes  mean in group No \n         4.196678          4.597106 \n\n\nR displays the result for the Welch Two Sample t-test, which is a version of the independent samples t-test that applies when equal variances are not assumed.\n\n\n14.2.6 Reporting an independent samples t-test\nThe independent samples t-test is used to compare whether the means of two groups are statistically significantly different. We use data on the number of gym attendances last month of male and female respondents.\nExample output R (do not include the output directly in an academic paper):\n\nlibrary(dplyr)\n\n# Calculate the standard error of the mean per group, dropping missing values. \n#These values (mean and standard error) are needed for the report.\n\ngym %&gt;%                               # Summary by group using dplyr\n  group_by(gender) |&gt;  \n  summarize(mean = mean(gym_attendance), na.rm = TRUE,\n            se = MeanSE(gym_attendance), na.rm = TRUE)\n\n# A tibble: 2 × 4\n  gender  mean na.rm     se\n  &lt;chr&gt;  &lt;dbl&gt; &lt;lgl&gt;  &lt;dbl&gt;\n1 Female  3.00 TRUE  0.0542\n2 Male    3.97 TRUE  0.0632\n\nt.test(formula = gym_attendance ~ gender,\n       data = gym,\n       alternative = \"two.sided\", \n       mu = 0,\n       conf.level = .95)\n\n\n    Welch Two Sample t-test\n\ndata:  gym_attendance by gender\nt = -11.674, df = 1944.4, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n95 percent confidence interval:\n -1.1355660 -0.8089068\nsample estimates:\nmean in group Female   mean in group Male \n            3.001031             3.973267 \n\n\n\n\n\n\n\n\n\n\nOutput explanation\n\n\n\n\nIn R, the output shows: +the means of the variables (see ‘sample estimates’). +the calculated t-value (see ‘t =’). +the degrees of freedom (see ‘df =’). +the p-value (i.e. the probability of finding the obtained t-value, given the null hypothesis). +the expected value under the null hypothesis (here true mean difference is not equal to 0). +the mean of both groups is obtained separately via mean().\n+the standard errors of both groups in the sample are obtained separately via MeanSE().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.2.6.1 Reporting\nThe correct report includes:\n\nA conclusion about the null hypothesis;\nthe mean (in the text or as M = …) and the standard error (SE = …) of each variable,\nThe difference in means (here 0.972),\nthe degrees of freedom,\np = p-value. When working with statistical software, you should report the exact p-value that is displayed.\n\nin R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p &lt; 0.001 in your report. \n\n\n\n\n\n\n\n\nReport\n\n\n\n✓ The number of gym attendances of men last month (M = 3.97; SE = 0.063) was higher than the number of gym attendances of women last month (M = 3.00; SE = 0.054). This difference, 0.972, was statistically significant, t(1944.363) = 11.674, p &lt; 0.001.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>T-tests for means</span>"
    ]
  },
  {
    "objectID": "analysis_08_t-test.html#effect-sizes-for-t-tests",
    "href": "analysis_08_t-test.html#effect-sizes-for-t-tests",
    "title": "14  T-tests for means",
    "section": "14.3 Effect sizes for t-tests",
    "text": "14.3 Effect sizes for t-tests\nWe can calculate Cohen’s \\(d\\) or Hedges’ \\(g^*_s\\) as an effect size measure for a t-test. We are using function cohens_d and hedges_g from package effectsize.\n\n14.3.1 Cohen’s \\(d\\) for one sample\nWe are using function cohens_d from package effectsize. The parameters are pretty much the same as for the function t.test:\n\nlibrary(effectsize)\ncohens_d(cps19_age ~ 1, \n         data = canada, \n         mu = 48.5)\n\nCohen's d |       95% CI\n------------------------\n0.01      | [0.00, 0.02]\n\n- Deviation from a difference of 48.5.\n\n\n\ncps19_age ~ 1\n\nThis is the formula used for a single sample mean. In this case specify the formula in the form &lt;variable name&gt; ~ 1.\n\ndata = canada\n\nWe specify the data frame that we are using. Replace with your own data frame name.\n\nmu = 48.5\n\nWe specify the value of the population mean under the null hypothesis. It is very important to specify this. If omitted, mu is set to 0 and this will often not be appropriate, especially for a one sample test.\n\n\n\n\n14.3.2 Cohen’s d for paired samples\nWe are using function cohens_d from package effectsize. The parameters are pretty much the same as for the function t.test:\n\nlibrary(effectsize)\ncohens_d(Pair(cps19_lr_parties_1, cps19_lr_parties_2) ~ 1, \n         data = canada, \n         mu = 0)\n\nCohen's d |         95% CI\n--------------------------\n-0.58     | [-0.60, -0.57]\n\n\n\nPair(cps19_lr_parties_1, cps19_lr_parties_2) ~ 1\n\nWe have two paired interval-ratio variables and therefore use a formula in the form Pair(&lt;variable name 1&gt;, &lt;variable name 2&gt;) ~ 1.\n\ndata = canada\n\nWe specify the data frame that we want to use.\n\nmu = 0\n\nThe mu parameter should be set to the value of the mean under the null hypothesis. In the case of a paired sample t-test we usually hypothesize that the difference between the two variables is 0 in the population, thus mu = 0.\n\n\n\n\n14.3.3 Hedges’ \\(g^*_s\\) for independent samples\nFor two independent samples, we recommend calculating Hedges \\(g^*_s\\) as effect size measure (Delacre et al. 2021). Its interpretation is similar to Cohen’s \\(d\\), but bias-corrected and adapted to a situation when equal variances cannot be assumed. The values are very similar to Cohen’s \\(d\\) for larger samples.\nNote that for our example we use the modified version of variable cps19_bornin_canada (see Independent-samples t-test):\n\nlibrary(effectsize)\nhedges_g(cps19_lr_parties_1 ~ cps19_bornin_canada, \n         data = canada, \n         mu = 0,\n         pooled_sd = FALSE)\n\nHedges' g |         95% CI\n--------------------------\n-0.14     | [-0.17, -0.11]\n\n- Estimated using un-pooled SD.\n\n\n\ncps19_lr_parties_1 ~ cps19_bornin_canada\n\nWe have one interval-ratio variable and one categorical variable (factor) that captures to which group an observation belongs, thus we use a formula of the form &lt;interval-ratio variable&gt; ~ &lt;categorical variable&gt;.\n\ndata = canada\n\nWe specify the data frame that we want to use.\n\nmu = 0\n\nThe mu parameter should be set to the value of the mean under the null hypothesis. In the case of an independent samples t-test we usually hypothesize that the difference between the two group means is 0 in the population, thus mu = 0.\n\npooled_sd = FALSE\n\nThis specifies that we do not use the pooled standard deviation, which is recommended when using Welch’ t-test (not assuming variances are equal), which t.test does by default for the independent samples t-test.\n\n\n\n\n14.3.4 Reporting measures of association for t-tests\n\n14.3.4.1 Cohen’s d\nCohen’s d, or standardized mean difference, is one of the most common ways to measure effect size for t-tests. There are different ways to calculate it, depending on the type of t-test but the reporting is the same. Here, I show Cohen’s d based on the one-sample t-test above.\nExample output R (do not include the output directly in an academic paper):\n\nMeanSE(fruit$fruitconsumption, na.rm = TRUE)\n\n[1] 1.714986\n\nt.test(x = fruit$fruitconsumption,\n           alternative = \"two.sided\",\n           mu = 100,\n           conf.level = 0.95)\n\n\n    One Sample t-test\n\ndata:  fruit$fruitconsumption\nt = -5.831, df = 33, p-value = 1.587e-06\nalternative hypothesis: true mean is not equal to 100\n95 percent confidence interval:\n 86.51084 93.48916\nsample estimates:\nmean of x \n       90 \n\nlibrary(effectsize)\ncohens_d(fruitconsumption ~ 1, \n         data = fruit, \n         mu = 100)\n\nCohen's d |         95% CI\n--------------------------\n-1.00     | [-1.41, -0.58]\n\n- Deviation from a difference of 100.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThe Cohen’s d value range is from -∞ to +∞ and values can therefore be negative. If d is negative, it simply means that the group mean of the sample (or in the case of the paired/independent sample t-test the first group) is lower than the group of mean of population (or in the case of the paired/independent sample t-test the second group).\nA Cohen’s d of 1 means that the difference between the sample mean and hypothesized population mean is 1 standard deviation. A Cohen’s d of 0.5 means that the difference between the sample mean and hypothesized mean is 0.5 standard deviations (half a standard deviation).\nThe following rule of thumbs are often applied for interpreting Cohen’s d:\n\nA value of at least 0.2 represents a small effect size.\nA value of at least 0.5 represents a medium effect size.\nA value of at least 0.8 represents a large effect size.\n\nAs always with rules of thumbs, be careful and consider the type of data that you are working with.\n\n\n\n\n14.3.4.2 Reporting\nIf you have calculated Cohen’s d for a t-test, you can add it to the report:\n\n\n\n\n\n\nReport\n\n\n\n✓ The mean fruit consumption of students was 90 (SE = 1.71). This is not significantly different from the mean fruit consumption of the whole population (t(33) = -1.167, p = 0.252). This represents a large difference, d = -1.00.\n\n\n\n\n14.3.4.3 Hedges’ \\(g^*_s\\) for independent samples\nCohen’s d and Hedges \\(g^*_s\\) are largely comparable, but Hedges modification is considered more robust for small samples.\nExample output R (do not include the output directly in an academic paper):\n\nMeanSE(fruit$fruitconsumption, na.rm = TRUE)\n\n[1] 1.714986\n\nt.test(x = fruit$fruitconsumption,\n           alternative = \"two.sided\",\n           mu = 100,\n           conf.level = 0.95)\n\n\n    One Sample t-test\n\ndata:  fruit$fruitconsumption\nt = -5.831, df = 33, p-value = 1.587e-06\nalternative hypothesis: true mean is not equal to 100\n95 percent confidence interval:\n 86.51084 93.48916\nsample estimates:\nmean of x \n       90 \n\nlibrary(effectsize)\nhedges_g(fruitconsumption ~ 1, \n         data = fruit, \n         mu = 100)\n\nHedges' g |         95% CI\n--------------------------\n-0.98     | [-1.38, -0.57]\n\n- Deviation from a difference of 100.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\nThe interpretation of Hedges’ \\(g_s^*\\) is similar to Cohen’s D. A Hedges’ \\(g_s^*\\) of 1 means that the difference between the two sample means is 1 standard deviation. A Hedges’ \\(g_s^*\\) of 0.5 means that the difference between the two sample means is 0.5 standard deviations (half a standard deviation).\nThe following rule of thumbs are often applied for interpreting Cohen’s d and Hedges’ \\(g_s^*\\):\n\nA value of at least 0.2 represents a small effect size.\nA value of at least 0.5 represents a medium effect size.\nA value of at least 0.8 represents a large effect size.\n\nAs always with rules of thumbs, be careful and consider the type of data that you are working with.\n\n\n\n\n14.3.4.4 Reporting\nThe Hedges’ \\(g_s^*\\) effect size is often included after the independent samples t-test, for example:\n\n\n\n\n\n\nReport\n\n\n\n✓ The mean fruit consumption of students was 90 (SE = 1.71). This is not significantly different from the mean fruit consumption of the whole population (t(33) = -1.167, p = 0.252). This represents a large difference, \\(g_s^*\\) = -0.98.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>T-tests for means</span>"
    ]
  },
  {
    "objectID": "analysis_08_t-test.html#footnotes",
    "href": "analysis_08_t-test.html#footnotes",
    "title": "14  T-tests for means",
    "section": "",
    "text": "In this overview we use the co-called ‘formula interface’ to t.test. You can also use the so-called traditional interface. For the one-sample t-test example, the equivalent code is:\n\nt.test(x = canada$cps19_age,\n       alternative = \"two.sided\",\n       mu = 48.5,\n       conf.level = 0.95)\n\n\n    One Sample t-test\n\ndata:  canada$cps19_age\nt = 2.2395, df = 37821, p-value = 0.02513\nalternative hypothesis: true mean is not equal to 48.5\n95 percent confidence interval:\n 48.52387 48.85871\nsample estimates:\nmean of x \n 48.69129 \n\n\n↩︎\nIn this overview we use the co-called ‘formula interface’ to t.test. You can also use the so-called traditional interface. For the paired samples t-test example, the equivalent code is:\n\nt.test(x = canada$cps19_lr_parties_1, \n       y = canada$cps19_lr_parties_2,\n       data = canada,\n       alternative = \"two.sided\",\n       mu = 0,\n       paired = TRUE,\n       conf.level = 0.95)\n\n\n    Paired t-test\n\ndata:  canada$cps19_lr_parties_1 and canada$cps19_lr_parties_2\nt = -95.406, df = 26718, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -2.691519 -2.583155\nsample estimates:\nmean difference \n      -2.637337 \n\n\nIn this case, do not forget to include paired = TRUE.↩︎",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>T-tests for means</span>"
    ]
  },
  {
    "objectID": "analysis_09_power_analysis.html",
    "href": "analysis_09_power_analysis.html",
    "title": "15  Power analysis",
    "section": "",
    "text": "The current course only provides a basic introduction to power analysis. Package pwr offers power analysis for, among others, t tests, proportion tests and chi squared tests. The usage of package pwr is not exam material.\nCalculate power for a two sample t-test with a given sample size (n = 30) and effect size (Cohen’s d = 0.5):\n\nlibrary(pwr)\npwr.t.test(n = 30, d = 0.5, sig.level = .05, type = \"two.sample\",\n           alternative = \"two.sided\")\n\n\n     Two-sample t test power calculation \n\n              n = 30\n              d = 0.5\n      sig.level = 0.05\n          power = 0.4778965\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nIf we want to know what sample size is required for detecting an effect size of d = 0.8 with 80% power, we omit n from the arguments:\n\npwr.t.test(d = 0.3, power = 0.8, sig.level = .05, type = \"two.sample\",\n           alternative = \"two.sided\")\n\n\n     Two-sample t test power calculation \n\n              n = 175.3847\n              d = 0.3\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Power analysis</span>"
    ]
  },
  {
    "objectID": "analysis_10_anova.html",
    "href": "analysis_10_anova.html",
    "title": "16  ANOVA",
    "section": "",
    "text": "16.1 Pairwise t-test for comparing multiple group means\nWe can use a pairwise t-test for comparing the means of all possible pairs of groups. We use a multiple testing adjustment (bonferroni correction) to account for the fact that we are conducting many t-tests:\npairwise.t.test(x = canada$pes19_lr_self_1,\n                g = canada$pes19_province,\n                p.adjust.method = \"bonferroni\",\n                alternative = \"two.sided\")\nPairwise comparisons using t tests with pooled SD \n\ndata:  canada$pes19_lr_self_1 and canada$pes19_province \n\n                          Alberta British Columbia Manitoba New Brunswick\nBritish Columbia          1.7e-06 -                -        -            \nManitoba                  0.022   1.000            -        -            \nNew Brunswick             0.041   1.000            1.000    -            \nNewfoundland and Labrador 0.066   1.000            1.000    1.000        \nNorthwest Territories     1.000   1.000            1.000    1.000        \nNova Scotia               0.034   1.000            1.000    1.000        \nNunavut                   1.000   1.000            1.000    1.000        \nOntario                   4.5e-06 1.000            1.000    1.000        \nPrince Edward Island      1.000   1.000            1.000    1.000        \nQuebec                    3.0e-05 1.000            1.000    1.000        \nSaskatchewan              1.000   1.000            1.000    1.000        \nYukon                     1.000   1.000            1.000    1.000        \n                          Newfoundland and Labrador Northwest Territories\nBritish Columbia          -                         -                    \nManitoba                  -                         -                    \nNew Brunswick             -                         -                    \nNewfoundland and Labrador -                         -                    \nNorthwest Territories     1.000                     -                    \nNova Scotia               1.000                     1.000                \nNunavut                   1.000                     1.000                \nOntario                   1.000                     1.000                \nPrince Edward Island      1.000                     1.000                \nQuebec                    1.000                     1.000                \nSaskatchewan              1.000                     1.000                \nYukon                     1.000                     1.000                \n                          Nova Scotia Nunavut Ontario Prince Edward Island\nBritish Columbia          -           -       -       -                   \nManitoba                  -           -       -       -                   \nNew Brunswick             -           -       -       -                   \nNewfoundland and Labrador -           -       -       -                   \nNorthwest Territories     -           -       -       -                   \nNova Scotia               -           -       -       -                   \nNunavut                   1.000       -       -       -                   \nOntario                   1.000       1.000   -       -                   \nPrince Edward Island      1.000       1.000   1.000   -                   \nQuebec                    1.000       1.000   1.000   1.000               \nSaskatchewan              1.000       1.000   1.000   1.000               \nYukon                     1.000       1.000   1.000   1.000               \n                          Quebec Saskatchewan\nBritish Columbia          -      -           \nManitoba                  -      -           \nNew Brunswick             -      -           \nNewfoundland and Labrador -      -           \nNorthwest Territories     -      -           \nNova Scotia               -      -           \nNunavut                   -      -           \nOntario                   -      -           \nPrince Edward Island      -      -           \nQuebec                    -      -           \nSaskatchewan              1.000  -           \nYukon                     1.000  1.000       \n\nP value adjustment method: bonferroni",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "analysis_10_anova.html#pairwise-t-test-for-comparing-multiple-group-means",
    "href": "analysis_10_anova.html#pairwise-t-test-for-comparing-multiple-group-means",
    "title": "16  ANOVA",
    "section": "",
    "text": "pairwise.t.test(…)\n\nThis calls the function pairwise.t.test to conduct this test. It is included in the stats packages, which is loaded automatically.\n\nx = canada$pes19_lr_self_1\n\nWe specify the interval ratio variable here (in our case variable pes19_lr_self_1 from the dataset canada). We need to use the dollar sign notation, i.e. &lt;dataset&gt;$&lt;variable name&gt;\n\ng = canada$pes19_province\n\nWe specify the grouping variable here, again using the dollar sign notation (see above).\n\np.adjust.method = \"bonferroni\"\n\nThis specifies that we want to use the Bonferroni correction.\n\nalternative = \"two.sided\"\n\nThis conducts two-sided significance tests (the default). Other options include \"greater\" and \"less\".",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "analysis_10_anova.html#reporting-anova",
    "href": "analysis_10_anova.html#reporting-anova",
    "title": "16  ANOVA",
    "section": "16.2 Reporting ANOVA",
    "text": "16.2 Reporting ANOVA\nANOVA compares variances in order to establish whether there is a difference in means between more than two groups. We use example data on the rating of 4 seasons of game of thrones.\nExample output R (do not include the output directly in an academic paper):\n\ngot_out &lt;- aov(formula =  score ~ season, \n                 data = got_dta)\nsummary(got_out)\n\n             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nseason        3   92.8  30.943   7.306 0.000121 ***\nResiduals   175  741.2   4.235                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n16.2.0.1 Reporting\nThe correct report includes:\n\nA conclusion about the null hypothesis;\nF(degrees of freedom Between Groups, degrees of freedom Within Groups,) = F-ratio,\np = p-value. When working with statistical software, you should report the exact p-value that is displayed.\n\nin R, small values may be displayed using the scientific notation (e.g. 2.2e-16 is the scientific notation of 0.00000000000000022.) This means that the value is very close to zero. R uses this notation automatically for very small numbers. In these cases, write p &lt; 0.001 in your report. \n\n\n\n\n\n\n\n\nReport\n\n\n\n✓ There was a statistically significant difference between the mean rating of game of thrones seasons across different groups, F(3, 175) = 7.306, p &lt; 0.001.",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "analysis_10_anova.html#bonferroni-correction",
    "href": "analysis_10_anova.html#bonferroni-correction",
    "title": "16  ANOVA",
    "section": "16.3 Bonferroni correction",
    "text": "16.3 Bonferroni correction\n\nlibrary(stats)\npairwise.t.test(score, season, p.adjust.method=\"bonferroni\")\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  score and season \n\n   S5      S6      S7     \nS6 0.92850 -       -      \nS7 0.20375 1.00000 -      \nS8 0.28608 0.00360 0.00024\n\nP value adjustment method: bonferroni \n\n\n\n\nThe description of the pairwise comparison with Bonferroni correction can be added after the report from the ANOVA. You list the groups that differ significantly. Then you indicate that the other categories were not statistically significant and include the lowest p value.\n\n\n\n\n\n\nReport\n\n\n\nThe difference between the last category (season 8) and the categories season 6 and season 7 is significant when we apply a t-test with Bonferroni correction (p &lt; 0.05). The differences between the remaining categories are not statistically significant (p = 0.20375 or higher).",
    "crumbs": [
      "Statistical analysis in R",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ANOVA</span>"
    ]
  },
  {
    "objectID": "common_errors.html",
    "href": "common_errors.html",
    "title": "Appendix A — Common errors in R",
    "section": "",
    "text": "A.1 Top-5 errors",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common errors in R</span>"
    ]
  },
  {
    "objectID": "common_errors.html#top-5-errors",
    "href": "common_errors.html#top-5-errors",
    "title": "Appendix A — Common errors in R",
    "section": "",
    "text": "Function not found\nThe difference between = and ==\nFile not found / No such file\nUpper and lower case\nUsing |&gt; instead of + in a ggplot",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common errors in R</span>"
    ]
  },
  {
    "objectID": "common_errors.html#syntax-errors",
    "href": "common_errors.html#syntax-errors",
    "title": "Appendix A — Common errors in R",
    "section": "A.2 Syntax errors",
    "text": "A.2 Syntax errors\n\nA.2.1 Upper and lower case\nR is case sensitive, which means that upper and lower case are not interchangeable:\n\nx &lt;- c(1,2,3,4,5)\nMean(x)  # Won't work, because the function mean starts with a lower case m\n\nError in Mean(x): could not find function \"Mean\"\n\n\nFix by using the correct case:\n\nx &lt;- c(1,2,3,4,5)\nmean(x)\n\n[1] 3\n\n\nVariable names are also case-sensitive:\n\nMyVariable = \"Hello\"\nprint(myvariable)  # Object not found, because we're using lower case here\n\nError in eval(expr, envir, enclos): object 'myvariable' not found\n\n\nFix by using the correct case:\n\nprint(MyVariable)\n\n[1] \"Hello\"\n\n\n\n\nA.2.2 Incomplete code\nA very common error by users is to not close a bracket. R needs ‘complete statements’ and if you execute ‘incomplete’ code with Enter/Return, R will not know where the command ends.\n\n #this is an example of a missing bracket\n\nIf you run this code, you will not get an error message but R will simply ‘wait’ for the rest and indicate this with a + sign. For example, in the example above, you will see the following output in the console:\n\n&gt; ((4+5)/(6 + 3) * 2\n+\n\nIn this case you can either write the missing part, i.e. the closing bracket, in the console (the window below) and click Enter/Return or, alternatively, click in the console and use the ‘Escape’ button (which will reset the console). You can then enter new (complete) code.\n\n\nA.2.3 Annotation errors\nIf you place code that you want R to execute behind an annotation, it will not run:\n\n# I am annotating this: x &lt;- c(1,2,3,4)\n\nFix:\n\n# I am annotating this\nx &lt;- c(1,2,3,4)\n\nThe same is true for annotation in a pipe:\n\nx &lt;- c(1,2,3,4)\nx |&gt;\n  mean() # annotation hello |&gt;\n\n[1] 2.5\n\n  sqrt()\n\nError in sqrt(): 0 arguments passed to 'sqrt' which requires 1\n\n\nFix:\n\nx &lt;- c(1,2,3,4)\nx |&gt;\n  mean() |&gt; # annotation hello \n  sqrt()\n\n[1] 1.581139\n\n\n\n\nA.2.4 Forgetting quotation marks around a character vector\nRemember that text (character vectors, also called strings) requires quotation marks around it:\n\nmy_text &lt;- Hello, this won't work\n\nError: &lt;text&gt;:1:17: unexpected ','\n1: my_text &lt;- Hello,\n                    ^\n\n\nWe normally use double quotation marks (\"), but single quotation marks will also work ('):\n\nmy_text &lt;- \"Hello, this works\"\nmy_text2 &lt;- 'Hello, this also works'\n\n\n\nA.2.5 Too many or too few brackets or quotation marks\nEvery bracket (() and every quotation mark (\") needs to be closed (once):\n\nx &lt;- c(1,2,3,4\n\nError: &lt;text&gt;:2:0: unexpected end of input\n1: x &lt;- c(1,2,3,4\n   ^\n\n\n\ny &lt;- \"Hello\n\nError: &lt;text&gt;:1:6: unexpected INCOMPLETE_STRING\n1: y &lt;- \"Hello\n         ^\n\n\n\nx &lt;- c(1,2,3,4))\n\nError: &lt;text&gt;:1:16: unexpected ')'\n1: x &lt;- c(1,2,3,4))\n                   ^\n\n\n\ny &lt;- \"Hello\"\"\n\nError: &lt;text&gt;:1:13: unexpected INCOMPLETE_STRING\n1: y &lt;- \"Hello\"\"\n                ^\n\n\n\nz &lt;- \"You cannot put a \"string\" inside a string\"\n\nError: &lt;text&gt;:1:25: unexpected symbol\n1: z &lt;- \"You cannot put a \"string\n                            ^\n\n\nIf you get unexpected symbol errors, it is often for this reason.\nIf you have a text with a double quotation mark in it, put \\ before it (this is called ‘escaping’, so R means that you mean to write a quotation mark and not announce the end of the character variable):\n\nmy_text &lt;- \"Is it \\\"normal\\\" to like R?\"\ncat(my_text)\n\nIs it \"normal\" to like R?\n\n\n\n\nA.2.6 The difference between = and ==\nPeople often confuse = and ==:\n\ndata(\"starwars\")\nstarwars |&gt;\n  mutate(height_inch == height / 2.54)\n\nError in `mutate()`:\nℹ In argument: `height_inch == height/2.54`.\nCaused by error:\n! object 'height_inch' not found\n\n\nHere we used two equal signs where one should be used. R thinks we are trying to make a comparison with height_inch (and throws an error, because it doesn’t exist) when we are trying to create a new variable called height_inch.\n\ndata(\"starwars\")\nstarwars |&gt;\n  filter(height = 150)\n\nError in `filter()`:\n! We detected a named input.\nℹ This usually means that you've used `=` instead of `==`.\nℹ Did you mean `height == 150`?\n\n\nHere we used a single equal sign, where we should have put two. In this case R recognizes the potential error and suggests that we need to two equal signs. Thanks R!\nRemember:\n\nOne equal sign (=) is used to assign a variable, for example in mutate:\n\ndta |&gt;\n  mutate(new_variable = old_variable + 10)\n\nTwo equal signs (==) are used when comparing or conditioning, for example in filter or case_when:\n\ndta |&gt;\n  filter(height == 200)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common errors in R</span>"
    ]
  },
  {
    "objectID": "common_errors.html#package-errors",
    "href": "common_errors.html#package-errors",
    "title": "Appendix A — Common errors in R",
    "section": "A.3 Package errors",
    "text": "A.3 Package errors\n\nA.3.1 Function not found\n\nPhi(data$econ, data$oecd)\n\nError in Phi(data$econ, data$oecd): could not find function \"Phi\"\n\n\nWe try to run a function, but R says it could not find it.\n\nHave you loaded the package that contains this function? In this example: library(DescTools)\nDid you spell the function name correctly, including the use of upper and lower case?\nIs this a custom function that is part of your code? You need to select and run the code that defines the function before referencing this function.\n\n\n\nA.3.2 Conflicting functions\nIf you load multiple packages which have functions with the same name, this can lead to conflicts. Usually, the last package loaded ‘masks’ functions with the same name from previously loaded packages. R will warn you about this when loading the packages, but you may not always be aware and as a result the wrong function is used.\n\n# Load tidyverse first, then expss\nlibrary(tidyverse)\nlibrary(expss)\n\n# Create an example data frame with one variable 'test'\ndta &lt;- tibble(test = letters[1:5]) \n\n# Try to call recode (from dplyr), but this is masked by recode from expss\ndta |&gt;\n  mutate(test2 = recode(test, \"a\" = \"b\"))\n\nError in `mutate()`:\nℹ In argument: `test2 = recode(test, a = \"b\")`.\nCaused by error in `FUN()`:\n! 'recode': all recodings should be formula but: \"b\"\n\n\nThere are various ways to address this problem:\n\nLoad the packages in the correct order, i.e. the last package is the one that you need any conflicting functions from:\n\n\nlibrary(expss)\nlibrary(tidyverse)\n\n\nUse packagename::function instead of just the function name:\n\n\n# We specify that we want to use recode from dplyr by writing dplyr::recode\ndta |&gt;\n  mutate(test2 = dplyr::recode(test, \"a\" = \"b\"))\n\n# A tibble: 5 × 2\n  test  test2\n  &lt;chr&gt; &lt;chr&gt;\n1 a     b    \n2 b     b    \n3 c     c    \n4 d     d    \n5 e     e    \n\n\n\nDetach a package you no longer need, for example:\n\n\ndetach(\"package:expss\", unload = TRUE)\n\n# Now there is no more conflict\ndta |&gt;\n  mutate(test2 = recode(test, \"a\" = \"b\"))\n\n# A tibble: 5 × 2\n  test  test2\n  &lt;chr&gt; &lt;chr&gt;\n1 a     b    \n2 b     b    \n3 c     c    \n4 d     d    \n5 e     e",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common errors in R</span>"
    ]
  },
  {
    "objectID": "common_errors.html#file-errors",
    "href": "common_errors.html#file-errors",
    "title": "Appendix A — Common errors in R",
    "section": "A.4 File errors",
    "text": "A.4 File errors\n\nA.4.1 File not found / No such file\nIf R cannot find a file you are trying to open:\n\nimport(\"file.csv\")\n\nError: No such file: file.csv\n\n\n\nCheck for typos and use of UPPER and lower case.\nDid you include the correct file extension (e.g. .csv, .sav, .por)?\nDoes the file indeed exist and is it located in the project folder (or working directory)? Type dir() in the Console to list the files in the current working directory. Using getwd() you can get the current working directory and this can be changed by setwd(). But the best practice is to work in an R project (a folder on your computer) where all your files are located (see week 1).\nPerhaps the file is in a sub-folder? For example, if the file is located in a folder called data, try import(\"data/file.csv\").",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common errors in R</span>"
    ]
  },
  {
    "objectID": "common_errors.html#data-preparation-and-transformation-errors",
    "href": "common_errors.html#data-preparation-and-transformation-errors",
    "title": "Appendix A — Common errors in R",
    "section": "A.5 Data preparation and transformation errors",
    "text": "A.5 Data preparation and transformation errors\n\nA.5.1 Forgetting to use mutate inside case_when\nWhen using case_when(), we must create a new variable in our recoding procedure with mutate(). Otherwise R will not know where to put the new, recoded data.\n\nlibrary(openintro) # This is where the data is from\ngpa_study_hours &lt;- gpa_study_hours |&gt;\n  case_when(\n          gpa &gt;= 3.7 ~ \"A\",\n          gpa &gt;= 3.3 ~ \"B\",\n          gpa &gt;= 1.7 ~ \"C\",\n          gpa &gt;= 1.3 ~ \"D\",\n          gpa &lt; 1.3 ~ \"F\")\n\nError in `case_when()`:\n! Case 1 (`gpa_study_hours`) must be a two-sided formula, not a\n  &lt;tbl_df/tbl/data.frame&gt; object.\n\n\nThe solution is to put the case_when statement inside mutate():\n\nlibrary(openintro) # This is where the data is from\ngpa_study_hours &lt;- gpa_study_hours |&gt;\n  mutate(grade = case_when(\n    gpa &gt;= 3.7 ~ \"A\",\n    gpa &gt;= 3.3 ~ \"B\",\n    gpa &gt;= 1.7 ~ \"C\",\n    gpa &gt;= 1.3 ~ \"D\",\n    gpa &lt; 1.3 ~ \"F\"))\n\n\n\nA.5.2 Not assigning the result\nIf you perform any operation that aims to modify data in your dataset (for example filter, select, mutate, etc.), you need to assign the result. Otherwise R will just print out your modifications but not save them in memory:\n\nexample_data &lt;- data.frame(x = c(1,2,3,4,5))\nexample_data |&gt;\n  mutate(y = x * 2)\n\n  x  y\n1 1  2\n2 2  4\n3 3  6\n4 4  8\n5 5 10\n\n\nR has printed out the result, but not saved it in example_data:\n\nprint(example_data) # No 'y', because we did not assign the result\n\n  x\n1 1\n2 2\n3 3\n4 4\n5 5\n\n\nIf you want to save the result, assign it to an object:\n\nexample_data &lt;- example_data |&gt;\n  mutate(y = x * 2)\nexample_data # Now 'y' has been stored in 'example_data'\n\n  x  y\n1 1  2\n2 2  4\n3 3  6\n4 4  8\n5 5 10\n\n\n\n\nA.5.3 Overwriting data\nIf you mutate a variable and save it to a variable with the same name, the original data is lost:\n\nexample_data &lt;- data.frame(x = c(1,2,3,4,5))\nexample_data\n\n  x\n1 1\n2 2\n3 3\n4 4\n5 5\n\nexample_data &lt;- example_data |&gt;\n  mutate(x = x + 10)\nexample_data\n\n   x\n1 11\n2 12\n3 13\n4 14\n5 15\n\n\n\n\nA.5.4 Missing data recoding using na_if: loss of generality\nIf you make a mistake in correctly spelling the value of a factor variable, when using the function na_if, you will get a ‘loss of generality’ error:\n\nexample_data &lt;- data.frame(drink = as.factor(c(\"Tea\", \"Coffee\", \"Coffee\", \"Milk\")))\n\n# Suppose we would like to mark 'Coffee' as missing values, and we write\nexample_data |&gt; \n  mutate(drink = na_if(drink, \"Koffee\")) # Note the spelling error in Coffee\n\nError in `mutate()`:\nℹ In argument: `drink = na_if(drink, \"Koffee\")`.\nCaused by error in `na_if()`:\n! Can't convert from `y` &lt;character&gt; to `x` &lt;factor&lt;b5ac8&gt;&gt; due to loss of generality.\n• Locations: 1\n\n\nIn more simple language: R cannot find a level ‘Koffee’ in the factor variable drink and this produces an error. If we correct the spelling error, this should work:\n\nexample_data |&gt; \n  mutate(drink = na_if(drink, \"Coffee\")) # This should work and produce missing values for the 2nd and 3rd row\n\n  drink\n1   Tea\n2  &lt;NA&gt;\n3  &lt;NA&gt;\n4  Milk",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common errors in R</span>"
    ]
  },
  {
    "objectID": "common_errors.html#ggplot2-errors",
    "href": "common_errors.html#ggplot2-errors",
    "title": "Appendix A — Common errors in R",
    "section": "A.6 ggplot2 errors",
    "text": "A.6 ggplot2 errors\n\nA.6.1 An empty graph\n\nHave you included a geom layer?\nHave you put a plus sign between the layers of the ggplot? (see below)\nHave you inadvertently used the pipe instead of the plus sign to connect layers?\n\n\n\nA.6.2 Forgetting the plus sign at the end of the line\nIf you do not include the plus sign at the end of the line, the next part of the graph is not seen as part of the current graph.\n\nlibrary(openintro)\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = interest_rate)) \n\n\n\n\n\n\n\ngeom_histogram()\n\ngeom_bar: na.rm = FALSE, orientation = NA\nstat_bin: binwidth = NULL, bins = NULL, na.rm = FALSE, orientation = NA, pad = FALSE\nposition_stack \n\n\nFix by adding the + sign at the end of the line:\n\nlibrary(openintro)\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = interest_rate)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\nA.6.3 Using |&gt; instead of + in a ggplot\nPerhaps confusingly you should use the + sign to add layers to a ggplot, not the pipe |&gt; (or %&gt;%). This throws an error:\n\nlibrary(openintro)\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = interest_rate)) |&gt;\n  geom_histogram()\n\nError in `geom_histogram()`:\n! `mapping` must be created by `aes()`\nℹ Did you use `%&gt;%` or `|&gt;` instead of `+`?\n\n\nFix by replacing the pipe by a plus sign:\n\nlibrary(openintro)\ndata(loan50)\nggplot(data = loan50,\n       mapping = aes(x = interest_rate)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\nA.6.4 Forgetting aes()\nNote that if you want to assign variables to an aesthetic (an axis, colour, shape, etc.) you need to use aes(). This won’t work:\n\nlibrary(openintro)\ndata(loan50)\nggplot(data = loan50,\n       x = interest_rate) +\n  geom_histogram()\n\nError in `geom_histogram()`:\n! Problem while computing stat.\nℹ Error occurred in the 1st layer.\nCaused by error in `setup_params()`:\n! `stat_bin()` requires an x or y aesthetic.\n\n\nFix by including aes():\n\nlibrary(openintro)\ndata(loan50)\nggplot(data = loan50,\n       aes(x = interest_rate)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\nForgetting aes() can also lead to ‘object not found’ errors, for example, when we forget to include aes() in the geom_point function:\n\nlibrary(openintro)\ndata(loan50)\nggplot(data = loan50, \n       mapping = aes(x = total_income, y = loan_amount)) +\n  geom_point(colour = homeownership)\n\nError in eval(expr, envir, enclos): object 'homeownership' not found\n\n\nR will interpret the above as setting the colour of all points to homeownership . It will look for an object called homeownership , which does not exist. You need to tell R that you are trying to map the colour of the points to the variable homeownership from the data frame you are using. Do that by putting aes() around colour = homeownership:\n\nlibrary(openintro)\ndata(loan50)\nggplot(data = loan50, \n       mapping = aes(x = total_income, y = loan_amount)) +\n  geom_point(aes(colour = homeownership))\n\n\n\n\n\n\n\n\n\n\nA.6.5 Colours do not match\nIf you are trying to set a fixed colour for a graph element, for example grey points in a scatterplot, you should not include aes() .\n\nlibrary(openintro)\ndata(loan50)\nggplot(data = loan50, \n       mapping = aes(x = total_income, y = loan_amount)) +\n  geom_point(aes(colour = \"grey\"))\n\n\n\n\n\n\n\n\nInstead of grey dots we get red dots! Why? Because we have told R to link the colour of the dots to a variable (or constant, really) “grey”. Think of it as adding a new variable to the dataset which has the same value for each case. R matches the first default colour (red) to use for all cases in the group (which are all cases in the graph).\nFix by removing aes():\n\nlibrary(openintro)\ndata(loan50)\nggplot(data = loan50, \n       mapping = aes(x = total_income, y = loan_amount)) +\n  geom_point(colour = \"grey\")\n\n\n\n\n\n\n\n\nRemember: use aes() when you want to link an element of the graph to a variable in your data. If you want to just change a fixed colour, border, etc. do not use aes().",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common errors in R</span>"
    ]
  },
  {
    "objectID": "common_errors.html#errors-in-using-statistical-functions",
    "href": "common_errors.html#errors-in-using-statistical-functions",
    "title": "Appendix A — Common errors in R",
    "section": "A.7 Errors in using statistical functions",
    "text": "A.7 Errors in using statistical functions\n\nA.7.1 Forgetting table() when using prop.test\nWhen using prop.test for data in a data frame, you need to include table() around the arguments. This will not work:\n\n# We are using variable am from mtcars which indicates if a car has automatic (0) or manual (1) transmission\nprop.test(mtcars$am)\n\nError in prop.test(mtcars$am): argument \"n\" is missing, with no default\n\n\nWe can fix this by putting table() around the variable(s):\n\n# We are using variable am from mtcars which indicates if a car has automatic (0) or manual (1) transmission\nprop.test(table(mtcars$am))\n\n\n    1-sample proportions test with continuity correction\n\ndata:  table(mtcars$am), null probability 0.5\nX-squared = 0.78125, df = 1, p-value = 0.3768\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.4078543 0.7578086\nsample estimates:\n      p \n0.59375",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Common errors in R</span>"
    ]
  }
]